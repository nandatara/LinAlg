#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass memoir
\begin_preamble
%\renewcommand{\contentsname}{Table of Contents}
%\renewcommand{\printtoctitle}[1]{\centering\Huge\bfseries #1}
\usepackage{lmodern}
 \usepackage{multicol}
\usepackage[svgnames]{xcolor}
\usepackage{calc,graphicx,soul}
\usepackage{wrapfig}
\usepackage{tikz,float}
\usepackage[
  backend=biber,
  citestyle=alphabetic,
  bibstyle=numeric,
 sorting=nyt,
 url=false, 
doi=false,
eprint=false,
 url=false,
 isbn=false
]{biblatex}
\usepackage[font=small,labelfont=bf,figurename=Fig.]{caption}
\usepackage{gauss}
\usepackage{mathrsfs}
\usepackage{listings}
%\nocite{*}
\addbibresource{Z:/Lyx/Docs/analysis.bib}
%\setsecheadstyle{\phantomsection\Large\scshape\MakeLowercase} 
%\setsubsecheadstyle{\phantomsection\normalsize\bfseries} 
%\setsubsubsecheadstyle{\phantomsection\small\bfseries}
%\setaftersubsubsecskip{-1em}
%\maxsecnumdepth{subsection}
%\setsecnumdepth{subsection} 
%\setsecheadstyle{\phantomsection\Large\scshape\MakeLowercase}
%\setcounter{tocdepth}{1}
\end_preamble
\options openany
\use_default_options true
\begin_modules
eqs-within-sections
theorems-ams-bytype
theorems-ams-extended-bytype
enumitem
theorems-chap-bytype
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format pdf5
\output_sync 1
\bibtex_command biber
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize a4paper
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_numerical
\use_bibtopic true
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\backgroundcolor #d9d9ff
\boxbgcolor #55aaff
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1.875in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle empty
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
definecolor{doc}{RGB}{0,60,110}
\end_layout

\begin_layout Plain Layout


\backslash
newlength{
\backslash
drop} 
\end_layout

\begin_layout Plain Layout


\backslash
newcommand*{
\backslash
titleLA }
\end_layout

\begin_layout Plain Layout

{
\backslash
begingroup 
\end_layout

\begin_layout Plain Layout


\backslash
drop=0.2
\backslash
textheight 
\end_layout

\begin_layout Plain Layout


\backslash
begin{minipage}[t]{0.05
\backslash
textwidth} 
\end_layout

\begin_layout Plain Layout


\backslash
color{doc!50} 
\backslash
rule{6pt}{0.8
\backslash
textheight} 
\end_layout

\begin_layout Plain Layout


\backslash
end{minipage} 
\end_layout

\begin_layout Plain Layout


\backslash
hspace{0.05
\backslash
textwidth} 
\end_layout

\begin_layout Plain Layout


\backslash
begin{minipage}[t]{0.8
\backslash
textwidth} 
\end_layout

\begin_layout Plain Layout


\backslash
vspace*{
\backslash
drop} %
\backslash
vspace{3
\backslash
baselineskip} 
\end_layout

\begin_layout Plain Layout

{
\backslash
noindent
\backslash
HUGE
\backslash
bfseries LECTURES ON 
\backslash

\backslash
[0.1
\backslash
baselineskip]
\backslash

\backslash
LINEAR ALGEBRA} 
\backslash

\backslash
[2
\backslash
baselineskip] 
\end_layout

\begin_layout Plain Layout

{
\backslash
Huge Tara Nanda}
\backslash

\backslash
[
\backslash
baselineskip] 
\end_layout

\begin_layout Plain Layout

%
\backslash
vspace{2
\backslash
baselineskip} 
\end_layout

\begin_layout Plain Layout

%
\backslash
begin{minipage}{0.8
\backslash
textwidth} 
\end_layout

\begin_layout Plain Layout

{
\backslash
itshape A course given at IISER Thiruvanathapuram in Varsha 2014} 
\backslash
end{minipage} 
\end_layout

\begin_layout Plain Layout


\backslash
hfill 
\end_layout

\begin_layout Plain Layout


\backslash
endgroup}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
pagestyle{empty}
\end_layout

\begin_layout Plain Layout


\backslash
titleLA
\end_layout

\begin_layout Plain Layout


\backslash
clearpage
\end_layout

\begin_layout Plain Layout


\backslash
pagestyle{companion}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
hypersetup{   colorlinks   = true, %Colours links instead of ugly boxes
\end_layout

\begin_layout Plain Layout

urlcolor     = blue, %Colour for external hyperlinks   
\end_layout

\begin_layout Plain Layout

linkcolor    = Fuchsia, %Colour of internal links   
\end_layout

\begin_layout Plain Layout

citecolor   = red %Colour of citations 
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
input{chapterstyle}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{Preface}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newcommand*{
\backslash
arraycolor}[1]{
\backslash
protect
\backslash
leavevmode
\backslash
color{#1}}
\end_layout

\begin_layout Plain Layout


\backslash
newcolumntype{A}{>{
\backslash
columncolor{blue!30!white}}c} 
\end_layout

\begin_layout Plain Layout


\backslash
newcolumntype{B}{>{
\backslash
columncolor{LightGoldenrod}}c} 
\end_layout

\begin_layout Plain Layout


\backslash
newcolumntype{C}{>{
\backslash
columncolor{FireBrick!50}}c} 
\end_layout

\begin_layout Plain Layout


\backslash
newcolumntype{D}{>{
\backslash
columncolor{Gray!42}}c} 
\end_layout

\begin_layout Plain Layout


\backslash
def
\backslash
cc{
\backslash
cellcolor{SkyBlue}}
\end_layout

\end_inset


\end_layout

\begin_layout Chapter*
\noindent
Preface
\end_layout

\begin_layout Standard
These lecture notes are organised in the form of a 
\emph on
fictitious narrative
\emph default
.
 It is always a pleasant experience when the development of any subject
 is conveyed in a chronological order.
 This is seldom feasible since the historical narrative is never linear.
 There are many detours and many many people have contributed to the subject.
 Many ideas may not have been ripe at the time of their discovery but over
 a period of time people may have realized their importance.
 These ideas then become definitions and Theorems.
\end_layout

\begin_layout Standard
Most books these days are written in a 
\emph on
linear
\emph default
 fashion.
 While such an approach has its pedagogical value especially for a begining
 student it tends to become very dry.
 I wonder as to how many people would love to read a dry and boring novel.
 I have tried to write an interesting novel with the aim of keeping the
 reader engrossed.
 In most lectures a 
\emph on
natural question
\emph default
 has been asked and the reasoning behind the Theorems and their proofs has
 been made 
\emph on
plausible.
 
\emph default
Although such a reasoning may not be true in the historical sense it would
 certainly reveal why a particular idea was discovered and even if it was
 not discovered that way then sooner or later the discovery would have been
 imminent.
\end_layout

\begin_layout Standard
To give a concrete example, in the chapter on Normal Groups, the notion
 of 
\emph on
kernel
\emph default
 arose quite naturally in the context of 
\emph on
homomorphisms
\emph default
.
 These in turn arose from the multiplicative property of an 
\emph on
isomorphism
\emph default
 a topic which originated in the following question: when are two groups
 ``same''? It was discovered that the kernel of a homomorphism was a subgroup
 of the original group with many interesting properties.
 So the natural question was the converse: is every subroup of a group the
 kernel of a homomorphism? In trying to answer this question we are very
 naturraly led to the concept of 
\emph on
conjugation
\emph default
 or 
\emph on
normality
\emph default
.
 Having answered this question and reached an important landmark we explore
 the beauty of the surroundings and are led to motivated proofs of the three
 
\emph on
Isomorphism Theorems
\emph default
 which are the corner stones of Group Theory.
\end_layout

\begin_layout Standard
I hope these lectures are useful and make an interesting reading
\end_layout

\begin_layout Standard
\noindent
\align right
Tara Nanda
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList table

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Part
Vector Spaces and Matrices
\end_layout

\begin_layout Chapter
Vector Spaces
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\u}{\mathbf{u}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\v}{\mathbf{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\w}{\mathbf{w}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\0}{\mathbf{0}}
\end_inset


\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $F$
\end_inset

 be a field (or, more generally, a division ring).
 A 
\emph on
vector space
\emph default
 
\begin_inset Formula $V$
\end_inset

 over 
\begin_inset Formula $F$
\end_inset

 is a set with two operations, 
\begin_inset Formula $+\,\colon\, V\times V\longrightarrow V$
\end_inset

 and 
\begin_inset Formula $\cdot\,\colon\, F\times V\longrightarrow V$
\end_inset

, such that 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $(\u+\v)+\w=\u+(\v+\w)$
\end_inset

 for all 
\begin_inset Formula $\u,\v,\w\in V$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\u+\v=\v+\u$
\end_inset

 for all 
\begin_inset Formula $\u,\v\in V$
\end_inset

 
\end_layout

\begin_layout Enumerate
There exists an element 
\begin_inset Formula $\0\in V$
\end_inset

 such that 
\begin_inset Formula $\u+\0=\u$
\end_inset

 for all 
\begin_inset Formula $\u\in V$
\end_inset

 
\end_layout

\begin_layout Enumerate
For any 
\begin_inset Formula $\u\in V$
\end_inset

, there exists an element 
\begin_inset Formula $\v\in V$
\end_inset

 such that 
\begin_inset Formula $\u+\v=\0$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $a\cdot(b\cdot\u)=(a\cdot b)\cdot\u$
\end_inset

 for all 
\begin_inset Formula $a,b\in F$
\end_inset

 and 
\begin_inset Formula $\u\in V$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $1\cdot\u=\u$
\end_inset

 for all 
\begin_inset Formula $\u\in V$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $a\cdot(\u+\v)=(a\cdot\u)+(a\cdot\v)$
\end_inset

 for all 
\begin_inset Formula $a\in F$
\end_inset

 and 
\begin_inset Formula $\u,\v\in V$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $(a+b)\cdot\u=(a\cdot\u)+(b\cdot\u)$
\end_inset

 for all 
\begin_inset Formula $a,b\in F$
\end_inset

 and 
\begin_inset Formula $\u\in V$
\end_inset

 
\end_layout

\begin_layout Standard
Equivalently, a vector space is a module 
\begin_inset Formula $V$
\end_inset

 over a ring 
\begin_inset Formula $F$
\end_inset

 which is a field (or, more generally, a division ring).
\end_layout

\begin_layout Standard
The elements of 
\begin_inset Formula $V$
\end_inset

 are called 
\emph on
vectors
\emph default
, and the element 
\begin_inset Formula $\mathbf{0}\in V$
\end_inset

 is called the 
\emph on
zero vector
\emph default
 of 
\begin_inset Formula $V$
\end_inset

.
 
\end_layout

\begin_layout Chapter
Quotient Spaces
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $M$
\end_inset

 be a module over a ring 
\begin_inset Formula $R$
\end_inset

, and let 
\begin_inset Formula $S$
\end_inset

 be a submodule of 
\begin_inset Formula $M$
\end_inset

.
 The 
\emph on
quotient module
\emph default
 
\begin_inset Formula $M/S$
\end_inset

 is the quotient group 
\begin_inset Formula $M/S$
\end_inset

 with scalar multiplication defined by 
\begin_inset Formula $\lambda\left(x+S\right)=\lambda x+S$
\end_inset

 for all 
\begin_inset Formula $\lambda\in R$
\end_inset

 and all 
\begin_inset Formula $x\in M$
\end_inset

.
\end_layout

\begin_layout Standard
This is a well defined operation.
 Indeed, if 
\begin_inset Formula $x+S=x'+S$
\end_inset

 then for some 
\begin_inset Formula $s\in S$
\end_inset

 we have 
\begin_inset Formula $x'=x+s$
\end_inset

 and therefore 
\begin_inset Formula 
\begin{align*}
\lambda x' & =\lambda\left(x+S\right)\\
 & =\lambda x+\lambda s
\end{align*}

\end_inset

so that 
\begin_inset Formula $\lambda x'+S=\lambda x+\lambda s+S=\lambda x+S$
\end_inset

, since 
\begin_inset Formula $\lambda s\in S$
\end_inset

.
\end_layout

\begin_layout Standard
In the special case that 
\begin_inset Formula $R$
\end_inset

 is a field this construction defines the 
\emph on
quotient vector space
\emph default
 of a vector space by a vector subspace.
\end_layout

\begin_layout Chapter
Hamel Basis
\end_layout

\begin_layout Section
Existence of a Basis
\end_layout

\begin_layout Definition
A (
\series bold
Hamel
\series default
) basis of a vector space is a linearly independent spanning set.
\end_layout

\begin_layout Standard
It can be proved that any two bases of the same vector space must have the
 same cardinality.
 This introduces the notion of dimension of a vector space, which is precisely
 the cardinality of the basis, and is denoted by 
\begin_inset Formula $\dim\left(V\right)$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the vector space.
\end_layout

\begin_layout Standard
The fact that every vector space has a Hamel basis is an important consequence
 of the axiom of choice (in fact, that proposition is equivalent to the
 axiom of choice.)
\end_layout

\begin_layout Example
\begin_inset Formula $\beta=\left\{ e_{i}\right\} $
\end_inset

, 
\begin_inset Formula $1\le i\le n$
\end_inset

, is a basis for 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 (the 
\begin_inset Formula $n$
\end_inset

-dimensional vector space over the reals).
 For 
\begin_inset Formula $n=4$
\end_inset

,
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\beta=\left\{ \begin{pmatrix}1\\
0\\
0\\
0
\end{pmatrix},\,\begin{pmatrix}0\\
1\\
0\\
0
\end{pmatrix},\,\begin{pmatrix}0\\
0\\
1\\
0
\end{pmatrix},\,\begin{pmatrix}0\\
0\\
0\\
1
\end{pmatrix}\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
The next example is a familiar one from the set of polynomials.
\end_layout

\begin_layout Example
\begin_inset Formula $\beta=\left\{ 1,x,x^{2}\right\} $
\end_inset

 is a basis for the vector space of polynomials with degree at most 2, over
 a division ring.
 
\end_layout

\begin_layout Standard
Here is an example from a ring.
\end_layout

\begin_layout Example
The set 
\begin_inset Formula 
\[
\beta=\left\{ \begin{pmatrix}1 & 0\\
0 & 0
\end{pmatrix},\,\begin{pmatrix}0 & 1\\
0 & 0
\end{pmatrix},\,\begin{pmatrix}0 & 0\\
1 & 0
\end{pmatrix},\,\begin{pmatrix}0 & 0\\
0 & 1
\end{pmatrix}\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
is a basis for the vector space of 
\begin_inset Formula $2\times2$
\end_inset

 matrices over a division ring, and assuming that the characteristic of
 the ring is not 2, then so is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta'=\left\{ \begin{pmatrix}2 & 0\\
0 & 0
\end{pmatrix},\,\begin{pmatrix}0 & 1\\
0 & 0
\end{pmatrix},\,\begin{pmatrix}0 & 0\\
{\displaystyle \frac{1}{2}} & 0
\end{pmatrix},\,\begin{pmatrix}0 & 0\\
0 & 4
\end{pmatrix}\right\} .
\]

\end_inset


\series bold
Remark.

\series default
 The empty set is a basis for the trivial vector space which consists of
 the unique element 
\begin_inset Formula $0$
\end_inset

.
 
\end_layout

\begin_layout Standard
More generally, for any (left) right module 
\begin_inset Formula $M$
\end_inset

 over a ring 
\begin_inset Formula $R$
\end_inset

, one may define a (left) right basis for 
\begin_inset Formula $M$
\end_inset

 as a subset 
\begin_inset Formula $B$
\end_inset

 of 
\begin_inset Formula $M$
\end_inset

 such that 
\begin_inset Formula $B$
\end_inset

 spans 
\begin_inset Formula $M$
\end_inset

 and is linearly independent.
 However, unlike bases for a vector space, bases for a module may not have
 the same cardinality.
 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $V$
\end_inset

 be a vector space over a field 
\begin_inset Formula $\mathbb{F}$
\end_inset

.
 Every linearly independent subset of 
\begin_inset Formula $V$
\end_inset

 can be extended to a basis for 
\begin_inset Formula $V$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A$
\end_inset

 be a linearly independent subset of 
\begin_inset Formula $V$
\end_inset

.
 Let 
\begin_inset Formula $\mathscr{S}$
\end_inset

 be the collection of all linearly independent supersets of 
\begin_inset Formula $A$
\end_inset

.
 First, 
\begin_inset Formula $\mathscr{S}$
\end_inset

 is non-empty since 
\begin_inset Formula $A\in\mathscr{S}$
\end_inset

.
 In addition, if 
\begin_inset Formula $A_{1}\subseteq A_{2}\subseteq\cdots$
\end_inset

 is a chain of linearly independent supersets of 
\begin_inset Formula $A$
\end_inset

, then their union is again a linearly independent superset of 
\begin_inset Formula $A$
\end_inset

.
 
\end_layout

\begin_layout Proof
So by Zorn's Lemma, 
\begin_inset Formula $\mathscr{S}$
\end_inset

 has a maximal element 
\begin_inset Formula $B$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $W=\operatorname{span}(B)$
\end_inset

.
 If 
\begin_inset Formula $W\ne V$
\end_inset

, pick 
\begin_inset Formula $b\in V-W$
\end_inset

.
 If 
\begin_inset Formula 
\[
0=rb+r_{1}b_{1}+\cdots+r_{n}b_{n},
\]

\end_inset

 where 
\begin_inset Formula $b_{i}\in B$
\end_inset

, then 
\begin_inset Formula $-rb=r_{1}b_{1}+\cdots+r_{n}b_{n}$
\end_inset

, so that 
\begin_inset Formula $-rb\in\operatorname{span}(B)=W$
\end_inset

.
 But 
\begin_inset Formula $b\notin W$
\end_inset

, so 
\begin_inset Formula $b\ne0$
\end_inset

, which implies 
\begin_inset Formula $r=0$
\end_inset

.
 Consequently 
\begin_inset Formula $r_{1}=\cdots=r_{n}=0$
\end_inset

 since 
\begin_inset Formula $B$
\end_inset

 is linearly independent.
 As a result, 
\begin_inset Formula $B\cup\lbrace b\rbrace$
\end_inset

 is a linearly independent superset of 
\begin_inset Formula $B$
\end_inset

 in 
\begin_inset Formula $\mathscr{S}$
\end_inset

, contradicting the maximality of 
\begin_inset Formula $B$
\end_inset

 in 
\begin_inset Formula $\mathscr{S}$
\end_inset

.
 
\end_layout

\begin_layout Proposition
Every spanning set of 
\begin_inset Formula $V$
\end_inset

 has a subset that is a basis for 
\begin_inset Formula $V$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A$
\end_inset

 be a spanning set of 
\begin_inset Formula $V$
\end_inset

.
 Let 
\begin_inset Formula $\mathscr{S}$
\end_inset

 be the collection of all linearly independent subsets of 
\begin_inset Formula $A$
\end_inset

.
 
\begin_inset Formula $\mathscr{S}$
\end_inset

 is non-empty as 
\begin_inset Formula $\varnothing\in\mathscr{S}$
\end_inset

.
 Let 
\begin_inset Formula $A_{1}\subseteq A_{2}\subseteq\cdots$
\end_inset

 be a chain of linearly independent subsets of 
\begin_inset Formula $A$
\end_inset

.
 Then the union of these sets is again a linearly independent subset of
 
\begin_inset Formula $A$
\end_inset

.
 
\end_layout

\begin_layout Proof
Therefore, by Zorn's lemma, 
\begin_inset Formula $\mathscr{S}$
\end_inset

 has a maximal element 
\begin_inset Formula $B$
\end_inset

.
 In other words, 
\begin_inset Formula $B$
\end_inset

 is a linearly independent subset 
\begin_inset Formula $A$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $W=\operatorname{span}(B)$
\end_inset

.
 Suppose 
\begin_inset Formula $W\ne V$
\end_inset

.
 Since 
\begin_inset Formula $A$
\end_inset

 spans 
\begin_inset Formula $V$
\end_inset

, there is an element 
\begin_inset Formula $b\in A$
\end_inset

 not in 
\begin_inset Formula $W$
\end_inset

 (for otherwise the span of 
\begin_inset Formula $A$
\end_inset

 must lie in 
\begin_inset Formula $W$
\end_inset

, which would imply 
\begin_inset Formula $W=V$
\end_inset

).
 Then, using the same argument as in the previous proposition, 
\begin_inset Formula $B\cup\lbrace b\rbrace$
\end_inset

 is linearly independent, which contradicts the maximality of 
\begin_inset Formula $B$
\end_inset

 in 
\begin_inset Formula $\mathscr{S}$
\end_inset

.
 Therefore, 
\begin_inset Formula $B$
\end_inset

 spans 
\begin_inset Formula $V$
\end_inset

 and thus a basis for 
\begin_inset Formula $V$
\end_inset

.
 
\end_layout

\begin_layout Corollary
Every vector space has a basis.
 
\end_layout

\begin_layout Proof
Either take 
\begin_inset Formula $\varnothing$
\end_inset

 to be the linearly independent subset of 
\begin_inset Formula $V$
\end_inset

 and apply proposition 1, or take 
\begin_inset Formula $V$
\end_inset

 to be the spanning subset of 
\begin_inset Formula $V$
\end_inset

 and apply proposition 2.
 
\end_layout

\begin_layout Standard

\series bold
Remark
\series default
.
 The two propositions above can be combined into one: If 
\begin_inset Formula $A\subseteq C$
\end_inset

 are two subsets of a vector space 
\begin_inset Formula $V$
\end_inset

 such that 
\begin_inset Formula $A$
\end_inset

 is linearly independent and 
\begin_inset Formula $C$
\end_inset

 spans 
\begin_inset Formula $V$
\end_inset

, then there exists a basis 
\begin_inset Formula $B$
\end_inset

 for 
\begin_inset Formula $V$
\end_inset

, with 
\begin_inset Formula $A\subseteq B\subseteq C$
\end_inset

.
 The proof again relies on Zorn's Lemma and is left to the reader to try.
 
\end_layout

\begin_layout Section
Change of basis
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $V$
\end_inset

 be a vector space.
 Given a basis 
\begin_inset Formula $A$
\end_inset

 for 
\begin_inset Formula $V$
\end_inset

, each vector 
\begin_inset Formula $v\in V$
\end_inset

 can be uniquely expressed in terms of the base elements 
\begin_inset Formula $v_{i}\in A$
\end_inset

 as follows: 
\begin_inset Formula 
\[
v=\sum_{v_{i}\in A}r_{i}v_{i}
\]

\end_inset

where the sum is taken over a finite number of elements in 
\begin_inset Formula $A$
\end_inset

.
 Suppose now that 
\begin_inset Formula $B$
\end_inset

 is another basis for 
\begin_inset Formula $V$
\end_inset

.
 By a 
\emph on
change of basis
\emph default
 from 
\begin_inset Formula $A$
\end_inset

 to 
\begin_inset Formula $B$
\end_inset

 we mean re-expressing 
\begin_inset Formula $v$
\end_inset

 in terms of base elements 
\begin_inset Formula $w_{i}\in B$
\end_inset

.
\end_layout

\begin_layout Standard
Formally, we can think of a change of basis as the identity function (viewed
 as a linear operator) on a vector space 
\begin_inset Formula $V$
\end_inset

, such that elements in the domain are expressed in terms of 
\begin_inset Formula $A$
\end_inset

 and elements in the range are expressed in terms of 
\begin_inset Formula $B$
\end_inset

.
\end_layout

\begin_layout Standard
Note that, by the very design of a basis, a change of basis in a vector
 space is always possible.
\end_layout

\begin_layout Standard
Now, if 
\begin_inset Formula $V$
\end_inset

 has dimension 
\begin_inset Formula $n<\infty$
\end_inset

.
 We can total order bases 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 Then a change of basis (from 
\begin_inset Formula $A$
\end_inset

 to 
\begin_inset Formula $B$
\end_inset

) has the matrix representation 
\begin_inset Formula 
\[
\left[I\right]_{B}^{A},
\]

\end_inset

where 
\begin_inset Formula $I\,:\, V\to V$
\end_inset

 is the identity operator.
 
\begin_inset Formula $\left[I\right]_{B}^{A}$
\end_inset

 is called a 
\emph on
change of basis matrix
\emph default
.
 By applying 
\begin_inset Formula $\left[I\right]_{B}^{A}$
\end_inset

 to a vector 
\begin_inset Formula $v$
\end_inset

 expressed in terms of 
\begin_inset Formula $A$
\end_inset

, we get 
\begin_inset Formula $v$
\end_inset

 expressed in terms of 
\begin_inset Formula $B$
\end_inset

: 
\begin_inset Formula 
\[
\left[v\right]_{B}=\left[I\right]_{B}^{A}\left[v\right]_{A},
\]

\end_inset

where 
\begin_inset Formula $\left[v\right]_{A}$
\end_inset

 and 
\begin_inset Formula $\left[v\right]_{B}$
\end_inset

 are 
\begin_inset Formula $v$
\end_inset

 expressed in the two bases 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 respectively.
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $I$
\end_inset

 is obviously invertible, 
\begin_inset Formula $\left[I\right]_{B}^{A}$
\end_inset

 is invertible also, whose inverse is 
\begin_inset Formula $\left[I\right]_{B}^{A}$
\end_inset

.
 Furthermore, 
\begin_inset Formula $[I]_{A}=I_{n}$
\end_inset

 for any basis 
\begin_inset Formula $A$
\end_inset

.
 Here, 
\begin_inset Formula $I_{n}$
\end_inset

 is the identity matrix.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $V=\mathbf{R}^{3}$
\end_inset

 and the following two sets 
\begin_inset Formula 
\[
A=\left\{ \begin{pmatrix}1\\
-1\\
2
\end{pmatrix},\,\begin{pmatrix}0\\
1\\
1
\end{pmatrix},\,\begin{pmatrix}2\\
3\\
0
\end{pmatrix}\right\} \quad\mbox{ and}\quad B=\left\{ \begin{pmatrix}1\\
0\\
0
\end{pmatrix},\,\begin{pmatrix}0\\
1\\
0
\end{pmatrix},\,\begin{pmatrix}0\\
0\\
1
\end{pmatrix}\right\} 
\]

\end_inset

be the two ordered bases for 
\begin_inset Formula $V$
\end_inset

, ordered in the way the elements are arranged in the set.
 For each 
\begin_inset Formula $v_{i}\in A$
\end_inset

, 
\begin_inset Formula $I\left(v_{i}\right)=v_{i}=\left[v_{i}\right]_{E_{3}}$
\end_inset

, we see that
\begin_inset Formula 
\[
\left[I\right]_{B}^{A}=\begin{pmatrix}\begin{array}{rrr}
1 & 0 & 2\\
-1 & 1 & 3\\
2 & 1 & 0
\end{array}\end{pmatrix}
\]

\end_inset

Notice that the columns of 
\begin_inset Formula $\left[I\right]_{B}^{A}$
\end_inset

 are exactly the elements of 
\begin_inset Formula $A$
\end_inset

.
 Indeed, each element of 
\begin_inset Formula $A$
\end_inset

 is 
\emph on
already
\emph default
 written in terms of the standard basis elements (in 
\begin_inset Formula $B$
\end_inset

).
 For example, let 
\begin_inset Formula $v$
\end_inset

 be the first basis element in 
\begin_inset Formula $A$
\end_inset

.
 Let us see what 
\begin_inset Formula $[v]_{A}$
\end_inset

 is, when expressed using base elements in 
\begin_inset Formula $B$
\end_inset

, the standard ordered basis: 
\begin_inset Formula 
\[
\left[v\right]_{B}=\left[I\right]_{B}^{A}\left[v\right]_{A}=\begin{pmatrix}\begin{array}{rrr}
1 & 0 & 2\\
-1 & 1 & 3\\
2 & 1 & 0
\end{array}\end{pmatrix}\left[v\right]_{A}=\begin{pmatrix}\begin{array}{rrr}
1 & 0 & 2\\
-1 & 1 & 3\\
2 & 1 & 0
\end{array}\end{pmatrix}\begin{pmatrix}1\\
0\\
0
\end{pmatrix}=\begin{pmatrix}\begin{array}{r}
1\\
-1\\
2
\end{array}\end{pmatrix},
\]

\end_inset

exactly as we have expected.
\end_layout

\begin_layout Standard
Conversely, let 
\begin_inset Formula $w$
\end_inset

 be the first basis element in 
\begin_inset Formula $B$
\end_inset

.
 What is 
\begin_inset Formula $w$
\end_inset

 when expressed in terms of basis elements of 
\begin_inset Formula $A$
\end_inset

? In other words, we need to find 
\begin_inset Formula 
\[
\left[w\right]_{A}=\left[I\right]_{A}^{B}\left[w\right]_{B}.
\]

\end_inset

Now, 
\begin_inset Formula $\left[w\right]_{B}$
\end_inset

 is just 
\begin_inset Formula $\begin{pmatrix}1\\
0\\
0
\end{pmatrix}$
\end_inset

, so 
\begin_inset Formula $\left[w\right]_{A}$
\end_inset

 is nothing more than the first column of 
\begin_inset Formula $\left[I\right]_{A}^{B}$
\end_inset

, which is just the inverse of the matrix 
\begin_inset Formula $\left[I\right]_{A}^{B}$
\end_inset

, so 
\begin_inset Formula 
\[
\left[I\right]_{A}^{B}=\left(\left[I\right]_{A}^{B}\right)^{-1}=\begin{pmatrix}1 & 0 & 2\\
-1 & 1 & 3\\
2 & 1 & 0
\end{pmatrix}^{-1}=\begin{pmatrix}\begin{array}{rrr}
{\displaystyle \frac{1}{3}} & -{\displaystyle \frac{2}{9}} & {\displaystyle \frac{2}{9}}\\
-{\displaystyle \frac{2}{3}} & {\displaystyle \frac{4}{9}} & {\displaystyle \frac{5}{9}}\\
{\displaystyle \frac{1}{3}} & {\displaystyle \frac{1}{9}} & -{\displaystyle \frac{1}{9}}
\end{array}\end{pmatrix}.
\]

\end_inset

Therefore, 
\begin_inset Formula $\left[w\right]_{A}=\begin{pmatrix}{\displaystyle \frac{1}{3}}\\
-{\displaystyle \frac{2}{3}}\\
{\displaystyle \frac{1}{3}}
\end{pmatrix}$
\end_inset

.
 A quick verification shows that this is indeed the case: 
\begin_inset Formula 
\[
\begin{pmatrix}1\\
0\\
0
\end{pmatrix}=\frac{1}{3}\begin{pmatrix}1\\
-1\\
2
\end{pmatrix}-\frac{2}{3}\begin{pmatrix}0\\
1\\
1
\end{pmatrix}+\frac{1}{3}\begin{pmatrix}2\\
3\\
0
\end{pmatrix}.
\]

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $C$
\end_inset

 be the set 
\begin_inset Formula 
\[
\left\{ \begin{pmatrix}1\\
0\\
2
\end{pmatrix},\,\begin{pmatrix}0\\
1\\
1
\end{pmatrix},\,\begin{pmatrix}2\\
1\\
0
\end{pmatrix}\right\} .
\]

\end_inset

 It is easy to check that 
\begin_inset Formula $C$
\end_inset

 forms a basis for 
\begin_inset Formula $\mathbf{R}^{3}$
\end_inset

 (determinant is non-zero).
 Order 
\begin_inset Formula $C$
\end_inset

 in the obvious manner.
 What is the change of basis matrix 
\begin_inset Formula $\left[I\right]_{A}^{C}$
\end_inset

? 
\end_layout

\begin_layout Standard
One way is to express each element of 
\begin_inset Formula $C$
\end_inset

 in terms of the elements of 
\begin_inset Formula $A$
\end_inset

.
 Another way is to use the formula 
\begin_inset Formula $\left[I\right]_{A}^{C}=\left[I\right]_{A}^{B}\left[I\right]_{B}^{C}$
\end_inset

.
 Applying the first example, we see that 
\begin_inset Formula $\left[I\right]_{B}^{C}$
\end_inset

 is just the matrix whose columns are elements of 
\begin_inset Formula $C$
\end_inset

.
 As a result: 
\begin_inset Formula 
\[
\left[I\right]_{A}^{C}=\left[I\right]_{A}^{B}\left[I\right]_{B}^{C}=\begin{pmatrix}\begin{array}{rrr}
{\displaystyle \frac{1}{3}} & -{\displaystyle \frac{2}{9}} & {\displaystyle \frac{2}{9}}\\
-{\displaystyle \frac{2}{3}} & {\displaystyle \frac{4}{9}} & {\displaystyle \frac{5}{9}}\\
{\displaystyle \frac{1}{3}} & {\displaystyle \frac{1}{9}} & -{\displaystyle \frac{1}{9}}
\end{array}\end{pmatrix}\begin{pmatrix}1 & 0 & 2\\
0 & 1 & 1\\
2 & 1 & 0
\end{pmatrix}=\begin{pmatrix}7/9 & 0 & 4/9\\
4/9 & 1 & -8/9\\
1/9 & 0 & 7/9
\end{pmatrix}.
\]

\end_inset


\end_layout

\begin_layout Standard

\series bold
Remark.

\series default
 Let us summarize what we have learned from the examples above, as well
 as list some additional facts.
 Let 
\begin_inset Formula $V$
\end_inset

 be a finite dimensional vector space of dimension 
\begin_inset Formula $n$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $E$
\end_inset

 is the standard basis (ordered), then for any ordered basis 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $\left[I\right]_{E}^{A}$
\end_inset

 is the matrix whose columns are exactly the basis elements in 
\begin_inset Formula $A$
\end_inset

 (assuming these elements have already been expressed in terms of 
\begin_inset Formula $E$
\end_inset

) such that the 
\begin_inset Formula $i$
\end_inset

-column corresponds to the 
\begin_inset Formula $i$
\end_inset

-th element in the ordered set 
\begin_inset Formula $A$
\end_inset

.
 
\end_layout

\begin_layout Itemize
This also means that every invertible matrix 
\begin_inset Formula $A$
\end_inset

 corresponds to (in a one-to-one fashion) a change of basis from the basis
 
\begin_inset Formula $S_{A}$
\end_inset

 whose elements are columns of 
\begin_inset Formula $A$
\end_inset

 to 
\begin_inset Formula $E$
\end_inset

, the standard basis: 
\begin_inset Formula $A=\left[I\right]_{E}^{S_{A}}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Continue to assume that 
\begin_inset Formula $E$
\end_inset

 is the standard basis.
 Let 
\begin_inset Formula $A,B$
\end_inset

 be any ordered bases for 
\begin_inset Formula $V$
\end_inset

.
 Using the above property, we can easily compute 
\begin_inset Formula $\left[I\right]_{B}^{A}$
\end_inset

, which is 
\begin_inset Formula $\left[I\right]_{B}^{E}\left[I\right]_{E}^{A}=\left(\left[I\right]_{E}^{B}\right)^{-1}\left[I\right]_{E}^{A}.$
\end_inset

 
\end_layout

\begin_layout Itemize
Let 
\begin_inset Formula $A'$
\end_inset

 be a re-ordering of the ordered basis 
\begin_inset Formula $A$
\end_inset

, where each 
\begin_inset Formula $v'_{i}\in A'$
\end_inset

 is just 
\begin_inset Formula $v_{\pi(i)}$
\end_inset

 for some permutation in 
\begin_inset Formula $S_{n}$
\end_inset

.
 Then 
\begin_inset Formula $\left[I\right]_{A}^{A'}$
\end_inset

 is the permutation matrix corresponding to the permutation 
\begin_inset Formula $\pi$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Suppose 
\begin_inset Formula $T$
\end_inset

 is a linear transformation from 
\begin_inset Formula $V$
\end_inset

 to 
\begin_inset Formula $W$
\end_inset

 (both finite dimensional).
 Under a bases 
\begin_inset Formula $A\subset V$
\end_inset

 and 
\begin_inset Formula $B\subset W$
\end_inset

, 
\begin_inset Formula $T$
\end_inset

 has matrix representation 
\begin_inset Formula $\left[T\right]_{B}^{A}$
\end_inset

.
 Under changes of basis from 
\begin_inset Formula $A$
\end_inset

 to 
\begin_inset Formula $A'$
\end_inset

, and 
\begin_inset Formula $B$
\end_inset

 to 
\begin_inset Formula $B'$
\end_inset

, we have 
\begin_inset Formula 
\[
\left[T\right]_{B'}^{A'}=\left[I\, T\, I\right]_{B'}^{A'}=\left[I\right]_{B}^{B'}\left[T\right]_{B}^{A}\left[I\right]_{A}^{A'}.
\]

\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $T$
\end_inset

 is a linear operator on 
\begin_inset Formula $V$
\end_inset

, then setting 
\begin_inset Formula $V=W$
\end_inset

, 
\begin_inset Formula $A=B$
\end_inset

 and 
\begin_inset Formula $A'=B'$
\end_inset

 from above, we have that 
\begin_inset Formula 
\[
\left[T\right]_{A'}=P^{-1}\left[T\right]_{A}P,
\]

\end_inset

where 
\begin_inset Formula $P$
\end_inset

 is the change of basis matrix 
\begin_inset Formula $\left[I\right]_{A}^{A'}$
\end_inset

.
 This shows that 
\begin_inset Formula $\left[T\right]_{A}$
\end_inset

 and 
\begin_inset Formula $\left[T\right]_{A'}$
\end_inset

 are similar matrices.
 In other words, under a change of basis, the linear transformation 
\begin_inset Formula $T$
\end_inset

 is basically the same.
 
\end_layout

\begin_layout Chapter
Rank Nullity Theorem
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
Img}{
\backslash
mathop{
\backslash
mathrm{Img}}}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
Ker}{
\backslash
mathop{
\backslash
mathrm{Ker}}}
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
The sum of the rank and the nullity of a linear mapping gives the dimension
 of the mapping's domain.
 More precisely, let 
\begin_inset Formula $T\,:\, V\longrightarrow W$
\end_inset

 be a linear mapping.
 If 
\begin_inset Formula $V$
\end_inset

 is a finite-dimensional, then 
\begin_inset Formula 
\[
\dim V=\dim\mathop{\mathrm{Ker}}T+\dim\mathop{\mathrm{Img}}T.
\]

\end_inset


\end_layout

\begin_layout Standard
The intuitive content of the Rank-Nullity theorem is the principle that
 
\end_layout

\begin_layout Quote
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 Every independent linear constraint takes away one degree of freedom.
 
\end_layout

\begin_layout Standard
The rank is just the number of independent linear constraints on 
\begin_inset Formula $v\in V$
\end_inset

 imposed by the equation 
\begin_inset Formula 
\[
T(v)=0.
\]

\end_inset

The dimension of 
\begin_inset Formula $V$
\end_inset

 is the number of unconstrained degrees of freedom.
 The nullity is the degrees of freedom in the resulting space of solutions.
 To put it yet another way: 
\end_layout

\begin_layout Quote
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 The number of variables 
\series bold
minus
\series default
 the number of independent linear constraints 
\series bold
equals
\series default
 the number of linearly independent solutions.
 
\end_layout

\begin_layout Proof
The images of a basis of 
\begin_inset Formula $V$
\end_inset

 will span 
\begin_inset Formula $\Img T$
\end_inset

, and hence 
\begin_inset Formula $\Img T$
\end_inset

 is finite-dimensional.
 Choose then a basis 
\begin_inset Formula $w_{1},\ldots,w_{n}$
\end_inset

 of 
\begin_inset Formula $\Img T$
\end_inset

 and choose preimages 
\begin_inset Formula $v_{1},\ldots,v_{n}\in U$
\end_inset

 such that 
\begin_inset Formula 
\[
w_{i}=T(v_{i}),\quad i=1\ldots n
\]

\end_inset

Choose a basis 
\begin_inset Formula $u_{1},\ldots,u_{k}$
\end_inset

 of 
\begin_inset Formula $\Ker T$
\end_inset

.
 The result will follow once we show that 
\begin_inset Formula $u_{1},\ldots,u_{k},v_{1},\ldots,v_{n}$
\end_inset

 is a basis of 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $v\in V$
\end_inset

 be given.
 Since 
\begin_inset Formula $T(v)\in\Img T$
\end_inset

, by definition, we can choose scalars 
\begin_inset Formula $b_{1},\ldots,b_{n}$
\end_inset

 such that 
\begin_inset Formula 
\[
T(v)=b_{1}w_{1}+\cdots+b_{n}w_{n}.
\]

\end_inset

Linearity of 
\begin_inset Formula $T$
\end_inset

 now implies that 
\begin_inset Formula $T(b_{1}v_{1}+\ldots+b_{n}v_{n}-v)=0,$
\end_inset

 and hence we can choose scalars 
\begin_inset Formula $a_{1},\ldots,a_{k}$
\end_inset

 such that 
\begin_inset Formula 
\[
b_{1}v_{1}+\ldots+b_{n}v_{n}-v=a_{1}u_{1}+\cdots+a_{k}u_{k}.
\]

\end_inset

Therefore 
\begin_inset Formula $u_{1},\ldots,u_{k},v_{1},\ldots,v_{n}$
\end_inset

 span 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Proof
Next, let 
\begin_inset Formula $a_{1},\ldots,a_{k},b_{1},\ldots,b_{n}$
\end_inset

 be scalars such that 
\begin_inset Formula 
\[
a_{1}u_{1}+\cdots+a_{k}u_{k}+b_{1}v_{1}+\cdots+b_{n}v_{n}=0.
\]

\end_inset

By applying 
\begin_inset Formula $T$
\end_inset

 to both sides of this equation it follows that 
\begin_inset Formula 
\[
b_{1}w_{1}+\cdots+b_{n}w_{n}=0,
\]

\end_inset

and since 
\begin_inset Formula $w_{1},\ldots,w_{n}$
\end_inset

 are linearly independent that 
\begin_inset Formula 
\[
b_{1}=b_{2}=\cdots=b_{n}=0.
\]

\end_inset

Consequently 
\begin_inset Formula 
\[
a_{1}u_{1}+\cdots+a_{k}u_{k}=0
\]

\end_inset

as well, and since 
\begin_inset Formula $u_{1},\ldots,u_{k}$
\end_inset

 are also assumed to be linearly independent we conclude that 
\begin_inset Formula 
\[
a_{1}=a_{2}=\cdots=a_{k}=0
\]

\end_inset

also.
 Therefore 
\begin_inset Formula $u_{1},\ldots,u_{k},v_{1},\ldots,v_{n}$
\end_inset

 are linearly independent, and are therefore a basis.
 
\end_layout

\begin_layout Chapter
Dual Spaces
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\B}{\mathcal{B}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\Bstar}{\mathcal{B}^{\ast}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\Vstar}{V^{\ast}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\Vstarstar}{V^{\ast\ast}}
\end_inset


\end_layout

\begin_layout Section
Dual of a vector space; dual bases
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $V$
\end_inset

 be a vector space over a field 
\begin_inset Formula $k$
\end_inset

.
 The 
\emph on
dual
\emph default
 of 
\begin_inset Formula $V$
\end_inset

, denoted by 
\begin_inset Formula $\Vstar$
\end_inset

, is the vector space of linear forms on 
\begin_inset Formula $V$
\end_inset

, i.e.
 linear mappings 
\begin_inset Formula $V\to k$
\end_inset

.
 The operations in 
\begin_inset Formula $\Vstar$
\end_inset

 are defined pointwise: 
\begin_inset Formula 
\[
(\varphi+\psi)(v)=\varphi(v)+\psi(v)
\]

\end_inset


\begin_inset Formula 
\[
(\lambda\varphi)(v)=\lambda\varphi(v)
\]

\end_inset

for 
\begin_inset Formula $\lambda\in K$
\end_inset

, 
\begin_inset Formula $v\in V$
\end_inset

 and 
\begin_inset Formula $\varphi,\psi\in\Vstar$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $V$
\end_inset

 is isomorphic to 
\begin_inset Formula $\Vstar$
\end_inset

 if and only if the dimension of 
\begin_inset Formula $V$
\end_inset

 is finite.
 If not, then 
\begin_inset Formula $\Vstar$
\end_inset

 has a larger (infinite) dimension than 
\begin_inset Formula $V$
\end_inset

; in other words, the cardinal of any basis of 
\begin_inset Formula $\Vstar$
\end_inset

 is strictly greater than the cardinal of any basis of 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Standard
Even when 
\begin_inset Formula $V$
\end_inset

 is finite-dimensional, there is no canonical or natural isomorphism 
\begin_inset Formula $V\longrightarrow\Vstar$
\end_inset

.
 But on the other hand, a basis 
\begin_inset Formula $\B$
\end_inset

 of 
\begin_inset Formula $V$
\end_inset

 does define a basis 
\begin_inset Formula $\Bstar$
\end_inset

 of 
\begin_inset Formula $\Vstar$
\end_inset

, and moreover a bijection 
\begin_inset Formula $\B\longrightarrow\Bstar$
\end_inset

.
 For suppose 
\begin_inset Formula $\B=\left\{ b_{1},\dots,b_{n}\right\} $
\end_inset

.
 For each 
\begin_inset Formula $i$
\end_inset

 from 
\begin_inset Formula $1$
\end_inset

 to 
\begin_inset Formula $n$
\end_inset

, define a mapping 
\begin_inset Formula 
\[
\beta_{i}\,:\, V\longrightarrow k
\]

\end_inset

by 
\begin_inset Formula 
\[
\beta_{i}\left(\sum_{k}x_{k}b_{k}\right))=x_{i}.
\]

\end_inset

It is easy to see that the 
\begin_inset Formula $\beta_{i}$
\end_inset

 are nonzero elements of 
\begin_inset Formula $\Vstar$
\end_inset

 and are independent.
 Thus 
\begin_inset Formula $\left\{ \beta_{1},\dots,\beta_{n}\right\} $
\end_inset

 is a basis of 
\begin_inset Formula $\Vstar$
\end_inset

, called the dual basis of 
\begin_inset Formula $\B$
\end_inset

.
\end_layout

\begin_layout Standard
The dual of 
\begin_inset Formula $\Vstar$
\end_inset

 is called the 
\emph on
second dual
\emph default
 or 
\emph on
bidual
\emph default
 of 
\begin_inset Formula $V$
\end_inset

.
 There 
\emph on
is
\emph default
 a very simple canonical injection 
\begin_inset Formula $V\longrightarrow\Vstarstar$
\end_inset

, and it is an isomorphism if the dimension of 
\begin_inset Formula $V$
\end_inset

 is finite.
 To see it, let 
\begin_inset Formula $x$
\end_inset

 be any element of 
\begin_inset Formula $V$
\end_inset

 and define a mapping 
\begin_inset Formula $x'\,:\,\Vstar\longrightarrow k$
\end_inset

 simply by 
\begin_inset Formula 
\[
x'(\phi)=\phi(x).
\]

\end_inset


\begin_inset Formula $x'$
\end_inset

 is linear by definition, and it is readily verified that the mapping 
\begin_inset Formula $x\longmapsto x'$
\end_inset

 from 
\begin_inset Formula $V$
\end_inset

 to 
\begin_inset Formula $\Vstarstar$
\end_inset

 is linear and injective.
\end_layout

\begin_layout Standard

\series bold
Dual of a topological vector space
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $V$
\end_inset

 is a topological vector space, the 
\emph on
continuous dual
\emph default
 
\begin_inset Formula $V^{\prime}$
\end_inset

 of 
\begin_inset Formula $V$
\end_inset

 is the subspace of 
\begin_inset Formula $\Vstar$
\end_inset

 consisting of the 
\emph on
continuous
\emph default
 linear forms.
\end_layout

\begin_layout Standard
A 
\emph on
normed
\emph default
 vector space 
\begin_inset Formula $V$
\end_inset

 is said to be 
\emph on
reflexive
\emph default
 if the natural embedding 
\begin_inset Formula $V\longrightarrow V^{\prime\prime}$
\end_inset

 is an isomorphism.
 For example, any finite dimensional space is reflexive, and any Hilbert
 space is reflexive by the Riesz representation theorem.
\end_layout

\begin_layout Standard

\series bold
Remarks.
\end_layout

\begin_layout Standard
Linear forms are also known as linear functionals.
\end_layout

\begin_layout Standard
Another way in which a linear mapping 
\begin_inset Formula $V\longrightarrow\Vstar$
\end_inset

 can arise is via a bilinear form 
\begin_inset Formula 
\[
V\times V\longrightarrow k.
\]

\end_inset

The notions of duality extend, in part, from vector spaces to modules, especiall
y free modules over commutative rings.
\end_layout

\begin_layout Chapter
Projections
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\adj}{^{{\displaystyle \star}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\img}{\mathop{\mathrm{img}}\nolimits}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\reals}{\mathbb{\mathbf{R}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\natnums}{\mathbb{\mathbf{N}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\cnums}{\mathbb{\mathbf{C}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\znums}{\mathbb{\mathbf{Z}}}
\end_inset


\end_layout

\begin_layout Definition
A linear transformation 
\begin_inset Formula $P\,:\, V\longrightarrow V$
\end_inset

 of a vector space 
\begin_inset Formula $V$
\end_inset

 is called a 
\emph on
projection
\emph default
 if it acts like the identity on its image.
 This condition can be more succinctly expressed by the equation 
\begin_inset Formula 
\begin{equation}
P^{2}=P.\label{eq:proj}
\end{equation}

\end_inset


\end_layout

\begin_layout Proposition
If 
\begin_inset Formula $P\,\colon\, V\longrightarrow V$
\end_inset

 is a projection, then its image and the kernel are complementary subspaces,
 namely 
\begin_inset Formula 
\begin{equation}
V=\ker P\oplus\img P.\label{eq:comp}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Suppose that 
\begin_inset Formula $P$
\end_inset

 is a projection.
 Let 
\begin_inset Formula $v\in V$
\end_inset

 be given, and set 
\begin_inset Formula 
\[
u=v-Pv.
\]

\end_inset

The projection condition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:proj"

\end_inset

 then implies that 
\begin_inset Formula $u\in\ker P$
\end_inset

, and we can write 
\begin_inset Formula $v$
\end_inset

 as the sum of an image and kernel vectors: 
\begin_inset Formula 
\[
v=u+Pv.
\]

\end_inset

This decomposition is unique, because the intersection of the image and
 the kernel is the trivial subspace.
 Indeed, suppose that 
\begin_inset Formula $v\in V$
\end_inset

 is in both the image and the kernel of 
\begin_inset Formula $P$
\end_inset

.
 Then, 
\begin_inset Formula $Pv=v$
\end_inset

 and 
\begin_inset Formula $Pv=0$
\end_inset

, and hence 
\begin_inset Formula $v=0$
\end_inset

.
\end_layout

\begin_layout Standard
Conversely, every direct sum decomposition 
\begin_inset Formula 
\[
V=V_{1}\oplus V_{2}
\]

\end_inset

corresponds to a projection 
\begin_inset Formula $P\,\colon\, V\longrightarrow V$
\end_inset

 defined by 
\begin_inset Formula 
\[
Pv=\begin{cases}
v & \textrm{if }v\in V_{1}\\
0 & \textrm{if }v\in V_{2}.
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
Specializing somewhat, suppose that the ground field is 
\begin_inset Formula $\reals$
\end_inset

 or 
\begin_inset Formula $\cnums$
\end_inset

 and that 
\begin_inset Formula $V$
\end_inset

 is equipped with a positive-definite inner product.
 In this setting we call an endomorphism 
\begin_inset Formula $P\,\colon\, V\longrightarrow V$
\end_inset

 an 
\emph on
orthogonal projection
\emph default
 if it is self-dual 
\begin_inset Formula 
\[
P\adj=P,
\]

\end_inset

in addition to satisfying the projection condition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:proj"

\end_inset

.
\end_layout

\begin_layout Proposition
The kernel and image of an orthogonal projection are orthogonal subspaces.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $u\in\ker P$
\end_inset

 and 
\begin_inset Formula $v\in\img P$
\end_inset

 be given.
 Since 
\begin_inset Formula $P$
\end_inset

 is self-dual we have 
\begin_inset Formula 
\[
0=\langle Pu,v\rangle=\langle u,Pv\rangle=\langle u,v\rangle.
\]

\end_inset


\end_layout

\begin_layout Standard
Thus we see that a orthogonal projection 
\begin_inset Formula $P$
\end_inset

 projects a 
\begin_inset Formula $v\in V$
\end_inset

 onto 
\begin_inset Formula $Pv$
\end_inset

 in an orthogonal fashion, i.e.
 
\begin_inset Formula 
\[
\langle v-Pv,u\rangle=0
\]

\end_inset

for all 
\begin_inset Formula $u\in\img P$
\end_inset

.
\end_layout

\begin_layout Chapter
Linear Operators
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\Ker}{\operatorname{Ker}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\Im}{\operatorname{Im}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\Hom}{\operatorname{Hom}}
\end_inset


\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $V$
\end_inset

 and 
\begin_inset Formula $W$
\end_inset

 be vector spaces over the same field 
\begin_inset Formula $F$
\end_inset

.
 A 
\emph on
linear transformation
\emph default
 is a function 
\begin_inset Formula $T\,\colon\, V\longrightarrow W$
\end_inset

 such that: 
\end_layout

\begin_layout Itemize
\begin_inset Formula $T(v+w)=T(v)+T(w)$
\end_inset

 for all 
\begin_inset Formula $v,w\in V$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $T(\lambda v)=\lambda T(v)$
\end_inset

 for all 
\begin_inset Formula $v\in V$
\end_inset

, and 
\begin_inset Formula $\lambda\in F$
\end_inset

 
\end_layout

\begin_layout Standard
The set of all linear maps 
\begin_inset Formula $V\longrightarrow W$
\end_inset

 is denoted by 
\begin_inset Formula $\Hom_{F}(V,W)$
\end_inset

 or 
\begin_inset Formula $\mathscr{L}(V,W)$
\end_inset

.
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $V=\mathbf{R}^{n}$
\end_inset

 and 
\begin_inset Formula $W=\mathbf{R}^{m}$
\end_inset

 and 
\begin_inset Formula $A$
\end_inset

 is any 
\begin_inset Formula $m\times n$
\end_inset

 matrix.
 Then the function 
\begin_inset Formula $L_{A}\,\colon\, V\longrightarrow W$
\end_inset

 defined by 
\begin_inset Formula $L_{A}(v)=Av$
\end_inset

, the multiplication of matrix 
\begin_inset Formula $A$
\end_inset

 and the vector 
\begin_inset Formula $v$
\end_inset

 (considered as an 
\begin_inset Formula $n\times1$
\end_inset

 matrix), is a linear transformation.
 
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $V$
\end_inset

 be the space of all differentiable functions over 
\begin_inset Formula $\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $W$
\end_inset

 the space of all continuous functions over 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 Then 
\begin_inset Formula $D\,\colon\, V\longrightarrow W$
\end_inset

 defined by 
\begin_inset Formula $D(f)=f'$
\end_inset

, the derivative of 
\begin_inset Formula $f$
\end_inset

, is a linear transformation.
 
\end_layout

\begin_layout Section*
Properties
\end_layout

\begin_layout Itemize
\begin_inset Formula $T(0)=0$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $S$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

 are linear transformations from 
\begin_inset Formula $V$
\end_inset

 to 
\begin_inset Formula $W$
\end_inset

, and 
\begin_inset Formula $k\in F$
\end_inset

, then so are 
\begin_inset Formula $S+T$
\end_inset

 and 
\begin_inset Formula $kT$
\end_inset

.
 As a result, 
\begin_inset Formula $\Hom_{F}(V,W)$
\end_inset

 is a vector space over F.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $G\colon W\longrightarrow U$
\end_inset

 is a linear transformations then 
\begin_inset Formula $G\circ T\colon V\longrightarrow U$
\end_inset

 is also a linear transformation.
 
\end_layout

\begin_layout Itemize
The kernel 
\begin_inset Formula $\Ker(T)=\left\{ v\in V\,\colon\, T(v)=0\right\} $
\end_inset

 is a subspace of 
\begin_inset Formula $V$
\end_inset

.
 
\end_layout

\begin_layout Itemize
The image 
\begin_inset Formula $\Im(T)=\left\{ T(v)\,\colon\, v\in V\right\} $
\end_inset

 is a subspace of 
\begin_inset Formula $W$
\end_inset

.
 
\end_layout

\begin_layout Itemize
The inverse image 
\begin_inset Formula $T^{-1}(w)$
\end_inset

 is a subspace if and only if 
\begin_inset Formula $w=0$
\end_inset

.
 
\end_layout

\begin_layout Itemize
A linear transformation is injective if and only if 
\begin_inset Formula $\Ker(T)=\{0\}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $v\in V$
\end_inset

 then 
\begin_inset Formula $T^{-1}(T(v))=v+\Ker(T)$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $w\in\Im(T)$
\end_inset

 then 
\begin_inset Formula $T(T^{-1}(w))=\{w\}$
\end_inset

.
 
\end_layout

\begin_layout Standard

\series bold
Remark.

\series default
 A linear transformation 
\begin_inset Formula $T\,\colon\, V\longrightarrow W$
\end_inset

 such that 
\begin_inset Formula $W=V$
\end_inset

 is called a 
\emph on
linear operator
\emph default
, and a 
\emph on
linear functional
\emph default
 when 
\begin_inset Formula $W=F$
\end_inset

.
 
\end_layout

\begin_layout Chapter
Determinants
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\supth}{^{\text{th}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\mM}{\mathbf{M}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\be}{\mathbf{e}}
\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\mM=(M_{ij})$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix with entries in a field 
\begin_inset Formula $\mathbb{F}$
\end_inset

.
 The matrix 
\begin_inset Formula $\mM$
\end_inset

 is really the same thing as a list of 
\begin_inset Formula $n$
\end_inset

 column vectors of size 
\begin_inset Formula $n$
\end_inset

.
 Consequently, the determinant operation may be regarded as a mapping 
\begin_inset Formula 
\[
\det:\overbrace{\mathbb{F}^{n}\times\ldots\times\mathbb{F}^{n}}^{n\mbox{ times}}\rightarrow\mathbb{F}
\]

\end_inset

The determinant of a matrix 
\begin_inset Formula $\mM$
\end_inset

 is then defined to be 
\begin_inset Formula $\det(\mM_{1},\ldots,\mM_{n}),$
\end_inset

 where 
\begin_inset Formula $\mM_{j}\in\mathbb{F}^{n}$
\end_inset

 denotes the 
\begin_inset Formula $j\supth$
\end_inset

 column of 
\begin_inset Formula $\mM$
\end_inset

.
\end_layout

\begin_layout Standard
Starting with the definition 
\begin_inset Formula 
\begin{equation}
\det(\mM_{1},\ldots,\mM_{n})=\sum_{\pi\in S_{n}}\mathrm{sgn}(\pi)M_{1\pi_{1}}M_{2\pi_{2}}\cdots M_{n\pi_{n}}\label{eq:detdef}
\end{equation}

\end_inset

the following properties are easily established: 
\end_layout

\begin_layout Enumerate
the determinant is multilinear; 
\end_layout

\begin_layout Enumerate
the determinant is anti-symmetric; 
\end_layout

\begin_layout Enumerate
the determinant of the identity matrix is 
\begin_inset Formula $1$
\end_inset

.
 
\end_layout

\begin_layout Standard
These three properties uniquely characterize the determinant, and indeed
 can --- some would say should --- be used as the definition of the determinant
 operation.
\end_layout

\begin_layout Standard
Let us prove this.
 We proceed by representing elements of 
\begin_inset Formula $\mathbb{F}^{n}$
\end_inset

 as linear combinations of 
\begin_inset Formula 
\[
\be_{1}=\begin{pmatrix}1\\
0\\
0\\
\vdots\\
0
\end{pmatrix},\quad\be_{2}=\begin{pmatrix}0\\
1\\
0\\
\vdots\\
0
\end{pmatrix},\quad\ldots\quad\be_{n}=\begin{pmatrix}0\\
0\\
0\\
\vdots\\
1
\end{pmatrix},
\]

\end_inset

the standard basis of 
\begin_inset Formula $\mathbb{F}^{n}$
\end_inset

.
 Let 
\begin_inset Formula $\mM$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix.
 The 
\begin_inset Formula $j\supth$
\end_inset

 column is represented as 
\begin_inset Formula $\sum_{i}M_{ij}\be_{i}$
\end_inset

; whence using multilinearity 
\begin_inset Formula 
\begin{align*}
\det(\mM) & =\det\sum_{i}M_{i1}\be_{i}\,,\sum_{i}M_{i2}\be_{i}\,,\;\ldots\;,\sum_{i}M_{in}\be_{i}\\
 & =\sum_{i_{1},\ldots,i_{n}=1}^{n}M_{i_{1}1}M_{i_{2}2}\cdots M_{i_{n}n}\det(\be_{i_{1}},\be_{i_{2}},\ldots,\be_{i_{n}})
\end{align*}

\end_inset

The anti-symmetry assumption implies that the expressions 
\begin_inset Formula $\det(\be_{i_{1}},\be_{i_{2}},\ldots,\be_{i_{n}})$
\end_inset

 vanish if any two of the indices 
\begin_inset Formula $i_{1},\ldots,i_{n}$
\end_inset

 coincide.
 If all 
\begin_inset Formula $n$
\end_inset

 indices are distinct, 
\begin_inset Formula 
\[
\det(\be_{i_{1}},\be_{i_{2}},\ldots,\be_{i_{n}})=\pm\det(\be_{1},\ldots,\be_{n}),
\]

\end_inset

the sign in the above expression being determined by the number of transposition
s required to rearrange the list 
\begin_inset Formula $(i_{1},\ldots,i_{n})$
\end_inset

 into the list 
\begin_inset Formula $(1,\ldots,n)$
\end_inset

.
 The sign is therefore the parity of the permutation 
\begin_inset Formula $(i_{1},\ldots,i_{n})$
\end_inset

.
 Since we also assume that 
\begin_inset Formula 
\[
\det(\be_{1},\ldots,\be_{n})=1,
\]

\end_inset

we now recover the original definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:detdef"

\end_inset

.
\end_layout

\begin_layout Chapter
Cayley Hamilton Theorem
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vu}{\mathbf{u}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vv}{\mathbf{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\ve}{\mathbf{e}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\vzero}{\mathbf{0}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\bB}{{\mathbf{B}}}
\end_inset


\begin_inset FormulaMacro
\renewcommand{\reals}{{\mathbf{R}}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
lp}{
\backslash
left(}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
rp}{
\backslash
right)} 
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
lb}{
\backslash
left[} 
\backslash
newcommand{
\backslash
rb}{
\backslash
right]}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
bvector}[1]{
\backslash
lb
\backslash
begin{array}{r}#1 
\backslash
end{array}
\backslash
rb} 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Overview
\end_layout

\begin_layout Standard
You should all know about the characteristic polynomial of a square matrix,
 
\begin_inset Formula $A$
\end_inset

.
 To calculate the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

, one subtracts a variable, say 
\begin_inset Formula $t$
\end_inset

, from the diagonal entries of 
\begin_inset Formula $A$
\end_inset

, and then takes the determinant of the result.
 In other words, letting 
\begin_inset Formula $p_{A}(t)$
\end_inset

 denote the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

, one has 
\begin_inset Formula 
\[
p_{A}(t)=\det(A-tI),
\]

\end_inset

where 
\begin_inset Formula $I$
\end_inset

 as usual denotes the identity matrix.
 For example, set 
\begin_inset Formula 
\[
A=\lb\begin{array}{rrr}
1 & 2 & 3\\
0 & -2 & 1\\
1 & 1 & 0
\end{array}\rb.
\]

\end_inset

Evaluating the determinant of 
\begin_inset Formula $A-tI$
\end_inset

 one gets 
\begin_inset Formula 
\[
p_{A}(t)=-t^{3}-t^{2}+6t+7.
\]

\end_inset


\end_layout

\begin_layout Standard
Now the interesting thing about square matrices is that one can do algebra
 with them.
 So if 
\begin_inset Formula $A$
\end_inset

 is a 
\begin_inset Formula $3\times3$
\end_inset

 matrix then 
\begin_inset Formula $A^{2}$
\end_inset

, 
\begin_inset Formula $A^{3}$
\end_inset

, indeed every power of 
\begin_inset Formula $A$
\end_inset

 will also be a 
\begin_inset Formula $3\times3$
\end_inset

 matrix.
 Indeed, one can take any polynomial 
\begin_inset Formula $p(t)$
\end_inset

, and happily plug 
\begin_inset Formula $A$
\end_inset

 into it.
 The result will be some other 
\begin_inset Formula $3\times3$
\end_inset

 matrix.
 The obvious question now is: what will happen when one plugs a square matrix
 
\begin_inset Formula $A$
\end_inset

 into its own characteristic polynomial? Let's see what happens for the
 sample 
\begin_inset Formula $3\times3$
\end_inset

 matrix above.
 Straightforward calculations show that 
\begin_inset Formula 
\[
A^{2}=\lb\begin{array}{rrr}
4 & 1 & 5\\
1 & 5 & -2\\
1 & 0 & 4
\end{array}\rb,\qquad A^{3}=\lb\begin{array}{rrr}
9 & 11 & 13\\
-1 & -10 & 8\\
5 & 6 & 3
\end{array}\rb,
\]

\end_inset

Next adding the various powers of 
\begin_inset Formula $A$
\end_inset

 with the coefficients of characteristic polynomial (note that one uses
 the identity matrix in place of the constants) one gets 
\size small

\begin_inset Formula 
\[
\begin{array}{cccc}
-A^{3} & -A^{2} & 6A & 7I\\
\\
-\lb\begin{array}{rrr}
9 & 11 & 13\\
-1 & -10 & 8\\
5 & 6 & 3
\end{array}\rb & -\lb\begin{array}{rrr}
4 & 1 & 5\\
1 & 5 & -2\\
1 & 0 & 4
\end{array}\rb & +6\lb\begin{array}{rrr}
1 & 2 & 3\\
0 & -2 & 1\\
1 & 1 & 0
\end{array}\rb & +7\lb\begin{array}{rrr}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array}\rb
\end{array}
\]

\end_inset


\begin_inset Formula 
\[
\qquad\qquad=\lb\begin{array}{rrr}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{array}\rb
\]

\end_inset


\size default
 Zero! One gets zero.
 This seemingly miraculous answer is not a coincidence.
 Indeed one gets zero regardless of what matrix one starts with.
 I encourage you to try this with a few examples of your own.
 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix, and let 
\begin_inset Formula $p_{A}(t)=\det(A-tI)$
\end_inset

 be the corresponding characteristic polynomial.
 Then, 
\begin_inset Formula $p_{A}(A)=0$
\end_inset

.
 
\end_layout

\begin_layout Standard
The goal of these notes will be to explain and prove the above theorem.
 There are various hidden reasons that make the Cayley-Hamilton theorem
 work.
 It is the purpose of these notes to bring these reasons into the open.
\end_layout

\begin_layout Section
The Gist of the Matter.
\end_layout

\begin_layout Standard
Indeed there are two factors that make the Cayley-Hamilton theorem such
 a striking and interesting result.
 Recall that if 
\begin_inset Formula $U$
\end_inset

 is an 
\begin_inset Formula $n$
\end_inset

-dimensional vector space, and 
\begin_inset Formula $\vu_{1},\vu_{2},\vu_{3},\ldots,\vu_{n+1}$
\end_inset

, are any 
\begin_inset Formula $n+1$
\end_inset

 vectors in 
\begin_inset Formula $U$
\end_inset

, then there will some kind of a linear relation between the 
\begin_inset Formula $\vu_{i}$
\end_inset

's, i.e.
 for some choice of scalars 
\begin_inset Formula $a_{1},a_{2},\ldots,a_{n+1}$
\end_inset

 one will have 
\begin_inset Formula 
\[
a_{1}\vu_{1}+a_{2}\vu_{2}+a_{3}\vu_{3}+\ldots a_{n+1}\vu_{n+1}=0.
\]

\end_inset


\end_layout

\begin_layout Standard
Now the space of 
\begin_inset Formula $3\times3$
\end_inset

 matrices is 
\begin_inset Formula $9$
\end_inset

-dimensional.
 Therefore for every 
\begin_inset Formula $3\times3$
\end_inset

 matrix 
\begin_inset Formula $A$
\end_inset

 there must be a linear relationship between the 
\begin_inset Formula $10$
\end_inset

 different matrix powers 
\begin_inset Formula 
\[
A^{9},A^{8},A^{7},A^{6},A^{5},A^{4},A^{3},A^{2},A^{1}=A,A^{0}=I.
\]

\end_inset

The 
\begin_inset Quotes eld
\end_inset

miracle
\begin_inset Quotes erd
\end_inset

 of the Cayley-Hamilton theorem is twofold.
 First, a linear relation arises already for the powers 
\begin_inset Formula $A^{3},A^{2},A^{1},A^{0}$
\end_inset

.
 Second, the coefficients for this linear relation are precisely the coefficient
s of the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Standard
Let's put it another way.
 Look at the first column vectors of the matrices 
\begin_inset Formula $A^{3},A^{2},A^{1},A^{0}$
\end_inset

, i.e.
 the vectors
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
[
\end_layout

\begin_layout Plain Layout


\backslash
bvector{9
\backslash

\backslash
-1
\backslash

\backslash
5},
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
bvector{4
\backslash

\backslash
1
\backslash

\backslash
1},
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
bvector{1
\backslash

\backslash
0
\backslash

\backslash
1 },
\backslash
quad  
\end_layout

\begin_layout Plain Layout


\backslash
bvector{1
\backslash

\backslash
0
\backslash

\backslash
0 }.
\end_layout

\begin_layout Plain Layout


\backslash
]
\end_layout

\end_inset

Now 
\begin_inset Formula $\reals^{3}$
\end_inset

 is a 
\begin_inset Formula $3$
\end_inset

-dimensional vector space, and so there should be a linear relation between
 the above 
\begin_inset Formula $4$
\end_inset

 vectors.
 Indeed there is: the coefficients of the linear relation are 
\begin_inset Formula $-1,-1,6,7$
\end_inset

 ( i.e.
 
\begin_inset Formula $-1$
\end_inset

 times the first vector, plus 
\begin_inset Formula $-1$
\end_inset

 times the second, plus 
\begin_inset Formula $6$
\end_inset

 times the third, plus 
\begin_inset Formula $7$
\end_inset

 times the fourth is equal to zero --- try it yourself!).
 What about the second column vectors of 
\begin_inset Formula $A^{3},A^{2},A^{1},A^{0}$
\end_inset

? Now the vectors in question are
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
[
\end_layout

\begin_layout Plain Layout


\backslash
bvector{11
\backslash

\backslash
-10
\backslash

\backslash
6},
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
bvector{1
\backslash

\backslash
5
\backslash

\backslash
0},
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
bvector{2
\backslash

\backslash
-2
\backslash

\backslash
1 },
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
bvector{0
\backslash

\backslash
1
\backslash

\backslash
0 }.
\end_layout

\begin_layout Plain Layout


\backslash
]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Again, we have here 
\begin_inset Formula $4$
\end_inset

 vectors from a 
\begin_inset Formula $3$
\end_inset

-dimensional vectors space, and therefore there should be a linear relation
 between the vectors.
 However by some miracle the coefficients of the linear relation for the
 second column vectors are the same as the coefficients of the linear relation
 between the first column vectors, namely 
\begin_inset Formula $-1,-1,6,7$
\end_inset

.
 Furthermore, these coefficients are precisely the coefficients of the character
istic polynomial: 
\begin_inset Formula $-t^{3}-t^{2}+6t+7$
\end_inset

.
 Needless to say the third column vectors are joined in a linear relation
 with the same coefficients: 
\begin_inset Formula $-1,-1,6,7$
\end_inset

.
 Why is this happening?
\end_layout

\begin_layout Section
The Cyclic Basis
\end_layout

\begin_layout Standard
Let's look again at the first column vectors of the matrices 
\begin_inset Formula $A^{0},A^{1},A^{2}$
\end_inset

 (recall that 
\begin_inset Formula $A^{0}$
\end_inset

 is just the identity matrix): 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
[
\end_layout

\begin_layout Plain Layout


\backslash
vu_0 = 
\backslash
bvector{1
\backslash

\backslash
0
\backslash

\backslash
0 },
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
vu_1=
\backslash
bvector{1
\backslash

\backslash
0
\backslash

\backslash
1 },
\backslash
quad
\end_layout

\begin_layout Plain Layout


\backslash
vu_2=
\backslash
bvector{4
\backslash

\backslash
1
\backslash

\backslash
1},
\end_layout

\begin_layout Plain Layout


\backslash
]
\end_layout

\end_inset

and let's take these 
\begin_inset Formula $3$
\end_inset

 vectors as a new basis, 
\begin_inset Formula $\bB$
\end_inset

.
 A basis obtained in this fashion, i.e.
 by starting with a vector and successively applying a matrix to it, is
 called a cyclic basis.
 What will be the representation of the matrix 
\begin_inset Formula $A$
\end_inset

 relative to this cyclic basis? Now 
\begin_inset Formula $\vu_{0}$
\end_inset

 is just the first elementary vector, 
\begin_inset Formula $\ve_{1}$
\end_inset

.
 Furthermore, note that 
\begin_inset Formula $\vu_{1}$
\end_inset

 is nothing but 
\begin_inset Formula $A\vu_{0}$
\end_inset

, and that 
\begin_inset Formula $\vu_{2}=A\vu_{1}$
\end_inset

.
 Now 
\begin_inset Formula $A\vu_{2}$
\end_inset

 is the first column vector of 
\begin_inset Formula $A^{3}$
\end_inset

 and we already determined the linear relation between the first column
 vectors of 
\begin_inset Formula $A^{3},\ldots A^{0}$
\end_inset

.
 The bottom line is that 
\begin_inset Formula 
\[
A\vu_{2}=-(\vu_{2}-6\vu_{1}-7\vu_{0}),
\]

\end_inset

and consequently 
\begin_inset Formula $A$
\end_inset

 will have the following appearance relative to the basis 
\begin_inset Formula $\bB$
\end_inset

: 
\begin_inset Formula 
\[
[A]_{\bB}=\lb\begin{array}{rrr}
0 & 0 & 7\\
1 & 0 & 6\\
0 & 1 & -1
\end{array}\rb
\]

\end_inset

The transition matrix 
\begin_inset Formula $P$
\end_inset

 from 
\begin_inset Formula $\bB$
\end_inset

 to the standard basis 
\begin_inset Formula $\ve_{1},\ve_{2},\ve_{3}$
\end_inset

 is given by 
\begin_inset Formula 
\[
P=\lb\begin{array}{rrr}
1 & 1 & 4\\
0 & 0 & 1\\
0 & 1 & 1
\end{array}\rb.
\]

\end_inset

Of course 
\begin_inset Formula $P$
\end_inset

 is relevant to our discussion precisely because 
\begin_inset Formula 
\[
[A]_{\bB}=P^{-1}AP.
\]

\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:conj"

\end_inset

 Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix, 
\begin_inset Formula $P$
\end_inset

 a non-singular 
\begin_inset Formula $n\times n$
\end_inset

 matrix, and set 
\begin_inset Formula $B=P^{-1}AP$
\end_inset

.
 The matrices 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 have the same characteristic polynomials.
 
\end_layout

\begin_layout Proof
The characteristic polynomial of 
\begin_inset Formula $B$
\end_inset

 is given as 
\begin_inset Formula 
\[
\det(B-tI)=\det\lp P^{-1}AP-tI\rp=\det\lp P^{-1}(A-tI)P\rp.
\]

\end_inset

Recall that the determinant of a product is the product of the determinants,
 and that the determinant of an inverse is the inverse of the determinant.
 Therefore 
\begin_inset Formula 
\[
\det(B-tI)=\det(P^{-1})\det(A-tI)\det(P)=\det(A-tI).
\]

\end_inset


\end_layout

\begin_layout Standard
In other words, according to the above theorem we should expect the characterist
ic polynomial of 
\begin_inset Formula $[A]_{\bB}$
\end_inset

 to be equal to the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

.
 Let's check this using a co-factor expansion.
 
\begin_inset Formula 
\[
\left|\begin{array}{ccc}
-t & 0 & 7\\
1 & -t & 6\\
0 & 1 & -1-t
\end{array}\right|=-t(t^{2}+t-6)+7\cdot1=-t^{3}-t^{2}+6t+7
\]

\end_inset

Also note that the last column of 
\begin_inset Formula $[A]_{\bB}$
\end_inset

 contains all but one of the coefficients of the characteristic polynomial.
 This too is not a coincidence.
 
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:ratform"

\end_inset

 Consider an 
\begin_inset Formula $n\times n$
\end_inset

 matrix 
\begin_inset Formula $B$
\end_inset

 such that the 
\begin_inset Formula $j^{\mbox{{\rm th}}}$
\end_inset

 column vector for 
\begin_inset Formula $j=1,2,\ldots n-1$
\end_inset

 is the basic vector 
\begin_inset Formula $\ve_{j+1}$
\end_inset

, while the last column of 
\begin_inset Formula $B$
\end_inset

 is the vector 
\begin_inset Formula $[-b_{0},-b_{1},\ldots,-b_{n-1}]^{T}$
\end_inset

.
 In other words 
\begin_inset Formula $B$
\end_inset

 has the following form: 
\begin_inset Formula 
\[
B=\lb\begin{array}{cccccc}
0 & 0 & 0 & \ldots & 0 & -b_{0}\\
1 & 0 & 0 & \ldots & 0 & -b_{1}\\
0 & 1 & 0 & \ldots & 0 & -b_{2}\\
0 & 0 & 1 & \ldots & 0 & -b_{3}\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & 0 & \ldots & 1 & -b_{n-1}
\end{array}\rb
\]

\end_inset

Then, the characteristic polynomial of 
\begin_inset Formula $B$
\end_inset

 is given by 
\begin_inset Formula 
\[
(-1)^{n}p_{B}(t)=t^{n}+b_{n-1}t^{n-1}+\ldots+b_{2}t^{2}+b_{1}t+b_{0}.
\]

\end_inset


\end_layout

\begin_layout Proof
We will calculate the determinant of 
\begin_inset Formula $B-tI$
\end_inset

 by doing a co-factor expansion along the first row.
 Let 
\begin_inset Formula $B_{1}$
\end_inset

 be the matrix obtained by deleting the first row and the first column from
 
\begin_inset Formula $B-tI$
\end_inset

, and let 
\begin_inset Formula $D$
\end_inset

 be the matrix obtained by deleting the first row and the last column from
 
\begin_inset Formula $B-tI$
\end_inset

.
 Doing a co-factor expansion along the top row, it is easy to see that 
\begin_inset Formula 
\[
\det(B-tI)=-t\det(B_{1})+(-1)^{n}b_{0}\det(D).
\]

\end_inset

Now 
\begin_inset Formula $D$
\end_inset

 is an upper triangular matrix with ones on the diagonal, and therefore
 
\begin_inset Formula $\det(D)=1$
\end_inset

.
 The matrix 
\begin_inset Formula $B_{1}$
\end_inset

, on the other hand has the same structure as 
\begin_inset Formula $B-tI$
\end_inset

, only it's 1 size smaller.
 To that end let 
\begin_inset Formula $B_{2}$
\end_inset

 be the matrix obtained by deleting the first two rows and columns from
 
\begin_inset Formula $B-tI$
\end_inset

.
 By the same reasoning as above it's easy to see that 
\begin_inset Formula 
\[
\det(B_{1})=-t\det(B_{2})+(-1)^{n-1}b_{1},
\]

\end_inset

and therefore 
\begin_inset Formula 
\[
\det(B-tI)=(-1)^{n}b_{0}-t\Big((-1)^{n-1}b_{1}-t\det(B_{2})\Big).
\]

\end_inset

Continuing inductively we see that for even 
\begin_inset Formula $n$
\end_inset

, the determinant of 
\begin_inset Formula $B-tI$
\end_inset

 will have the form: 
\begin_inset Formula 
\[
b_{0}-t\Bigg(-b_{1}-t\Big(b_{2}-t\big(-b_{3}-t(\ldots)\big)\Big)\Bigg)=b_{0}+b_{1}t+b_{2}t^{2}+b_{3}t^{3}+\ldots+b_{n-1}t^{n-1}+t^{n}
\]

\end_inset

For odd 
\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $\det(B-tI)$
\end_inset

 will be just like the formula above, but multiplied through by a negative
 sign.
 
\end_layout

\begin_layout Section
Putting it all together
\end_layout

\begin_layout Standard
Thanks to Propositions 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:conj"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:ratform"

\end_inset

 we are now in a position to understand and to prove the Cayley-Hamilton
 Theorem.
 Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix.
 Start by setting 
\begin_inset Formula $\vu_{0}=\ve_{1}$
\end_inset

, and then create a sequence of vectors by successively applying 
\begin_inset Formula $A$
\end_inset

, i.e.
 
\begin_inset Formula $\vu_{1}=A\vu_{0}$
\end_inset

, 
\begin_inset Formula $\vu_{2}=A\vu_{1}$
\end_inset

, etc.
 Notice that 
\begin_inset Formula $\vu_{k}=A^{k}\vu_{0}$
\end_inset

; in other words, 
\begin_inset Formula $\vu_{k}$
\end_inset

 is the first column of the matrix 
\begin_inset Formula $A^{k}$
\end_inset

.
\end_layout

\begin_layout Standard
Next, suppose that the 
\begin_inset Formula $n$
\end_inset

 vectors 
\begin_inset Formula $\vu_{0},\vu_{1},\vu_{2},\ldots,\vu_{n-1}$
\end_inset

 form a basis, 
\begin_inset Formula $\bB$
\end_inset

, of 
\begin_inset Formula $\reals^{n}$
\end_inset

 (There are matrices 
\begin_inset Formula $A$
\end_inset

 for which this doesn't happen, but we'll consider this possibility later.)
 There will therefore exist scalars 
\begin_inset Formula $b_{0},b_{1},\ldots b_{n-1}$
\end_inset

 such that 
\begin_inset Formula 
\[
\vu_{n}+b_{n-1}\vu_{n-1}+\ldots+b_{1}\vu_{1}+b_{0}\vu_{0}=0.
\]

\end_inset

Now the representation of 
\begin_inset Formula $A$
\end_inset

 relative to the cyclic basis 
\begin_inset Formula $\bB$
\end_inset

 will have the form 
\begin_inset Formula 
\[
[A]_{\bB}=\lb\begin{array}{cccccc}
0 & 0 & 0 & \ldots & 0 & -b_{0}\\
1 & 0 & 0 & \ldots & 0 & -b_{1}\\
0 & 1 & 0 & \ldots & 0 & -b_{2}\\
0 & 0 & 1 & \ldots & 0 & -b_{3}\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & 0 & \ldots & 1 & -b_{n-1}
\end{array}\rb
\]

\end_inset

By Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:conj"

\end_inset

 the characteristic polynomial of 
\begin_inset Formula $[A]_{\bB}$
\end_inset

 is equal to the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

.
 Furthermore, by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:ratform"

\end_inset

 the characteristic polynomial of 
\begin_inset Formula $[A]_{\bB}$
\end_inset

 is equal to 
\begin_inset Formula 
\[
\pm(t^{n}+b_{n-1}t^{n-1}+\ldots b_{1}t+b_{0}).
\]

\end_inset

Only one conclusion is possible: 
\begin_inset Formula $b_{0},b_{1},\ldots,b_{n-1}$
\end_inset

 must be precisely the coefficients of the characteristic polynomial of
 
\begin_inset Formula $A$
\end_inset

.
 Let us summarize these findings.
 
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:cols"

\end_inset

 Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix, with characteristic polynomial 
\begin_inset Formula 
\[
p_{A}(t)=\pm\lp t^{n}+b_{n-1}t^{n-1}+\ldots+b_{1}t+b_{0}\rp.
\]

\end_inset

Fix a number 
\begin_inset Formula $k$
\end_inset

 between 
\begin_inset Formula $1$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

, and let 
\begin_inset Formula $\vu_{j}$
\end_inset

 be the 
\begin_inset Formula $k^{\mbox{{\rm th}}}$
\end_inset

 column of the matrix 
\begin_inset Formula $A^{j}$
\end_inset

.
 If the vectors 
\begin_inset Formula $\vu_{0},\vu_{1},\ldots,\vu_{n-1}$
\end_inset

 form a basis of 
\begin_inset Formula $\reals^{n}$
\end_inset

, then the vectors 
\begin_inset Formula $\vu_{0},\vu_{1},\ldots,\vu_{n-1},\vu_{n}$
\end_inset

 satisfy the linear relation: 
\begin_inset Formula 
\[
\vu_{n}+b_{n-1}\vu_{n-1}+\ldots+b_{1}\vu_{1}+b_{0}\vu_{0}=0.
\]

\end_inset


\end_layout

\begin_layout Section
A Complication
\end_layout

\begin_layout Standard
We are almost done with the proof of the Cayley-Hamilton Theorem.
 First, however, we must deal with the possibility that the square matrix
 
\begin_inset Formula $A$
\end_inset

 is such that the column vectors of 
\begin_inset Formula $A^{0},A^{1},\ldots,A^{n-1}$
\end_inset

 do not form a basis.
 Consider, for example 
\begin_inset Formula 
\[
A=\lb\begin{array}{rrr}
1 & -1 & 2\\
1 & 4 & -4\\
1 & 2 & -2
\end{array}\rb
\]

\end_inset

An easy calculation shows that the characteristic polynomial is given by
 
\begin_inset Formula 
\[
p_{A}(t)=t^{3}-3t^{2}+t+2.
\]

\end_inset

Writing down the sequence of powers of 
\begin_inset Formula $A$
\end_inset

: 
\begin_inset Formula 
\[
\begin{array}{cccc}
A^{3} & A^{2} & A^{1} & A^{0}\\
\\
\lb\begin{array}{rrr}
3 & -2 & 4\\
2 & 15 & -14\\
2 & 7 & -6
\end{array}\rb & \quad\lb\begin{array}{rrr}
2 & -1 & 2\\
1 & 7 & -6\\
1 & 3 & -2
\end{array}\rb & \quad\lb\begin{array}{rrr}
1 & -1 & 2\\
1 & 4 & -4\\
1 & 2 & -2
\end{array}\rb & \quad\lb\begin{array}{rrr}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array}\rb
\end{array}
\]

\end_inset

we notice that the first columns do, in fact, obey a linear relation with
 the coefficients of the characteristic polynomial:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{equation}
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:comp0}
\end_layout

\begin_layout Plain Layout


\backslash
bvector{3
\backslash

\backslash
2
\backslash

\backslash
2}
\end_layout

\begin_layout Plain Layout

-3
\backslash
bvector{2
\backslash

\backslash
1
\backslash

\backslash
1} +
\backslash
bvector{1
\backslash

\backslash
1
\backslash

\backslash
1} +2
\backslash
bvector{1
\backslash

\backslash
0
\backslash

\backslash
0} = 
\backslash
bvector{0
\backslash

\backslash
0
\backslash

\backslash
0}.
 
\end_layout

\begin_layout Plain Layout


\backslash
end{equation} 
\end_layout

\end_inset

However these first column vectors 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 do not 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 form a basis of 
\begin_inset Formula $\reals^{3}$
\end_inset

, and therefore Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:cols"

\end_inset

 is not enough to explain why these vectors obey the above linear relation.
\end_layout

\begin_layout Standard
In order to find an explanation, let us proceed as follows.
 Just as before, start by setting 
\begin_inset Formula $\vu_{0}=\ve_{1}$
\end_inset

, and 
\begin_inset Formula $\vu_{1}=A\vu_{0}$
\end_inset

.
 If we take 
\begin_inset Formula $\vu_{2}=A\vu_{1}$
\end_inset

, then 
\begin_inset Formula $\bB=(\vu_{0},\vu_{1},\vu_{2})$
\end_inset

 will not form a basis, so instead, let us choose 
\begin_inset Formula $\vu_{2}$
\end_inset

 that is linearly independent from 
\begin_inset Formula $\vu_{0}$
\end_inset

 and 
\begin_inset Formula $\vu_{1}$
\end_inset

, thereby ensuring that 
\begin_inset Formula $\bB$
\end_inset

 is a basis.
 There are many, many possible such choices for 
\begin_inset Formula $\vu_{2}$
\end_inset

.
 To keep the discussion concrete, let us take 
\begin_inset Formula $\vu_{2}=\ve_{3}=[0,0,1]^{T}$
\end_inset

.
 Note that 
\begin_inset Formula 
\[
A\vu_{0}=\vu_{1}
\]

\end_inset


\begin_inset Formula 
\[
A\vu_{1}=[2,1,1]^{T}=\vu_{0}+\vu_{1}.
\]

\end_inset


\begin_inset Formula 
\[
A\vu_{2}=[2,-4,2]^{T}=6\vu_{0}-4\vu_{1}+2\vu_{2}.
\]

\end_inset

Therefore, representing 
\begin_inset Formula $A$
\end_inset

 relative to the basis 
\begin_inset Formula $\bB$
\end_inset

 we obtain 
\begin_inset Formula 
\[
[A]_{\bB}=\lb\begin{array}{rrr}
0 & 1 & 6\\
1 & 1 & -4\\
0 & 0 & 2
\end{array}\rb
\]

\end_inset

By Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:conj"

\end_inset

, we know that the characteristic polynomial of 
\begin_inset Formula $[A]_{\bB}$
\end_inset

 is equal to the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

.
 However, we know much more.
 
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:2block"

\end_inset

 Let 
\begin_inset Formula $B$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix of the form 
\begin_inset Formula 
\[
B=\lb\begin{array}{cc}
B_{1} & B_{2}\\
\mathbf{0} & B_{3}
\end{array}\rb
\]

\end_inset

where 
\begin_inset Formula $B_{1}$
\end_inset

 is a 
\begin_inset Formula $k\times k$
\end_inset

 matrix, 
\begin_inset Formula $B_{2}$
\end_inset

 is a 
\begin_inset Formula $k\times(n-k)$
\end_inset

 matrix, and 
\begin_inset Formula $B_{3}$
\end_inset

 is a 
\begin_inset Formula $(n-k)\times(n-k)$
\end_inset

 matrix.
 Then, the characteristic polynomial of 
\begin_inset Formula $B$
\end_inset

 is the product of the characteristic polynomials of 
\begin_inset Formula $B_{1}$
\end_inset

 and 
\begin_inset Formula $B_{3}$
\end_inset

, i.e.
 
\begin_inset Formula $p_{B}(t)=p_{B_{1}}(t)\times p_{B_{3}}(t)$
\end_inset

.
\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula 
\[
B-tI=\lb\begin{array}{cc}
B_{1}-tI_{1} & B_{2}\\
\mathbf{0} & B_{3}-tI_{3}
\end{array}\rb
\]

\end_inset

where 
\begin_inset Formula $I_{1}$
\end_inset

 is the 
\begin_inset Formula $k\times k$
\end_inset

 identity matrix, and 
\begin_inset Formula $I_{3}$
\end_inset

 is the 
\begin_inset Formula $(n-k)\times(n-k)$
\end_inset

 identity matrix.
 The Proposition now follows from the fact that the determinant of a matrix
 whose shape is like 
\begin_inset Formula $B$
\end_inset

 is the determinant of the upper-left block times the determinant of the
 lower-right block.
 
\end_layout

\begin_layout Standard
Thanks to Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:2block"

\end_inset

 we know that the characteristic polynomial of 
\begin_inset Formula $[A]_{\bB}$
\end_inset

 is a product of the characteristic polynomial of the 
\begin_inset Formula $2\times2$
\end_inset

 matrix 
\begin_inset Formula 
\[
\lb\begin{array}{rr}
0 & 1\\
1 & 1
\end{array}\rb
\]

\end_inset

and the characteristic polynomial of the 
\begin_inset Formula $1\times1$
\end_inset

 matrix 
\begin_inset Formula $[2]$
\end_inset

.
 In other words, 
\begin_inset Formula 
\[
p_{[A]_{\bB}}(t)=(t^{2}-t-1)(t-2).
\]

\end_inset

Furthermore by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:ratform"

\end_inset

 we know that 
\begin_inset Formula $A\vu_{1}$
\end_inset

, 
\begin_inset Formula $\vu_{1}$
\end_inset

, 
\begin_inset Formula $\vu_{0}$
\end_inset

, i.e.
 the first column vectors of 
\begin_inset Formula $A^{2},A^{1},A^{0}$
\end_inset

, obey a linear relation with the coefficients of the polynomial 
\begin_inset Formula $t^{2}-t-1$
\end_inset

: 
\begin_inset Formula 
\[
A\vu_{1}-\vu_{1}-\vu_{0}=\vzero,
\]

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{equation}
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:comp1} 
\end_layout

\begin_layout Plain Layout


\backslash
bvector{2
\backslash

\backslash
1
\backslash

\backslash
1} 
\end_layout

\begin_layout Plain Layout

-
\backslash
bvector{1
\backslash

\backslash
1
\backslash

\backslash
1} 
\end_layout

\begin_layout Plain Layout

-
\backslash
bvector{1
\backslash

\backslash
0
\backslash

\backslash
0} = 
\backslash
bvector{0
\backslash

\backslash
0
\backslash

\backslash
0}.
 
\end_layout

\begin_layout Plain Layout


\backslash
end{equation}
\end_layout

\end_inset

Multiplying this relation through by 
\begin_inset Formula $A$
\end_inset

 we deduce that the first column vectors of 
\begin_inset Formula $A^{3},A^{2},A^{1}$
\end_inset

 obey the same linear relation:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{equation}
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:comp2} 
\end_layout

\begin_layout Plain Layout


\backslash
bvector{3
\backslash

\backslash
2
\backslash

\backslash
2}  
\end_layout

\begin_layout Plain Layout

-
\backslash
bvector{2
\backslash

\backslash
1
\backslash

\backslash
1} 
\end_layout

\begin_layout Plain Layout

-
\backslash
bvector{1
\backslash

\backslash
1
\backslash

\backslash
1} = 
\backslash
bvector{0
\backslash

\backslash
0
\backslash

\backslash
0}.
 
\end_layout

\begin_layout Plain Layout


\backslash
end{equation} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Next think about what it means to multiply a polynomial such as 
\begin_inset Formula $t^{2}-t-1$
\end_inset

 by another polynomial such as 
\begin_inset Formula $t-2$
\end_inset

.
 Indeed, one can structure the multiplication by multiplying the first polynomia
l through by 
\begin_inset Formula $t$
\end_inset

, then multiplying it through by 
\begin_inset Formula $-2$
\end_inset

, and then adding the two terms: 
\begin_inset Formula 
\[
\begin{array}{cccc}
t^{3} & -t^{2} & -t\\
 & -2t^{2} & 2t & 2\\
\hline t^{3} & -3t^{2} & +t & +2
\end{array}
\]

\end_inset

The bottom line is, of course, just the characteristic polynomial of 
\begin_inset Formula $A$
\end_inset

, and the whole idea behind the above calculation is that 
\begin_inset Formula $p_{A}(t)$
\end_inset

 can be 
\begin_inset Quotes eld
\end_inset

formed out of
\begin_inset Quotes erd
\end_inset

 the polynomial 
\begin_inset Formula $t^{2}-t-1$
\end_inset

.
 This shows that we can combine relations (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:comp1"

\end_inset

) and (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:comp2"

\end_inset

) and produce in the end the desired relation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:comp0"

\end_inset

).
 All we have to do is take relation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:comp2"

\end_inset

), and add to it 
\begin_inset Formula $-2$
\end_inset

 times the relation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:comp1"

\end_inset

).
 This explains why the first column vectors of 
\begin_inset Formula $A^{3},A^{2},A^{1},A^{0}$
\end_inset

 obey a linear relation whose coefficients come from the characteristic
 polynomial of 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:cols2"

\end_inset

 Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix, with characteristic polynomial 
\begin_inset Formula 
\[
p_{A}(t)=\pm\lp t^{n}+b_{n-1}t^{n-1}+\ldots+b_{1}t+b_{0}\rp.
\]

\end_inset

Fix a number 
\begin_inset Formula $k$
\end_inset

 between 
\begin_inset Formula $1$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

, and let 
\begin_inset Formula $\vu_{j}$
\end_inset

 be the 
\begin_inset Formula $k^{\mbox{{\rm th}}}$
\end_inset

 column of the matrix 
\begin_inset Formula $A^{j}$
\end_inset

.
 The vectors 
\begin_inset Formula $\vu_{0},\vu_{1},\ldots,\vu_{n-1},\vu_{n}$
\end_inset

 satisfy the linear relation: 
\begin_inset Formula 
\[
\vu_{n}+b_{n-1}\vu_{n-1}+\ldots+b_{1}\vu_{1}+b_{0}\vu_{0}=0,
\]

\end_inset

even if the vectors 
\begin_inset Formula $\vu_{0},\vu_{1},\ldots,\vu_{n-1}$
\end_inset

 do not form a basis of 
\begin_inset Formula $\reals^{n}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Suppose that there is a number 
\begin_inset Formula $m$
\end_inset


\end_layout

\begin_layout Chapter
Minimal Polynomial
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $T$
\end_inset

 be an endomorphism of an 
\begin_inset Formula $n$
\end_inset

-dimensional vector space 
\begin_inset Formula $V$
\end_inset

.
 We define the 
\emph on
minimal polynomial
\emph default
, 
\begin_inset Formula $M_{T}(X)$
\end_inset

, to be the unique monic polynomial of minimal degree such that 
\begin_inset Formula $M_{T}(T)=0$
\end_inset

.
 We say that 
\begin_inset Formula $P(X)$
\end_inset

 is a 
\emph on
zero polynomial
\emph default
 for 
\begin_inset Formula $T$
\end_inset

 if 
\begin_inset Formula $P(T)$
\end_inset

 is the zero endomorphism.
\end_layout

\begin_layout Standard
Note that the minimal polynomial exists by virtue of the Cayley-Hamilton
 theorem, which provides a zero polynomial for 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_layout Section*
Properties
\end_layout

\begin_layout Standard
Firstly, 
\begin_inset Formula $\operatorname{End}(V)$
\end_inset

 is a vector space of dimension 
\begin_inset Formula $n^{2}$
\end_inset

.
 Therefore the 
\begin_inset Formula $n^{2}+1$
\end_inset

 vectors, 
\begin_inset Formula $i_{v},T,T^{2},\ldots T^{n^{2}}$
\end_inset

, are linearly dependant.
 So there are coefficients, 
\begin_inset Formula $a_{i}$
\end_inset

 not all zero such that 
\begin_inset Formula $\sum_{i=0}^{n^{2}}a_{i}T^{i}=0$
\end_inset

.
 We conclude that a non-trivial zero polynomial for 
\begin_inset Formula $T$
\end_inset

 exists.
 We take 
\begin_inset Formula $M_{T}(X)$
\end_inset

 to be a zero polynomial for 
\begin_inset Formula $T$
\end_inset

 of minimal degree with leading coefficient one.
\end_layout

\begin_layout Lemma
If 
\begin_inset Formula $P(X)$
\end_inset

 is a zero polynomial for 
\begin_inset Formula $T$
\end_inset

 then 
\begin_inset Formula $M_{T}(X)\mid P(X)$
\end_inset

.
 
\end_layout

\begin_layout Proof
 By the division algorithm for polynomials, 
\begin_inset Formula $P(X)=Q(X)M_{T}(X)+R(X)$
\end_inset

 with 
\begin_inset Formula $\deg R<\deg M_{T}$
\end_inset

.
 We note that 
\begin_inset Formula $R(X)$
\end_inset

 is also a zero polynomial for 
\begin_inset Formula $T$
\end_inset

 and by minimality of 
\begin_inset Formula $M_{T}(X)$
\end_inset

, must be just 
\begin_inset Formula $0$
\end_inset

.
 Thus we have shown 
\begin_inset Formula $M_{T}(X)\mid P(X)$
\end_inset

.
 
\end_layout

\begin_layout Standard
The minimal polynomial has a number of interesting properties:
\end_layout

\begin_layout Enumerate
The roots are exactly the eigenvalues of the endomorphism.
 
\end_layout

\begin_layout Enumerate
If the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 splits into linear factors then 
\begin_inset Formula $T$
\end_inset

 is upper-triangular with respect to some basis.
 
\end_layout

\begin_layout Enumerate
The minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 splits into 
\emph on
distinct
\emph default
 linear factors (i.e.
 no repeated roots) if and only if 
\begin_inset Formula $T$
\end_inset

 is diagonal with respect to some basis.
 
\end_layout

\begin_layout Standard
It is then a simple corollary of the fundamental theorem of algebra that
 every endomorphism of a finite dimensional vector space over 
\begin_inset Formula $\mathbb{C}$
\end_inset

 may be upper-triangularized.
\end_layout

\begin_layout Standard
The minimal polynomial is intimately related to the characteristic polynomial
 for 
\begin_inset Formula $T$
\end_inset

.
 For let 
\begin_inset Formula $\chi_{T}(X)$
\end_inset

 be the characteristc polynomial.
 Since 
\begin_inset Formula $\chi_{T}(T)=0$
\end_inset

, we have by the above lemma that 
\begin_inset Formula $M_{T}(X)\mid\chi_{T}(X)$
\end_inset

.
 It is also a fact that the eigenvalues of 
\begin_inset Formula $T$
\end_inset

 are exactly the roots of 
\begin_inset Formula $\chi_{T}$
\end_inset

.
 So when split into linear factors the only difference between 
\begin_inset Formula $M_{T}(X)$
\end_inset

 and 
\begin_inset Formula $\chi_{T}(X)$
\end_inset

 is the algebraic multiplicity of the roots.
\end_layout

\begin_layout Standard
In general they may not be the same--for example any diagonal matrix with
 repeated eigenvalues.
\end_layout

\begin_layout Chapter
Primary Decomposition Theorem
\end_layout

\begin_layout Standard
This is an important theorem in linear algebra.
 It states the following: Let 
\begin_inset Formula $\mathbb{F}$
\end_inset

 be a field, 
\begin_inset Formula $V$
\end_inset

 a vector space over 
\begin_inset Formula $\mathbb{F}$
\end_inset

, 
\begin_inset Formula $\dim V=n$
\end_inset

, and 
\begin_inset Formula $T\,\colon\, V\longrightarrow V$
\end_inset

 a linear operator, such that its minimal polynomial (or its annihilator
 polynomial) is 
\begin_inset Formula $m_{T}$
\end_inset

, which decomposes in 
\begin_inset Formula $\mathbb{F}[X]$
\end_inset

 into irreducible factors as 
\begin_inset Formula $m_{T}=p_{1}^{\alpha_{1}}\ldots p_{r}^{\alpha_{r}}$
\end_inset

.
 Then, 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $V=\bigoplus_{i=1}^{r}\ker(p_{i}^{\alpha_{i}}(T))$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\ker(p_{i}^{\alpha_{i}}(T))$
\end_inset

 is 
\begin_inset Formula $T$
\end_inset

-invariant for every 
\begin_inset Formula $i$
\end_inset

 
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $T_{i}$
\end_inset

 is the restriction of 
\begin_inset Formula $T$
\end_inset

 to 
\begin_inset Formula $\ker(p_{i}^{\alpha_{i}}(T))$
\end_inset

, then 
\begin_inset Formula $m_{T_{i}}=p_{i}^{\alpha_{i}}$
\end_inset

 
\end_layout

\begin_layout Standard
This is a consequence of a more general theorem: Let 
\begin_inset Formula $V$
\end_inset

, 
\begin_inset Formula $T$
\end_inset

 be as above, and 
\begin_inset Formula $f\in\mathbb{F}[X]$
\end_inset

 such that 
\begin_inset Formula $f(T)=0$
\end_inset

, with 
\begin_inset Formula $f=f_{1}\cdot\cdot\cdot\cdot\cdot f_{r}$
\end_inset

 and 
\begin_inset Formula $\gcd(f_{i},\, f_{j})=1$
\end_inset

 if 
\begin_inset Formula $i\neq j$
\end_inset

, then 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $V=\bigoplus_{i=1}^{r}\ker(f_{i}(T))$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\ker\, f_{i}(T))$
\end_inset

 is 
\begin_inset Formula $T$
\end_inset

-invariant for every 
\begin_inset Formula $i$
\end_inset

 
\end_layout

\begin_layout Standard
To illustrate its importance, the primary decomposition theorem, together
 with the cyclic decomposition theorem, imply the existence and uniqueness
 of the Jordan canonical form.
\end_layout

\begin_layout Chapter
Jordan Canonical Form
\end_layout

\begin_layout Definition
A 
\series bold
Jordan block
\series default
 or 
\series bold
Jordan matrix
\series default
 is a matrix of the form
\begin_inset Formula 
\[
\begin{pmatrix}\lambda & 1 & 0 & \cdots & 0\\
0 & \lambda & 1 & \cdots & 0\\
0 & 0 & \lambda & \cdots & 0\\
\vdots & \vdots & \vdots & \ddots & 1\\
0 & 0 & 0 & \cdots & \lambda
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
with a constant value 
\begin_inset Formula $\lambda$
\end_inset

 along the diagonal and 1's on the superdiagonal.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Some texts place the 1's on the subdiagonal instead.
\end_layout

\end_inset

 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $V$
\end_inset

 be a finite-dimensional vector space over a field 
\begin_inset Formula $\mathbb{F}$
\end_inset

 and 
\begin_inset Formula $T\,:\, V\longrightarrow V$
\end_inset

 be a linear transformation.
 Then, if the characteristic polynomial factors completely over 
\begin_inset Formula $\mathbb{F}$
\end_inset

, there will exist a basis of 
\begin_inset Formula $V$
\end_inset

 with respect to which the matrix of 
\begin_inset Formula $T$
\end_inset

 is of the form
\begin_inset Formula 
\[
\begin{pmatrix}J_{1} & 0 & \cdots & 0\\
0 & J_{2} & \cdots & 0\\
 &  & \cdots\\
0 & 0 & \cdots & J_{k}
\end{pmatrix}
\]

\end_inset

where each 
\begin_inset Formula $J_{i}$
\end_inset

 is a Jordan block in which 
\begin_inset Formula $\lambda=\lambda_{i}$
\end_inset

.
 
\end_layout

\begin_layout Definition
The matrix in Theorem 1 is called a 
\emph on
Jordan canonical form
\emph default
 for the transformation 
\emph on

\begin_inset Formula $T$
\end_inset


\emph default
.
\end_layout

\begin_layout Proof
This theorem can be proved combining the cyclic decomposition theorem and
 the primary decomposition theorem.
 
\end_layout

\begin_layout Proof
By hypothesis, the characteristic polynomial of 
\begin_inset Formula $T$
\end_inset

 factorizes completely over 
\begin_inset Formula $\mathbb{F}$
\end_inset

, and then so does the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 (or its annihilator polynomial).
 This is because the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 has exactly the same factors on 
\begin_inset Formula $\mathbb{F}[X]$
\end_inset

 as the characteristic polynomial of 
\begin_inset Formula $T$
\end_inset

.
 Let's suppose then that the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 factorizes as 
\begin_inset Formula $m_{T}=(X-\lambda_{1})^{\alpha_{1}}\ldots(X-\lambda_{r})^{\alpha_{r}}$
\end_inset

.
 We know, by the primary decomposition theorem, that 
\begin_inset Formula 
\[
V=\bigoplus_{i=1}^{r}\ker((T-\lambda_{i}I)^{\alpha_{i}}).
\]

\end_inset

Let 
\begin_inset Formula $T_{i}$
\end_inset

 be the restriction of 
\begin_inset Formula $T$
\end_inset

 to 
\begin_inset Formula $\ker((T-\lambda_{i}I)^{\alpha_{i}})$
\end_inset

.
 We apply now the cyclic decomposition theorem to every linear operator
 
\begin_inset Formula 
\[
(T_{i}-\lambda_{i}I)\,\colon\,\ker(T-\lambda_{i}I)^{\alpha_{i}}\longrightarrow\ker(T-\lambda_{i}I)^{\alpha_{i}}.
\]

\end_inset

We know then that 
\begin_inset Formula $\ker(T-\lambda_{i}I)^{\alpha_{i}}$
\end_inset

 has a basis 
\begin_inset Formula $B_{i}$
\end_inset

 of the form 
\begin_inset Formula $B_{i}=B_{1,i}\bigcup B_{2,i}\bigcup\ldots\bigcup B_{d_{i},i}$
\end_inset

 such that each 
\begin_inset Formula $B_{s,i}$
\end_inset

 is of the form 
\begin_inset Formula 
\[
B_{s,i}=\{v_{s,i},(T-\lambda_{i})v_{s,i},(T-\lambda_{i})^{2}v_{s,i},\ldots,(T-\lambda_{i})^{k_{s,i}}v_{s,i}\}.
\]

\end_inset


\end_layout

\begin_layout Standard
Let's see that 
\begin_inset Formula $T$
\end_inset

 in each of this 
\begin_inset Quotes eld
\end_inset

cyclic sub-basis
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $B_{s,i}$
\end_inset

 is a Jordan block: Simply notice the following fact about this polynomials:
 
\begin_inset Formula 
\begin{eqnarray*}
X(X-\lambda_{i})^{j} & = & (X-\lambda_{i})^{j+1}+X(X-\lambda_{i})^{j}-(X-\lambda_{i})^{j+1}\\
 & = & (X-\lambda_{i})^{j+1}+(X-X+\lambda_{i})(X-\lambda_{i})^{j}\\
 & = & (X-\lambda_{i})^{j+1}+\lambda_{i}(X-\lambda_{i})^{j}
\end{eqnarray*}

\end_inset

and then 
\begin_inset Formula 
\[
T(T-\lambda_{i}I)^{j}(v_{s,i})=(T-\lambda_{i})^{j+1}(v_{s,i})+\lambda_{i}(T-\lambda_{i}I)^{j}(v_{s,i}).
\]

\end_inset

So, if we also notice that 
\begin_inset Formula $(T-\lambda_{i}I)^{k_{s,i}+1}(v_{s,i})=0$
\end_inset

, we have that 
\begin_inset Formula $T$
\end_inset

 in this sub-basis is the Jordan block 
\begin_inset Formula 
\[
\begin{pmatrix}\lambda_{i} & 0 & 0 & \cdots & 0 & 0\\
1 & \lambda_{i} & 0 & \cdots & 0 & 0\\
0 & 1 & \lambda_{i} & \cdots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & 0 & \cdots & \lambda_{i} & 0\\
0 & 0 & 0 & \cdots & 1 & \lambda_{i}
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
So, taking the basis 
\begin_inset Formula $B=B_{1}\bigcup B_{2}\bigcup\ldots\bigcup B_{r}$
\end_inset

, we have that 
\begin_inset Formula $T$
\end_inset

 in this basis has a Jordan form.
\end_layout

\begin_layout Standard
This form is unique (except for the order of the blocks) due to the uniqueness
 of the cyclic decomposition.
 
\end_layout

\begin_layout Example
What is the Jordan canonical form of the matrix
\begin_inset Formula 
\[
A=\begin{bmatrix}\begin{array}{rrrrrr}
0 & 1 & 0 & -1 & 0 & 0\\
0 & 0 & 1 & 1 & -1 & 0\\
-1 & 0 & 0 & 0 & -1 & -1\\
1 & 0 & 0 & 0 & 1 & 0\\
0 & 1 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 1 & 0 & 0
\end{array}\end{bmatrix}.
\]

\end_inset

You are given that
\end_layout

\begin_layout Itemize
\begin_inset Formula $A$
\end_inset

has exactly two different eigenvalues
\end_layout

\begin_layout Itemize
one eigenvalue is 
\begin_inset Formula $\lambda_{1}=i$
\end_inset

 .
\end_layout

\begin_layout Standard

\series bold
Soln.

\series default
 This is a real matrix.
 So, nonreal eigenvalues must occur in pairs of conjugates.
 So, the other distinct eigenvalue of 
\begin_inset Formula $A$
\end_inset

 must be 
\begin_inset Formula $-i$
\end_inset

.
 Therefore, the minimal polynomial of 
\begin_inset Formula $A$
\end_inset

 must take the form of
\begin_inset Formula 
\[
\left[(x-i)(x+i)\right]^{k}=(x^{2}+1)^{k}\textrm{ for some }k\in\left\{ 1,2,3\right\} .
\]

\end_inset

The characteristic polynomial is given by 
\begin_inset Formula $\left(\lambda^{2}+1\right)^{3}$
\end_inset

.
 Hence the six eigenvalues are 
\begin_inset Formula $\pm i$
\end_inset

 with multiplicities.
 Because of 
\begin_inset Formula $\operatorname{tr}(A)=0$
\end_inset

 both 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $-i$
\end_inset

 have the same multiplicity.
 
\end_layout

\begin_layout Example
Find the JCF of
\begin_inset Formula 
\[
A=\begin{bmatrix}1 & 0 & 1 & -1\\
0 & 1 & 1 & 0\\
0 & 0 & 1 & 1\\
0 & 0 & 0 & 1
\end{bmatrix}.
\]

\end_inset


\end_layout

\begin_layout Standard

\series bold
Soln.

\series default
 The matrix is upper triangular so all the characteristic values are 1 and
 the vectors
\begin_inset Formula 
\[
x=\begin{bmatrix}1\\
0\\
0\\
0
\end{bmatrix}\quad\textrm{and}\quad y=\begin{bmatrix}0\\
1\\
0\\
0
\end{bmatrix}
\]

\end_inset

are eigenvectors.
 This implies that 
\begin_inset Formula $\left(A-I\right)^{2}$
\end_inset

 has nullity 3 or 4.
 But it is easy to see that the topright element of 
\begin_inset Formula $\left(A-I\right)^{2}$
\end_inset

 is 1 so nullity of 
\begin_inset Formula $\left(A-I\right)^{2}$
\end_inset

is 3 and nullity of 
\begin_inset Formula $\left(A-I\right)^{3}$
\end_inset

 must necessarily be 4.
 The JCF is
\begin_inset Formula 
\[
J=J_{3}(1)\oplus J_{1}(1).
\]

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $A$
\end_inset

 be a 
\begin_inset Formula $5\times5$
\end_inset

 matrix over 
\begin_inset Formula $\mathbf{R}$
\end_inset

 with
\begin_inset Formula 
\begin{eqnarray*}
\chi\left(t\right) & = & \left(t+1\right)^{3}\left(t+2\right)^{2}\\
\mu\left(t\right) & = & \left(t+1\right)\left(t+2\right)^{2}.
\end{eqnarray*}

\end_inset

What is the JCF of 
\begin_inset Formula $A^{-1}$
\end_inset

?
\end_layout

\begin_layout Standard

\series bold
Soln.

\series default
 The JCF of 
\begin_inset Formula $A$
\end_inset

 is
\begin_inset Formula 
\[
J=\begin{bmatrix}-2 & 1 & 0 & 0 & 0\\
0 & -2 & 0 & 0 & 0\\
0 & 0 & -1 & 0 & 0\\
0 & 0 & 0 & -1 & 0\\
0 & 0 & 0 & 0 & -1
\end{bmatrix}
\]

\end_inset

so the JCF of 
\begin_inset Formula $A^{-1}$
\end_inset

 is
\begin_inset Formula 
\[
J^{-1}=\begin{bmatrix}\begin{array}{rrrrr}
-\frac{1}{2} & -\frac{1}{4} & 0 & 0 & 0\\
0 & -\frac{1}{2} & 0 & 0 & 0\\
0 & 0 & -1 & 0 & 0\\
0 & 0 & 0 & -1 & 0\\
0 & 0 & 0 & 0 & -1
\end{array}\end{bmatrix}.
\]

\end_inset


\end_layout

\begin_layout Example
The characteristic polynomial of a matrix is 
\begin_inset Formula $x^{2}\left(x^{2}-1\right)$
\end_inset

.
 Find all the possible JCFs.
\end_layout

\begin_layout Standard

\series bold
Soln.

\series default
 The minimal polynomial can be either 
\begin_inset Formula $x\left(x-1\right)\left(x+1\right)$
\end_inset

 or 
\begin_inset Formula $x^{2}\left(x-1\right)\left(x+1\right)$
\end_inset

.
 Hence the possible JCFs are
\begin_inset Formula 
\[
\begin{bmatrix}\begin{array}{rrrr}
0 & 0 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & -1
\end{array}\end{bmatrix}\quad\textrm{and}\quad\begin{bmatrix}\begin{array}{rrrr}
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & -1
\end{array}\end{bmatrix}.
\]

\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $T$
\end_inset

 be an operator on the finite dimensional complex vector space 
\begin_inset Formula $V$
\end_inset

.
 The characteristic polynomial of 
\begin_inset Formula $T$
\end_inset

 equals the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 if and only if the dimension of each eigenspace of 
\begin_inset Formula $T$
\end_inset

 is 1.
\end_layout

\begin_layout Proof
Let the characteristic and minimal polynomial be, respectively, 
\begin_inset Formula $\chi\left(t\right)$
\end_inset

 and 
\begin_inset Formula $\mu\left(t\right)$
\end_inset

, with
\begin_inset Formula 
\begin{align*}
\chi(t) & =(t-\lambda_{1})^{a_{1}}\cdots(t-\lambda_{k})^{a_{k}}\\
\mu(t) & =(t-\lambda_{1})^{b_{1}}\cdots(t-\lambda_{k})^{b_{k}},
\end{align*}

\end_inset

where 
\begin_inset Formula $1\leq b_{i}\leq a_{i}$
\end_inset

 for each 
\begin_inset Formula $i$
\end_inset

.
 Then 
\begin_inset Formula $b_{i}$
\end_inset

 is the size of the largest Jordan block associated to 
\begin_inset Formula $\lambda_{i}$
\end_inset

 in the Jordan canonical form of 
\begin_inset Formula $T$
\end_inset

, and the sum of the sizes of the Jordan blocks associated to 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\lambda_{i}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is equal to 
\begin_inset Formula $a_{i}$
\end_inset

.
 Hence, 
\begin_inset Formula $b_{i}=a_{i}$
\end_inset

 if and only if 
\begin_inset Formula $T$
\end_inset

 has a unique Jordan block associated to 
\begin_inset Formula $\lambda_{i}$
\end_inset

.
 Since the dimension of 
\begin_inset Formula $E_{\lambda_{i}}$
\end_inset

is equal to the number of Jordan blocks associated to 
\begin_inset Formula $\lambda_{i}$
\end_inset

 in the Jordan canonical form of T, it follows that 
\begin_inset Formula $b_{i}=a_{i}$
\end_inset

 if and only if 
\begin_inset Formula $\dim(E_{\lambda_{i}})=1$
\end_inset

.
\end_layout

\begin_layout Standard
In particular, if the matrix has 
\begin_inset Formula $n$
\end_inset

 distinct eigenvalues, then each eigenvalue has a one-dimensional eigenspace.
\end_layout

\begin_layout Standard
Also in particular,
\end_layout

\begin_layout Corollary
Let 
\begin_inset Formula $T$
\end_inset

 be a diagonalizable operator on a finite dimensional vector space 
\begin_inset Formula $V$
\end_inset

.
 The characteristic polynomial of 
\begin_inset Formula $T$
\end_inset

 equals the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 if and only if the number of distinct eigenvalues of 
\begin_inset Formula $T$
\end_inset

 is 
\begin_inset Formula $\dim(V)$
\end_inset

 .
\end_layout

\begin_layout Standard
Using the Rational Canonical Form instead, we obtain:
\end_layout

\begin_layout Theorem
Let  
\begin_inset Formula $V$
\end_inset

be a finite dimensional vector space over the field 
\begin_inset Formula $\mathbb{F}$
\end_inset

, and 
\begin_inset Formula $T$
\end_inset

 an operator on 
\begin_inset Formula $V$
\end_inset

.
 Let 
\begin_inset Formula $\chi\left(t\right)$
\end_inset

 be the characteristic polynomial of 
\begin_inset Formula $T$
\end_inset

, and assume that the factorization of 
\begin_inset Formula $\chi\left(t\right)$
\end_inset

 into irreducibles over 
\begin_inset Formula $\mathbb{F}$
\end_inset

 is 
\begin_inset Formula 
\[
\chi(t)=\phi_{1}(t)^{a_{1}}\cdots\phi_{k}(t)^{a_{k}}.
\]

\end_inset

Then the minimal polynomial of 
\begin_inset Formula $T$
\end_inset

 equals the characteristic polynomial of 
\begin_inset Formula $T$
\end_inset

 if and only if 
\begin_inset Formula $\dim\left(\mathrm{ker}\phi_{i}\left(T\right)\right)=\deg\left(\phi_{i}\left(t\right)\right)$
\end_inset

.
\end_layout

\begin_layout Proof
Proceed as above, using the Rational Canonical forms instead.
 The exponent 
\begin_inset Formula $b_{i}$
\end_inset

 of 
\begin_inset Formula $\phi_{i}\left(t\right)$
\end_inset

 in the minimal polynomial gives the largest power of 
\begin_inset Formula $\phi_{i}\left(t\right)$
\end_inset

 that has a companion block in the Rational canonical form, and 
\begin_inset Formula $\frac{1}{d_{i}}\dim\left(\mathrm{ker}\phi_{i}\left(T\right)\right)$
\end_inset

(where 
\begin_inset Formula $d_{i}=\deg\phi_{i}$
\end_inset

 is the number of companion blocks.
\end_layout

\begin_layout Standard
3 down vote 
\end_layout

\begin_layout Standard
The following equivalent criteria, valid for an arbitrary field, are short
 to state, but maybe they are less practical.
\end_layout

\begin_layout Proposition
The following are equivalent for a linear operator on a vector space of
 nonzero finite dimension.
\end_layout

\begin_layout Enumerate
The minimal polynomial is equal to the characteristic polynomial.
 
\end_layout

\begin_layout Enumerate
The Rational Canonical Form has a single block.
 
\end_layout

\begin_layout Enumerate
The operator has a matrix similar to a companion matrix.
 
\end_layout

\begin_layout Enumerate
There exists a vector whose images by the operator span the whole space.
\end_layout

\begin_layout Proof
Point 1.
 and 2.
 are equivalent because the minimal polynomial is the largest invariant
 factor and the characteristic polynomial is the product of all invariant
 factors; the invariant factors are in bijection with the blocks of the
 Rational Canonical Form.
 These blocks are companion matrices, so 2.
 implies 3., and by the uniqueness of the RCF 3.
 also implies 2.
\end_layout

\begin_layout Proof
Finally 3.
 implies 4.
 (take the first basis vector) and 4 implies 3.
 by taking a basis consisting of n successive images (counting from 0) of
 the cyclic vector.
 
\end_layout

\begin_layout Standard
Here is a generalization to principal ideal domains.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $A$
\end_inset

 be a principal ideal domain, 
\begin_inset Formula $p$
\end_inset

 an irreducible element of 
\begin_inset Formula $A$
\end_inset

, and 
\begin_inset Formula $M$
\end_inset

 a finitely generated 
\begin_inset Formula $A$
\end_inset

-module annihilated by some power of 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Standard
Then there is a unique nondecreasing tuple 
\begin_inset Formula $(n_{1},\dots,n_{k})$
\end_inset

 of positive integers such that 
\begin_inset Formula $M$
\end_inset

 is isomorphic to the direct sum of the 
\begin_inset Formula $A/(p^{n_{i}})$
\end_inset

.
\end_layout

\begin_layout Standard
The 
\series bold
characteristic ideal
\series default
 of 
\begin_inset Formula $M$
\end_inset

 is 
\begin_inset Formula $\left(p^{s}\right)$
\end_inset

, where 
\begin_inset Formula $s$
\end_inset

 is the sum of the 
\begin_inset Formula $n_{i}$
\end_inset

; and the annihilator of 
\begin_inset Formula $M$
\end_inset

 is 
\begin_inset Formula $p^{n_{k}}$
\end_inset

.
 Let 
\begin_inset Formula $\phi$
\end_inset

 be the endomorphism 
\begin_inset Formula $x\longmapsto px$
\end_inset

 of 
\begin_inset Formula $M$
\end_inset

.
\end_layout

\begin_layout Standard
The following conditions are clearly equivalent:
\end_layout

\begin_layout Itemize
\begin_inset Formula $k=1$
\end_inset

,
\end_layout

\begin_layout Itemize
\begin_inset Formula $s=n_{k}$
\end_inset

,
\end_layout

\begin_layout Itemize
\begin_inset Formula $\text{Ker }\phi\simeq A/(p)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\text{Coker }\phi\simeq A/(p)$
\end_inset

.
\end_layout

\begin_layout Chapter
Eigenvalues and Eigenvectors
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\x}{\boldsymbol{x}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\a}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\b}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\c}{\boldsymbol{c}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\v}{\boldsymbol{v}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\e}{\boldsymbol{e}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\R}{\mathbb{R}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\theenumi}{\roman{enumi}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\labelenumi}{(\theenumi)}
\end_inset


\end_layout

\begin_layout Section
Main Idea
\end_layout

\begin_layout Standard
Given a matrix 
\begin_inset Formula $A\in M(n\times n)$
\end_inset

, is it possible to find a basis in which the associated linear transformation
 is represented by a diagonal matrix? In other words, can we find an invertible
 matrix 
\begin_inset Formula $S$
\end_inset

 such that 
\begin_inset Formula 
\begin{equation}
D=S^{-1}AS\label{e.d}
\end{equation}

\end_inset

is diagonal? Writing 
\begin_inset Formula 
\[
D=\begin{pmatrix}\lambda_{1} &  & 0\\
 & \ddots\\
0 &  & \lambda_{n}
\end{pmatrix}\quad\text{and}\quad S=\begin{pmatrix}| &  & |\\
\v_{1} & \cdots & \v_{n}\\
| &  & |
\end{pmatrix}\,,
\]

\end_inset

i.e.
\begin_inset space \space{}
\end_inset


\begin_inset Formula $\v_{1},\dots,\v_{n}$
\end_inset

 are the columns of the matrix 
\begin_inset Formula $S$
\end_inset

, equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "e.d"

\end_inset

 can be written 
\begin_inset Formula $SD=AS$
\end_inset

, or 
\begin_inset Formula 
\[
\begin{pmatrix}| &  & |\\
\lambda_{1}\v_{1} & \cdots & \lambda_{n}\v_{n}\\
| &  & |
\end{pmatrix}=A\,\begin{pmatrix}| &  & |\\
\v_{1} & \cdots & \v_{n}\\
| &  & |
\end{pmatrix}\,.
\]

\end_inset

If we separate this matrix equation 
\begin_inset Formula $n$
\end_inset

 column vector equations, we get 
\begin_inset Formula 
\[
\lambda_{1}\v_{1}=A\v_{1}\,,\dots,\lambda_{n}\v_{n}=A\v_{n}\,.
\]

\end_inset

In other words, the entries on the diagonal of 
\begin_inset Formula $D$
\end_inset

 are the eigenvalues of 
\begin_inset Formula $A$
\end_inset

, and the columns of 
\begin_inset Formula $S$
\end_inset

 are the corresponding eigenvectors.
 Therefore, our task is the following: 
\end_layout

\begin_layout Quote
Find 
\begin_inset Formula $n$
\end_inset

 eigenvalues, and 
\begin_inset Formula $n$
\end_inset

 linearly independent eigenvectors of 
\begin_inset Formula $A$
\end_inset

.
 
\end_layout

\begin_layout Section
Computing Eigenvalues and Eigenvectors
\end_layout

\begin_layout Standard
As an example, let's consider the matrix 
\begin_inset Formula 
\[
A=\begin{pmatrix}0 & -i & i\\
i & 0 & -i\\
-i & i & 0
\end{pmatrix}\,.
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Step 1: Compute and factor the characteristic polynomial
\end_layout

\begin_layout Standard
The characteristic polynomial is defined 
\begin_inset Formula 
\[
p_{A}(\lambda)=\det(A-\lambda I)\,.
\]

\end_inset

It is zero if and only if 
\begin_inset Formula $A-\lambda I$
\end_inset

 is singular, i.e.
\begin_inset space \space{}
\end_inset

if and only if the equation 
\begin_inset Formula $A\v=\lambda\v$
\end_inset

 has a nontrivial solution, i.e.
\begin_inset space \space{}
\end_inset

if and only if 
\begin_inset Formula $\lambda$
\end_inset

 is an eigenvalue.
 In order to find the zeros, try to write the characteristic polynomial
 as a product of linear factors: 
\begin_inset Formula 
\[
p_{A}(\lambda)=\pm(\lambda-\lambda_{1})\cdots(\lambda-\lambda_{n})\,.
\]

\end_inset

Notice that some linear factor 
\begin_inset Formula $\lambda-\lambda_{k}$
\end_inset

 may occur more than once.
 In that case it is crucial that the dimension of the corresponding eigenspace,
 i.e.
\begin_inset space \space{}
\end_inset

the dimension of the solution space of the linear system 
\begin_inset Formula $(A-\lambda_{k}I)\v_{k}=0$
\end_inset

 has the same multiplicity.
 If its dimension is less than the multiplicity of the eigenvalue, the matrix
 cannot be diagonalized.
\end_layout

\begin_layout Standard
In our example, 
\begin_inset Formula 
\begin{align*}
p_{A}(\lambda) & =\begin{vmatrix}-\lambda & -i & i\\
i & -\lambda & -i\\
-i & i & -\lambda
\end{vmatrix}\\
 & =-\lambda^{3}+(-i)^{3}+i^{3}-3\,(-\lambda)\, i\,(-i)\\
 & =-\lambda\,(\lambda^{2}-3)\\
 & =-\lambda\,(\lambda+\sqrt{3})\,(\lambda-\sqrt{3})\,.
\end{align*}

\end_inset

Therefore the three eigenvalues are 
\begin_inset Formula $\lambda_{1}=0$
\end_inset

, 
\begin_inset Formula $\lambda_{2}=-\sqrt{3}$
\end_inset

, 
\begin_inset Formula $\lambda_{2}=\sqrt{3}$
\end_inset

.
 Since the eigenvalues are distinct, we already know that the matrix must
 be diagonalizable.
\end_layout

\begin_layout Subsubsection*
Step 2: Compute the eigenvectors for each eigenvalue
\end_layout

\begin_layout Standard
For each of the 
\begin_inset Formula $\lambda_{k}$
\end_inset

 where 
\begin_inset Formula $k=1,\dots,n$
\end_inset

 we have to solve the homogeneous equation 
\begin_inset Formula 
\[
(A-\lambda_{k})\v_{k}=0\,.
\]

\end_inset

In this example, 
\begin_inset Formula 
\[
(A-\lambda_{1})\v_{1}=\begin{pmatrix}0 & -i & i\\
i & 0 & -i\\
-i & i & 0
\end{pmatrix}=0\,.
\]

\end_inset

After row-reduction, we obtain the matrix 
\begin_inset Formula 
\[
\begin{pmatrix}1 & 0 & -1\\
0 & 1 & -1\\
0 & 0 & 0
\end{pmatrix}\,,
\]

\end_inset

thus the first eigenvector is 
\begin_inset Formula $\v_{1}=(-1,-1,-1)^{T}$
\end_inset

.
 Next, 
\begin_inset Formula 
\[
(A-\lambda_{2})\v_{2}=\begin{pmatrix}\sqrt{3} & -i & i\\
i & \sqrt{3} & -i\\
-i & i & \sqrt{3}
\end{pmatrix}=0\,.
\]

\end_inset

Let's row-reduce this matrix: 
\begin_inset Formula 
\begin{align*}
 & \begin{pmatrix}\sqrt{3} & -i & i\\
i & \sqrt{3} & -i\\
-i & i & \sqrt{3}
\end{pmatrix}\xrightarrow{\substack{\text{R1}/\sqrt{3}\to\text{R1}\\
i\text{R2}\to\text{R2}\\
i\text{R3}\to\text{R3}
}
}\begin{pmatrix}1 & -\tfrac{i}{\sqrt{3}} & \tfrac{i}{\sqrt{3}}\\
-1 & \sqrt{3}i & 1\\
1 & -1 & \sqrt{3}i
\end{pmatrix}\xrightarrow{\substack{\text{R1}+\text{R2}\to\text{R2}\\
\text{R2}+\text{R3}\to\text{R3}
}
}\\
 & \begin{pmatrix}1 & -\tfrac{i}{\sqrt{3}} & \tfrac{i}{\sqrt{3}}\\
0 & \tfrac{2}{\sqrt{3}}i & 1+\tfrac{i}{\sqrt{3}}\\
0 & \sqrt{3}i-1 & 1+\sqrt{3}i
\end{pmatrix}\xrightarrow{\substack{-\tfrac{\sqrt{3}}{2}i\text{R2}\to\text{R2}\\
\text{R3}/(\sqrt{3}i-1)\to\text{R3}
}
}\begin{pmatrix}1 & -\tfrac{i}{\sqrt{3}} & \tfrac{i}{\sqrt{3}}\\
0 & 1 & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
0 & 1 & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i
\end{pmatrix}\\
 & \xrightarrow{\substack{\text{R1}-\tfrac{i}{\sqrt{3}}\text{R2}\to\text{R1}\\
\text{R2}-\text{R3}\to\text{R3}
}
}\begin{pmatrix}1 & 0 & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i\\
0 & 1 & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
0 & 0 & 0
\end{pmatrix}
\end{align*}

\end_inset

Therefore, 
\begin_inset Formula 
\[
\v_{2}=\begin{pmatrix}\tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i\\
\tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
-1
\end{pmatrix}\,,\qquad\v_{3}=\begin{pmatrix}\tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
\tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i\\
-1
\end{pmatrix}\,,
\]

\end_inset

where the computation for 
\begin_inset Formula $\v_{3}$
\end_inset

 is very similar to the previous one.
 Hence, we can write 
\begin_inset Formula 
\[
D=\begin{pmatrix}0 & 0 & 0\\
0 & -\sqrt{3} & 0\\
0 & 0 & \sqrt{3}
\end{pmatrix}\,,\qquad S=\begin{pmatrix}-1 & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
-1 & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i\\
-1 & -1 & -1
\end{pmatrix}\,.
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Step 3: Check your solution
\end_layout

\begin_layout Standard
It is easiest to check that 
\begin_inset Formula $SD=AS$
\end_inset

, because this does not require the computation of a matrix inverse.
 In this example, 
\begin_inset Formula 
\begin{align*}
SD & =\begin{pmatrix}-1 & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
-1 & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i\\
-1 & -1 & -1
\end{pmatrix}\begin{pmatrix}0 & 0 & 0\\
0 & -\sqrt{3} & 0\\
0 & 0 & \sqrt{3}
\end{pmatrix}=\begin{pmatrix}0 & -\tfrac{\sqrt{3}}{2}-\tfrac{3}{2}i & \tfrac{\sqrt{3}}{2}-\tfrac{3}{2}i\\
0 & -\tfrac{\sqrt{3}}{2}+\tfrac{3}{2}i & \tfrac{\sqrt{3}}{2}+\tfrac{3}{2}i\\
0 & \sqrt{3} & -\sqrt{3}
\end{pmatrix}\\
AS & =\begin{pmatrix}0 & -i & i\\
i & 0 & -i\\
-i & i & 0
\end{pmatrix}\begin{pmatrix}-1 & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i\\
-1 & \tfrac{1}{2}-\tfrac{\sqrt{3}}{2}i & \tfrac{1}{2}+\tfrac{\sqrt{3}}{2}i\\
-1 & -1 & -1
\end{pmatrix}=\begin{pmatrix}0 & -\tfrac{\sqrt{3}}{2}-\tfrac{3}{2}i & \tfrac{\sqrt{3}}{2}-\tfrac{3}{2}i\\
0 & -\tfrac{\sqrt{3}}{2}+\tfrac{3}{2}i & \tfrac{\sqrt{3}}{2}+\tfrac{3}{2}i\\
0 & \sqrt{3} & -\sqrt{3}
\end{pmatrix}\,.
\end{align*}

\end_inset


\end_layout

\begin_layout Chapter
Inner Product Spaces
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\ip}[1]{{\langle#1\rangle}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\v}{{\mathbf{v}}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\w}{{\mathbf{w}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\0}{{\mathbf{0}}}
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newtheorem{note}{
\end_layout

\end_inset

Note
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Definition
An 
\emph on
inner product
\emph default
 on a vector space 
\begin_inset Formula $V$
\end_inset

 over a field 
\begin_inset Formula $\mathbb{F}$
\end_inset

 (which must be either the field 
\begin_inset Formula $\mathbf{R}$
\end_inset

 of real numbers or the field 
\begin_inset Formula $\mathbf{C}$
\end_inset

 of complex numbers) is a function 
\begin_inset Formula $\left\langle \ ,\ \right\rangle :V\times V\longrightarrow\mathbb{F}$
\end_inset

 such that, for all 
\begin_inset Formula $k_{1},k_{2}\in\mathbb{F}$
\end_inset

 and 
\begin_inset Formula $\v_{1},\v_{2},\v,\w\in V$
\end_inset

, the following properties hold: 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\langle k_{1}\v_{1}+k_{2}\v_{2},\w\right\rangle =k_{1}\left\langle \v_{1},\w\right\rangle +k_{2}\left\langle \v_{2},\w\right\rangle $
\end_inset

 (linearity
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
A small minority of authors impose linearity on the second coordinate instead
 of the first coordinate.
\end_layout

\end_inset

) 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\langle \v,\w\right\rangle =\overline{\left\langle \w,\v\right\rangle }$
\end_inset

, where 
\begin_inset Formula $\overline{\ \ \ \ }$
\end_inset

 denotes complex conjugation (conjugate symmetry) 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\langle \v,\v\right\rangle \geq0$
\end_inset

, and 
\begin_inset Formula $\left\langle \v,\v\right\rangle =0$
\end_inset

 if and only if 
\begin_inset Formula $\v=\0$
\end_inset

 (positive definite) 
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{note}
\end_layout

\end_inset

 Rule (ii) guarantees that 
\begin_inset Formula $\left\langle \v,\v\right\rangle \in\mathbf{R}$
\end_inset

, so the inequality 
\begin_inset Formula $\left\langle \v,\v\right\rangle \geq0$
\end_inset

 in rule (iii) makes sense even when 
\begin_inset Formula $\mathbb{F}=\mathbf{C}$
\end_inset

.) 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{note}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The standard example of an inner product is the dot product on 
\begin_inset Formula $\mathbb{F}^{n}$
\end_inset

: 
\begin_inset Formula 
\[
\left\langle (x_{1},\dots,x_{n}),(y_{1},\dots,y_{n})\right\rangle :=\sum_{i=1}^{n}x_{i}\overline{y_{i}}
\]

\end_inset


\end_layout

\begin_layout Standard
Every inner product space is a normed vector space, with the norm being
 defined by 
\begin_inset Formula $||\v||:=\sqrt{\left\langle \v,\v\right\rangle }$
\end_inset

.
\end_layout

\begin_layout Standard
An 
\emph on
inner product space
\emph default
 (or 
\emph on
pre-Hilbert space
\emph default
) is a vector space (over 
\begin_inset Formula $\mathbf{R}$
\end_inset

 or 
\begin_inset Formula $\mathbf{C}$
\end_inset

) with an inner product 
\begin_inset Formula $\ip{\cdot,\cdot}$
\end_inset

.
\end_layout

\begin_layout Standard
For example, 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 with the familiar dot product forms an inner product space.
\end_layout

\begin_layout Standard
Every inner product space is also a normed vector space, with the norm defined
 by 
\begin_inset Formula $\Vert x\Vert:=\sqrt{\ip{x,\, x}}$
\end_inset

.
 This norm satisfies the parallelogram law.
\end_layout

\begin_layout Standard
If the metric 
\begin_inset Formula $\Vert{x-y}\Vert$
\end_inset

 induced by the norm is complete, then the inner product space is called
 a Hilbert space.
\end_layout

\begin_layout Section*
The Cauchy--Schwarz inequality
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
|\ip{x,\, y}|\le\Vert x\Vert\cdot\Vert y\Vert
\end{align}

\end_inset

holds in any inner product space.
\end_layout

\begin_layout Standard
According to (1), one can define the 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 angle between two non-zero vectors
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

: 
\begin_inset Formula 
\begin{align}
\cos(x,\, y):=\frac{\ip{x,\, y}}{\Vert{x}\Vert\cdot\Vert{y}\Vert}.
\end{align}

\end_inset

This provides that the scalars are the real numbers.
 In any case, the 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 perpendicularity
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 of the vectors may be defined with the condition 
\begin_inset Formula 
\[
\ip{x,\, y}=0.
\]

\end_inset


\end_layout

\begin_layout Section*
Proof of Cauchy--Schwarz inequality
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 are linearly dependent, we write 
\begin_inset Formula $\boldsymbol{b}=\lambda\boldsymbol{a}$
\end_inset

.
 So we get: 
\begin_inset Formula 
\[
\langle\boldsymbol{a},\lambda\boldsymbol{a}\rangle^{2}=\lambda^{2}\langle\boldsymbol{a},\boldsymbol{a}\rangle^{2}=\lambda^{2}||\boldsymbol{a}||^{4}=||\boldsymbol{a}||^{2}||\boldsymbol{b}||^{2}.
\]

\end_inset

So we have equality if 
\begin_inset Formula $\boldsymbol{a}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{b}$
\end_inset

 are linearly dependent.
 In the other case we look at the quadratic function 
\begin_inset Formula 
\[
||x\cdot\boldsymbol{a}+\boldsymbol{b}||^{2}=x^{2}||\boldsymbol{a}||^{2}+2x\langle\boldsymbol{a},\boldsymbol{b}\rangle+||\boldsymbol{b}||^{2}.
\]

\end_inset

This function is positive for every real 
\begin_inset Formula $x$
\end_inset

, if 
\begin_inset Formula $\boldsymbol{a}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{b}$
\end_inset

 are linearly independent.
 Thus it has no real zeroes, which means that 
\begin_inset Formula 
\[
\langle\boldsymbol{a},\boldsymbol{b}\rangle^{2}-||\boldsymbol{a}||^{2}||\boldsymbol{b}||^{2}
\]

\end_inset

is always negative.
 So we have: 
\begin_inset Formula 
\[
\langle\boldsymbol{a},\boldsymbol{b}\rangle^{2}<||\boldsymbol{a}||^{2}||\boldsymbol{b}||^{2},
\]

\end_inset

which is the Cauchy-Schwarz inequality if 
\begin_inset Formula $\boldsymbol{a}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{b}$
\end_inset

 are linearly independent.
\end_layout

\begin_layout Part
Numerical Linear Algebra
\end_layout

\begin_layout Chapter
Row Echelon Form
\end_layout

\begin_layout Standard
A matrix is said to be in row 
\emph on
echelon form
\emph default
 if each non-zero row has more leading zeros than the previous row.
 Row-echelon form is the key idea underlying the Gaussian elimination algorithm
 and LU factorization.
\begin_inset Newline newline
\end_inset

Let us give the precise definition.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $(M_{ij})$
\end_inset

 be an 
\begin_inset Formula $n\times m$
\end_inset

 matrix.
 For each row 
\begin_inset Formula $i=1,\ldots,n$
\end_inset

 define the pivot position 
\begin_inset Formula $P_{i}$
\end_inset

 to be either the minimum value of 
\begin_inset Formula $j=1,\ldots,m$
\end_inset

 for which 
\begin_inset Formula $M_{ij}\neq0$
\end_inset

, or 
\begin_inset Formula $\infty$
\end_inset

 if the row consists entirely of zeros.
 A matrix is in echelon form if for all 
\begin_inset Formula $i>1$
\end_inset

, either 
\begin_inset Formula $P_{i}=\infty$
\end_inset

 or 
\begin_inset Formula $P_{i-1}<P_{i}$
\end_inset

 
\end_layout

\begin_layout Chapter
Gaussian Elimination
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
x}{
\backslash
boldsymbol{x}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset FormulaMacro
\renewcommand{\a}{\boldsymbol{a}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\b}{\boldsymbol{b}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\c}{\boldsymbol{c}}
\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
e}{
\backslash
boldsymbol{e}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
newcommand{
\backslash
R}{
\backslash
mathbf{R}}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\theenumi}{\roman{enumi}}
\end_inset

 
\begin_inset FormulaMacro
\renewcommand{\labelenumi}{(\theenumi)}
\end_inset


\end_layout

\begin_layout Standard

\emph on
Row reduction
\emph default
, also known as 
\emph on
Gaussian elimination
\emph default
, is an algorithm for solving a system of linear equations 
\begin_inset Formula 
\[
\begin{array}{ccccccccl}
a_{11}x_{1} & + & a_{12}x_{2} & + & \ldots & + & a_{1m}x_{m} & = & b_{1}\\
a_{21}x_{1} & + & a_{22}x_{2} & + & \ldots & + & a_{2m}x_{m} & = & b_{2}\\
\vdots &  & \vdots &  & \ddots &  & \vdots &  & \vdots\\
a_{n1}x_{1} & + & a_{n2}x_{2} & + & \ldots & + & a_{nm}x_{m} & = & b_{n}
\end{array}
\]

\end_inset

To describe row reduction, it is convenient to formulate a linear system
 as a single matrix-vector equation 
\begin_inset Formula $Ax=b,$
\end_inset

 where 
\begin_inset Formula 
\[
A=\begin{bmatrix}a_{11} & a_{12} & \cdots & a_{1m}\\
a_{21} & a_{22} & \cdots & a_{2m}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \cdots & a_{nm}
\end{bmatrix},\qquad b=\begin{bmatrix}b_{1}\\
b_{2}\\
\vdots\\
b_{n}
\end{bmatrix},\qquad x=\begin{bmatrix}x_{1}\\
x_{2}\\
\vdots\\
x_{m}
\end{bmatrix}
\]

\end_inset

are, respectively, the 
\begin_inset Formula $n\times m$
\end_inset

 matrix of coefficients of the linear system, the 
\begin_inset Formula $n$
\end_inset

-place column vector of the scalars from the right-hand of the equations,
 and the 
\begin_inset Formula $m$
\end_inset

-place column vector of unknowns.
\end_layout

\begin_layout Standard
The method consists of combining the coefficient matrix 
\begin_inset Formula $A$
\end_inset

 with the right hand vector 
\begin_inset Formula $b$
\end_inset

 to form the 
\begin_inset Quotes eld
\end_inset

augmented
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $n\times(m+1)$
\end_inset

 matrix
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{bmatrix}A & b\end{bmatrix}=\begin{bmatrix}a_{11} & a_{12} & \cdots & a_{1m} & b_{1}\\
a_{21} & a_{22} & \cdots & a_{2m} & b_{2}\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
a_{n1} & a_{n2} & \cdots & a_{nm} & b_{n}
\end{bmatrix}=\begin{bmatrix}R_{1}\\
R_{2}\\
\vdots\\
R_{n},
\end{bmatrix}
\]

\end_inset

where each 
\begin_inset Formula $R_{i}$
\end_inset

 is the 
\begin_inset Formula $m+1$
\end_inset

-place row vector corresponding to row 
\begin_inset Formula $i$
\end_inset

 of the augmented matrix.
\end_layout

\begin_layout Standard
A sequence of elementary row operations is then applied to this matrix so
 as to transform it to row echelon form.
 The elementary operations are: 
\end_layout

\begin_layout Itemize

\series bold
row scaling:
\series default
 the multiplication a row by a nonzero scalar; 
\begin_inset Formula 
\[
R_{i}\mapsto cR_{i},\quad c\neq0;
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
row exchange:
\series default
 the exchanges of two rows; 
\begin_inset Formula 
\[
R_{i}\leftrightarrow R_{j};
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
row replacement:
\series default
 the addition of a multiple of one row to another row; 
\begin_inset Formula 
\[
R_{i}\mapsto R_{i}+cR_{j},\quad c\neq0,\; i\neq j.
\]

\end_inset


\end_layout

\begin_layout Standard
Note that these operations are 
\begin_inset Quotes eld
\end_inset

legal
\begin_inset Quotes erd
\end_inset

 because 
\begin_inset Formula $x$
\end_inset

 is a solution of the transformed system if and only if it is a solution
 of the initial system.
\end_layout

\begin_layout Standard
If the number of equations equals the number of variables (
\begin_inset Formula $m=n$
\end_inset

), and if the coefficient matrix 
\begin_inset Formula $A$
\end_inset

 is non-singular, then the algorithm will terminate when the augmented matrix
 has the following form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{bmatrix}a'_{11} & a'_{12} & \cdots & a'_{1n} & b_{1}\\
0 & a_{22}' & \cdots & a_{2n}' & b_{2}'\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & \cdots & a_{nn}' & b_{n}'
\end{bmatrix}
\]

\end_inset

With these assumptions, there exists a unique solution, which can be obtained
 from the above matrix by back substitution.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% Assume we have transformed the first column, and we want to continue the
 elimination with the
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% following matrix
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% $$ 
\backslash
begin{bmatrix}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% a_{11} & a_{12} & 
\backslash
cdots & a_{1n} & b_1 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 0 & a_{22}' & 
\backslash
cdots & a_{2n}' & b_2' 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 0 & a_{32}' & 
\backslash
cdots & a_{3n}' & b_3' 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 
\backslash
vdots & 
\backslash
vdots & 
\backslash
ddots & 
\backslash
vdots & 
\backslash
vdots 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 0 & a_{n2}' & 
\backslash
cdots & a_{nn}' & b_n'
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% 
\backslash
end{bmatrix} $$
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% To zero $a_{32}'$, we want to divide the second row by the ``pivot''
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% $a_{22}'$ , multiply it with $a_{32}'$, and subtract it from the third
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% row.
 If the pivot is zero, we have to swap two rows.
 This procedure
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% frequently breaks down, not only for ill-conditioned matrices.
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% Therefore, most programs perform partial pivoting or complete pivoting
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% (normally not necessary.)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the general case, the termination procedure is somewhat more complicated.
 First recall that a matrix is in echelon form if each row has more leading
 zeros than the rows above it.
 A pivot is the leading non-zero entry of some row.
 We then have 
\end_layout

\begin_layout Itemize
If there is a pivot in the last column, the system is inconsistent ; there
 will be no solutions.
 
\end_layout

\begin_layout Itemize
If that is not the case, then the general solution will have 
\begin_inset Formula $d$
\end_inset

 degrees of freedom, where 
\begin_inset Formula $d$
\end_inset

 is the number of columns from 
\begin_inset Formula $1$
\end_inset

 to 
\begin_inset Formula $m$
\end_inset

 that have no pivot.
 To be more precise, the general solution will have the form of one particular
 solution plus an arbitrary linear combination of 
\begin_inset Formula $d$
\end_inset

 linearly independent 
\begin_inset Formula $n$
\end_inset

-vectors.
\end_layout

\begin_deeper
\begin_layout Standard
In even more prosaic language, the variables in the non-pivot columns are
 to be considered 
\begin_inset Quotes eld
\end_inset

free variables
\begin_inset Quotes erd
\end_inset

 and should be 
\begin_inset Quotes eld
\end_inset

moved
\begin_inset Quotes erd
\end_inset

 to the right-hand side of the equation.
 The general solution is then obtained by arbitrarily choosing values of
 the free variables, and then solving for the remaining 
\begin_inset Quotes eld
\end_inset

non-free
\begin_inset Quotes erd
\end_inset

 variables that reside in the pivot columns.
 
\end_layout

\end_deeper
\begin_layout Standard
A variant of Gaussian elimination is Gauss-Jordan elimination.
 In this variation we reduce to echelon form, and then if the system proves
 to be consistent, continue to apply the elementary row operations until
 the augmented matrix is in 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 reduced echelon form
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

.
 This means that not only does each pivot have all zeroes below it, but
 that each pivot also has all zeroes above it.
\end_layout

\begin_layout Standard
In essence, Gauss-Jordan elimination performs the back substitution; the
 values of the unknowns can be read off directly from the terminal augmented
 matrix.
 Not surprisingly, Gauss-Jordan elimination is slower than Gaussian elimination.
 It is useful, however, for solving systems on paper.
\end_layout

\begin_layout Subsection*
Step 1: Write out the 
\emph on
augmented matrix
\end_layout

\begin_layout Standard
A system of linear equation is generally of the form 
\begin_inset Formula 
\begin{equation}
A\,\x=\b\,,\label{e.linear}
\end{equation}

\end_inset

where 
\begin_inset Formula $A\in M(n\times m)$
\end_inset

 and 
\begin_inset Formula $\b\in\R^{n}$
\end_inset

 are given, and 
\begin_inset Formula $\x=(x_{1},\dots,x_{m})^{T}$
\end_inset

 is the vector of unknowns.
 For example, the system 
\begin_inset Formula 
\begin{align*}
x_{2}+2\, x_{3}-x_{4} & =1\\
x_{1}+x_{3}+x_{4} & =4\\
-x_{1}+x_{2}-x_{4} & =2\\
2\, x_{2}+3\, x_{3}-x_{4} & =7
\end{align*}

\end_inset

can be written in the form 
\begin_inset CommandInset ref
LatexCommand eqref
reference "e.linear"

\end_inset

 with 
\begin_inset Formula 
\[
A=\begin{pmatrix}0 & 1 & 2 & -1\\
1 & 0 & 1 & 1\\
-1 & 1 & 0 & -1\\
0 & 2 & 3 & -1
\end{pmatrix}\,,\qquad\b=\begin{pmatrix}1\\
4\\
2\\
7
\end{pmatrix}\,.
\]

\end_inset

To simplify notation, we write 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $\b$
\end_inset

 into a single 
\emph on
augmented matrix
\emph default
, 
\begin_inset Formula 
\begin{equation}
M=\left(\begin{matrix}0 & 1 & 2 & -1\\
1 & 0 & 1 & 1\\
-1 & 1 & 0 & -1\\
0 & 2 & 3 & -1
\end{matrix}\right.\left|\left.\begin{matrix}1\\
4\\
2\\
7
\end{matrix}\right)\right.\,.\label{e.m}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection*
Step 2: Bring 
\begin_inset Formula $M$
\end_inset

 into 
\emph on
reduced row echelon form
\end_layout

\begin_layout Standard
The goal of this step is to bring the augmented matrix into 
\emph on
reduced row echelon form
\emph default
.
 A matrix is in this form if 
\end_layout

\begin_layout Itemize
the first non-zero entry of each row is 
\begin_inset Formula $1$
\end_inset

, this element is referred to as the 
\emph on
pivot
\emph default
, 
\end_layout

\begin_layout Itemize
each pivot is the only non-zero entry in its column, 
\end_layout

\begin_layout Itemize
each row has at least as many leading zeros as the previous row.
 
\end_layout

\begin_layout Standard
For example, the following matrix is in row echelon form, where 
\begin_inset Formula $*$
\end_inset

 could be any, possibly non-zero, number: 
\begin_inset Formula 
\[
\begin{pmatrix}0 & 1 & * & 0 & * & * & 0\\
0 & 0 & 0 & 1 & * & * & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0 & 0 & 0
\end{pmatrix}
\]

\end_inset

Three types of 
\emph on
elementary row operations
\emph default
 are permitted in this process, namely 
\end_layout

\begin_layout Itemize
(A) exchanging two rows of 
\begin_inset Formula $M$
\end_inset

, 
\end_layout

\begin_layout Itemize
(B) multiplying a row by a non-zero scalar,.
 
\end_layout

\begin_layout Itemize
(C) adding a multiple of one row to another row.
 
\end_layout

\begin_layout Standard
As an example, we row-reduce the augmented matrix 
\begin_inset CommandInset ref
LatexCommand eqref
reference "e.m"

\end_inset

: 
\begin_inset Formula 
\begin{align*}
 & \left(\begin{matrix}0 & 1 & 2 & -1\\
1 & 0 & 1 & 1\\
-1 & 1 & 0 & -1\\
0 & 2 & 3 & -1
\end{matrix}\right.\left|\left.\begin{matrix}1\\
4\\
2\\
7
\end{matrix}\right)\right.\xrightarrow{\text{reorder rows}}\left(\begin{matrix}1 & 0 & 1 & 1\\
-1 & 1 & 0 & -1\\
0 & 1 & 2 & -1\\
0 & 2 & 3 & -1
\end{matrix}\right.\left|\left.\begin{matrix}4\\
2\\
1\\
7
\end{matrix}\right)\right.\xrightarrow{\text{R1}+\text{R2}\to\text{R2}}\\
 & \left(\begin{matrix}1 & 0 & 1 & 1\\
0 & 1 & 1 & 0\\
0 & 1 & 2 & -1\\
0 & 2 & 3 & -1
\end{matrix}\right.\left|\left.\begin{matrix}4\\
6\\
1\\
7
\end{matrix}\right)\right.\xrightarrow{\substack{\text{R3}-\text{R2}\to\text{R3}\\
\text{R4}-2\,\text{R2}\to\text{R4}
}
}\left(\begin{matrix}1 & 0 & 1 & 1\\
0 & 1 & 1 & 0\\
0 & 0 & 1 & -1\\
0 & 0 & 1 & -1
\end{matrix}\right.\left|\left.\begin{matrix}4\\
6\\
-5\\
-5
\end{matrix}\right)\right.\xrightarrow{\text{R4}-\text{R3}\to\text{R4}}\\
 & \left(\begin{matrix}1 & 0 & 1 & 1\\
0 & 1 & 1 & 0\\
0 & 0 & 1 & -1\\
0 & 0 & 0 & 0
\end{matrix}\right.\left|\left.\begin{matrix}4\\
6\\
-5\\
0
\end{matrix}\right)\right.\xrightarrow{\substack{\text{R1}-\text{R3}\to\text{R1}\\
\text{R2}-\text{R3}\to\text{R2}
}
}\left(\begin{matrix}1 & 0 & 0 & 2\\
0 & 1 & 0 & 1\\
0 & 0 & 1 & -1\\
0 & 0 & 0 & 0
\end{matrix}\right.\left|\left.\begin{matrix}9\\
11\\
-5\\
0
\end{matrix}\right)\right.
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection*
Step 3: Zero, one, or many solutions?
\end_layout

\begin_layout Standard
There are two fundamentally different situations: 
\end_layout

\begin_layout Itemize
The matrix 
\begin_inset Formula $A$
\end_inset

 is 
\emph on
regular
\emph default
.
 In this case, the left-hand block of 
\begin_inset Formula $M$
\end_inset

 has been reduced to the identity matrix.
 There is exactly one solution, independent of which vector 
\begin_inset Formula $\b$
\end_inset

 you started out with.
\end_layout

\begin_layout Itemize
The matrix 
\begin_inset Formula $A$
\end_inset

 is 
\emph on
degenerate
\emph default
.
 In this case, the left-hand block of the row-reduced augmented matrix has
 more columns than non-zero rows.
 Then, dependent on which vector 
\begin_inset Formula $\b$
\end_inset

 you started out with, there is either no solution at all (the system is
 
\emph on
inconsistent
\emph default
), or an infinite number of solutions (the system is 
\emph on
underdetermined
\emph default
).
 
\end_layout

\begin_layout Standard
If the rightmost column of the row-reduced augmented matrix has a nonzero
 entry in a row that is otherwise zero, the system is inconsistent.
\end_layout

\begin_layout Standard
Otherwise, the general solution has the following structure.
 It is the sum of a 
\emph on
particular solution
\emph default
 of the 
\emph on
inhomogeneous equation
\emph default
 
\begin_inset Formula $A\x=\b$
\end_inset

 and the 
\emph on
general solution
\emph default
 of the 
\emph on
homogeneous equation
\emph default
 
\begin_inset Formula $A\x=0$
\end_inset

.
\end_layout

\begin_layout Subsection*
Step 4: Write out the solution
\end_layout

\begin_layout Itemize
If the left-hand block of the row-reduced matrix is not square, make it
 square by adding or removing rows of zeros.
 This has to be done in such a way that the leading 
\begin_inset Formula $1$
\end_inset

 in each row (the 
\emph on
pivot
\emph default
) lies on the diagonal! 
\end_layout

\begin_layout Itemize
The rightmost column of the row-reduced augmented matrix is a particular
 solution.
 
\end_layout

\begin_layout Itemize
To find a basis for the general solution of the homogeneous system, proceed
 as follows: Take every column of the row-reduced augmented matrix that
 has a zero on the diagonal.
 Replace that zero by 
\begin_inset Formula $-1$
\end_inset

.
 The set of these column vectors is the basis you need.
 
\end_layout

\begin_layout Standard
In the example above, a particular solution is 
\begin_inset Formula $(9,11,-5,0)^{T}$
\end_inset

 and the general solution of the homogeneous equation is a one-dimensional
 subspace with basis vector 
\begin_inset Formula $(2,1,-1,-1)^{T}$
\end_inset

.
 Therefore, the general solution to the inhomogeneous equation 
\begin_inset Formula $A\x=\b$
\end_inset

 is the line 
\begin_inset Formula 
\[
\x=\begin{pmatrix}9\\
11\\
-5\\
0
\end{pmatrix}+\lambda\begin{pmatrix}2\\
1\\
-1\\
-1
\end{pmatrix}\,.
\]

\end_inset

Another example: Assume that the row-reduced matrix is 
\begin_inset Formula 
\[
\left(\begin{matrix}0 & 0 & 1 & -3 & 0 & 4\\
0 & 0 & 0 & 0 & 1 & 6
\end{matrix}\right.\left|\left.\begin{matrix}-3\\
7
\end{matrix}\right)\right.\,.
\]

\end_inset

Padding the matrix with the required rows of zeros gives 
\begin_inset Formula 
\[
\left(\begin{matrix}0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 1 & -3 & 0 & 4\\
0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 1 & 6\\
0 & 0 & 0 & 0 & 0 & 0
\end{matrix}\right.\left|\left.\begin{matrix}0\\
0\\
-3\\
0\\
7\\
0
\end{matrix}\right)\right.\,,
\]

\end_inset

and the general solution is 
\begin_inset Formula 
\[
\x=\begin{pmatrix}0\\
0\\
-3\\
0\\
7\\
0
\end{pmatrix}+\lambda_{1}\begin{pmatrix}-1\\
0\\
0\\
0\\
0\\
0
\end{pmatrix}+\lambda_{2}\begin{pmatrix}0\\
-1\\
0\\
0\\
0\\
0
\end{pmatrix}+\lambda_{3}\begin{pmatrix}0\\
0\\
-3\\
-1\\
0\\
0
\end{pmatrix}+\lambda_{4}\begin{pmatrix}0\\
0\\
4\\
0\\
6\\
-1
\end{pmatrix}\,.
\]

\end_inset


\end_layout

\begin_layout Subsection*
Step 5: Check your solution
\end_layout

\begin_layout Standard
By multiplying 
\begin_inset Formula $A$
\end_inset

 with the vectors representing the solution, you can easily verify that
 the computation is correct.
 In our example, 
\begin_inset Formula 
\begin{gather*}
A\begin{pmatrix}9\\
11\\
-5\\
0
\end{pmatrix}=\begin{pmatrix}0 & 1 & 2 & -1\\
1 & 0 & 1 & 1\\
-1 & 1 & 0 & -1\\
0 & 2 & 3 & -1
\end{pmatrix}\begin{pmatrix}9\\
11\\
-5\\
0
\end{pmatrix}=\begin{pmatrix}1\\
4\\
2\\
7
\end{pmatrix}=\b\,,\\
A\begin{pmatrix}2\\
1\\
-1\\
-1
\end{pmatrix}=\begin{pmatrix}0 & 1 & 2 & -1\\
1 & 0 & 1 & 1\\
-1 & 1 & 0 & -1\\
0 & 2 & 3 & -1
\end{pmatrix}\begin{pmatrix}2\\
1\\
-1\\
-1
\end{pmatrix}=\begin{pmatrix}0\\
0\\
0\\
0
\end{pmatrix}\,.
\end{gather*}

\end_inset


\end_layout

\begin_layout Section
Properties of the Matrix Inverse
\end_layout

\begin_layout Standard
Given a matrix 
\begin_inset Formula $A\in M(n\times n)$
\end_inset

, its inverse 
\begin_inset Formula $A^{-1}$
\end_inset

 is the matrix with the property that 
\begin_inset Formula 
\[
AA^{-1}=I=A^{-1}A\,.
\]

\end_inset

Note the following identities (see Riley, Hobson & Bence, p.
\begin_inset space \space{}
\end_inset

271): 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $(A^{-1})^{-1}=A$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $(A^{T})^{-1}=(A^{-1})^{T}$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $(A^{H})^{-1}=(A^{-1})^{H}$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $(AB)^{-1}=B^{-1}A^{-1}$
\end_inset

 
\end_layout

\begin_layout Standard
Moreover, 
\begin_inset Formula $A$
\end_inset

 is invertible, then the solution to the system of linear equations 
\begin_inset Formula $A\x=\b$
\end_inset

 can be written 
\begin_inset Formula 
\[
\x=A^{-1}\b\,.
\]

\end_inset

This observation tells us how we can compute the matrix inverse once we
 know how to solve linear equations.
 We begin by writing 
\begin_inset Formula $\b$
\end_inset

 as a linear combination of the standard unit vectors 
\begin_inset Formula $\e_{1},\dots,\e_{n}$
\end_inset

, 
\begin_inset Formula 
\[
\b=b_{1}\e_{1}+\dots+\b_{n}\e_{n}\,.
\]

\end_inset

Then 
\begin_inset Formula 
\[
\x=A^{-1}\,\bigl(b_{1}\e_{1}+\dots+\b_{n}\e_{n}\bigr)=b_{1}A^{-1}\e_{1}+\dots+b_{n}A^{-1}\e_{n}\,.
\]

\end_inset

Notice that the vectors 
\begin_inset Formula $\x_{1}=A^{-1}\e_{1},\dots\x_{n}=A^{-1}\e_{n}$
\end_inset

 are the columns of 
\begin_inset Formula $A^{-1}$
\end_inset

.
 At the same time, we see that these vectors are the solutions to the 
\begin_inset Formula $n$
\end_inset

 linear equations 
\begin_inset Formula 
\[
A\x_{1}=\e_{1}\,,\quad\cdots\quad A\x_{n}=\e_{n}\,.
\]

\end_inset

To find 
\begin_inset Formula $A^{-1}$
\end_inset

 we therefore have to simultaneously solve 
\begin_inset Formula $n$
\end_inset

 inhomogeneous linear equations, which is the essence of the following procedure.
\end_layout

\begin_layout Section
Computing the inverse
\end_layout

\begin_layout Subsection*
Form the augmented matrix
\end_layout

\begin_layout Standard
Write the matrix 
\begin_inset Formula $A$
\end_inset

 to the left, and the identity matrix to the right.
 For example, when 
\begin_inset Formula 
\[
A=\begin{pmatrix}0 & \tfrac{1}{2} & -\tfrac{1}{2}\\
1 & 0 & 1\\
2 & \tfrac{1}{2} & 1
\end{pmatrix}\,,
\]

\end_inset

write 
\begin_inset Formula 
\[
M=\left(\begin{matrix}0 & \tfrac{1}{2} & -\tfrac{1}{2}\\
1 & 0 & 1\\
2 & \tfrac{1}{2} & 1
\end{matrix}\right.\left|\left.\begin{matrix}1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{matrix}\right)\right.\,.
\]

\end_inset


\end_layout

\begin_layout Subsection*
Reduce to row-echelon form
\end_layout

\begin_layout Standard
Use elementary row transformations on the augmented matrix to bring the
 left-hand matrix into row echelon form.
 
\end_layout

\begin_layout Itemize
If you can obtain the identity matrix in the left-hand block, the matrix
 is invertible and the final right-hand block is 
\begin_inset Formula $A^{-1}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If you obtain a row of zeros in the left-hand block, i.e.
\begin_inset space \space{}
\end_inset

if 
\begin_inset Formula $\operatorname{rank}A<n$
\end_inset

, then 
\begin_inset Formula $A$
\end_inset

 is not invertible.
 
\end_layout

\begin_layout Standard
Let's work out the example: 
\begin_inset Formula 
\begin{align*}
 & \left(\begin{matrix}0 & \tfrac{1}{2} & -\tfrac{1}{2}\\
1 & 0 & 1\\
2 & \tfrac{1}{2} & 1
\end{matrix}\right.\left|\left.\begin{matrix}1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{matrix}\right)\right.\xrightarrow{\text{reorder rows}}\left(\begin{matrix}1 & 0 & 1\\
2 & \tfrac{1}{2} & 1\\
0 & \tfrac{1}{2} & -\tfrac{1}{2}
\end{matrix}\right.\left|\left.\begin{matrix}0 & 1 & 0\\
0 & 0 & 1\\
1 & 0 & 0
\end{matrix}\right)\right.\xrightarrow{\text{R2}-2\,\text{R1}\to\text{R2}}\\
 & \left(\begin{matrix}1 & 0 & 1\\
0 & \tfrac{1}{2} & -1\\
0 & \tfrac{1}{2} & -\tfrac{1}{2}
\end{matrix}\right.\left|\left.\begin{matrix}0 & 1 & 0\\
0 & -2 & 1\\
1 & 0 & 0
\end{matrix}\right)\right.\xrightarrow{\text{R3}-\text{R2}\to\text{R3}}\left(\begin{matrix}1 & 0 & 1\\
0 & \tfrac{1}{2} & -1\\
0 & 0 & \tfrac{1}{2}
\end{matrix}\right.\left|\left.\begin{matrix}0 & 1 & 0\\
0 & -2 & 1\\
1 & 2 & -1
\end{matrix}\right)\right.\xrightarrow{\substack{2\,\text{R2}\to\text{R2}\\
2\,\text{R3}\to\text{R3}
}
}\\
 & \left(\begin{matrix}1 & 0 & 1\\
0 & 1 & -2\\
0 & 0 & 1
\end{matrix}\right.\left|\left.\begin{matrix}0 & 1 & 0\\
0 & -4 & 2\\
2 & 4 & -2
\end{matrix}\right)\right.\xrightarrow{\substack{\text{R1}-\text{R3}\to\text{R1}\\
\text{R2}+2\,\text{R3}\to\text{R2}
}
}\left(\begin{matrix}1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{matrix}\right.\left|\left.\begin{matrix}-2 & -3 & 2\\
4 & 4 & -2\\
2 & 4 & -2
\end{matrix}\right)\right.
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection*
Check you solution
\end_layout

\begin_layout Standard
We see that 
\begin_inset Formula 
\[
A^{-1}=\begin{pmatrix}-2 & -3 & 2\\
4 & 4 & -2\\
2 & 4 & -2
\end{pmatrix}
\]

\end_inset

and it is easy to check that 
\begin_inset Formula 
\[
AA^{-1}=\begin{pmatrix}0 & \tfrac{1}{2} & -\tfrac{1}{2}\\
1 & 0 & 1\\
2 & \tfrac{1}{2} & 1
\end{pmatrix}\begin{pmatrix}-2 & -3 & 2\\
4 & 4 & -2\\
2 & 4 & -2
\end{pmatrix}=\begin{pmatrix}1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}=I\,.
\]

\end_inset


\end_layout

\begin_layout Example
Consider the real matrix 
\begin_inset Formula 
\[
A(t):=\begin{pmatrix}1 & 1 & 1\\
t & 2t & 2\\
t+1 & 0 & 2t
\end{pmatrix},
\]

\end_inset

which depends on a real valued parameter
\begin_inset space ~
\end_inset


\begin_inset Formula $t$
\end_inset

.
 We want to find all solutions of the homogenous linear system defined by
 
\begin_inset Formula $A$
\end_inset

 depending on the parameter
\begin_inset space ~
\end_inset


\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
Therefore, we use the Algorithm Gauss:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{alignat*}1   
\end_layout

\begin_layout Plain Layout

A(t)=
\backslash
begin{gmatrix}[p]
\end_layout

\begin_layout Plain Layout

1 & 1 & 1 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

t & 2t & 2 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

t+1 & 0 & 2t    
\end_layout

\begin_layout Plain Layout


\backslash
rowops    
\end_layout

\begin_layout Plain Layout


\backslash
add[-t]{0}{1}    
\end_layout

\begin_layout Plain Layout


\backslash
add[-(t+1)]{0}{2}   
\end_layout

\begin_layout Plain Layout


\backslash
end{gmatrix}
\backslash
kern-6.23pt
\backslash
leadsto&   
\end_layout

\begin_layout Plain Layout


\backslash
begin{gmatrix}[p]    
\end_layout

\begin_layout Plain Layout

1 & 1 & 1 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

0 & t & 2-t 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

0 & -t-1 & t-1   
\end_layout

\begin_layout Plain Layout


\backslash
rowops    
\end_layout

\begin_layout Plain Layout


\backslash
add12    
\end_layout

\begin_layout Plain Layout


\backslash
mult{2}{
\backslash
cdot(-1)}   
\end_layout

\begin_layout Plain Layout


\backslash
end{gmatrix}
\backslash

\backslash
   
\end_layout

\begin_layout Plain Layout


\backslash
leadsto&
\end_layout

\begin_layout Plain Layout


\backslash
begin{gmatrix}[p]    
\end_layout

\begin_layout Plain Layout

1 & 1 & 1 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

0 & t & 2-t 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

0 & 1 & -1    
\end_layout

\begin_layout Plain Layout


\backslash
rowops    
\end_layout

\begin_layout Plain Layout


\backslash
swap12    
\end_layout

\begin_layout Plain Layout


\backslash
add[-t]12    
\end_layout

\begin_layout Plain Layout


\backslash
mult2{:2}   
\end_layout

\begin_layout Plain Layout


\backslash
end{gmatrix}
\backslash

\backslash
   
\end_layout

\begin_layout Plain Layout


\backslash
leadsto&
\end_layout

\begin_layout Plain Layout


\backslash
begin{pmatrix}    
\end_layout

\begin_layout Plain Layout

1 & 1 & 1 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

0 & 1 & -1 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

0 & 0 & 1   
\end_layout

\begin_layout Plain Layout


\backslash
end{pmatrix}.
  
\end_layout

\begin_layout Plain Layout


\backslash
end{alignat*}  
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
LU Decomposition
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\rT}{{\scriptscriptstyle \mathrm{T}}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\row}{\mathrm{row}}
\end_inset


\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times m$
\end_inset

 matrix.
 An LU decomposition (sometimes also called an LU factorization) of 
\begin_inset Formula $A$
\end_inset

, if it exists, is an 
\begin_inset Formula $n\times n$
\end_inset

 unit lower triangular matrix 
\begin_inset Formula $L$
\end_inset

 and an 
\begin_inset Formula $n\times m$
\end_inset

 matrix U, in (upper) echelon form, such that 
\begin_inset Formula 
\[
A=LU
\]

\end_inset


\end_layout

\begin_layout Standard
The LU factorization is closely related to the row reduction algorithm.
 In a very real sense, the factorization is a record of the steps taken
 in row reducing a matrix to echelon form.
 The matrix 
\begin_inset Formula $L$
\end_inset

 
\begin_inset Quotes eld
\end_inset

encodes
\begin_inset Quotes erd
\end_inset

 the sequence of row replacement operations that row reduce the given matrix
 
\begin_inset Formula $A$
\end_inset

 to echelon form 
\begin_inset Formula $U$
\end_inset

.
\end_layout

\begin_layout Proposition
Suppose that 
\begin_inset Formula $A=LU$
\end_inset

 is an LU factorization, and let 
\begin_inset Formula $L_{ij}$
\end_inset

 denote the entries of 
\begin_inset Formula $L$
\end_inset

.
 Then, the row reduction 
\begin_inset Formula $A\stackrel{\rho}{\Longrightarrow}U$
\end_inset

 is accomplished by the following sequence 
\begin_inset Formula $\rho$
\end_inset

 of 
\begin_inset Formula $\tfrac{1}{2}n(n-1)$
\end_inset

 row replacement operations: 
\begin_inset Formula 
\begin{align*}
\hskip2em & \row_{j}\mapsto\row_{j}-L_{j1}\;\row_{1},\quad j=2,\ldots,n;\\
 & \row_{j}\mapsto\row_{j}-L_{j2}\;\row_{2},\quad j=3,\ldots,n;\\
 & \hskip3em\vdots\\
 & \row_{j}\mapsto\row_{j}-L_{jk}\;\row_{k},\quad j=k+1,\ldots,n,\quad k=1,\ldots,n-1\\
 & \hskip3em\vdots
\end{align*}

\end_inset

 
\end_layout

\begin_layout Note*
the first 
\begin_inset Formula $n-1$
\end_inset

 steps clear out column 
\begin_inset Formula $1$
\end_inset

, the next 
\begin_inset Formula $n-2$
\end_inset

 steps clear out column 
\begin_inset Formula $2$
\end_inset

, etc.
 
\end_layout

\begin_layout Proposition
Not every matrix admits an LU factorization.
 Indeed, an LU factorization exists if and only if 
\begin_inset Formula $A$
\end_inset

 can be reduced to echelon without using row exchange operations.
 However, if an LU factorization exists, then it is unique.
 
\end_layout

\begin_layout Standard
In the most general case, one has to employ row exchange operations.
\end_layout

\begin_layout Proposition
Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times m$
\end_inset

 matrix.
 Then, there exists an 
\begin_inset Formula $n\times n$
\end_inset

 permutation matrix 
\begin_inset Formula $P$
\end_inset

 (indeed, many such) such that the matrix 
\begin_inset Formula $PA$
\end_inset

 admits an LU factorization, i.e., there exist matrices 
\begin_inset Formula $P,L,U$
\end_inset

 such that 
\begin_inset Formula 
\[
PA=LU.
\]

\end_inset


\end_layout

\begin_layout Standard
The key idea behind LU factorization is that one does not need to employ
 row scalings to do row reduction until the second half (the back-substitution
 phase) of the algorithm.
 This has significant implication for numerical stability of the algorithm.
\end_layout

\begin_layout Standard
The LU decomposition of a given matrix 
\begin_inset Formula $A$
\end_inset

 is useful for the solution of the systems of linear equations of the form
 
\begin_inset Formula $Ax=b$
\end_inset

.
 Indeed, it suffices to first solve the linear system 
\begin_inset Formula $Ly=b$
\end_inset

, and second, to solve the system 
\begin_inset Formula $Ux=y$
\end_inset

.
 This two-step procedure is easy to implement, because owing to the lower
 and upper-triangular nature of the matrices 
\begin_inset Formula $L$
\end_inset

 and 
\begin_inset Formula $U$
\end_inset

, the required row operations are determined, more or less, directly from
 the entries of 
\begin_inset Formula $L$
\end_inset

 and 
\begin_inset Formula $U$
\end_inset

.
 Indeed, the first step, 
\begin_inset Formula 
\[
[\, L\; b\,]\stackrel{\rho_{1}}{\Longrightarrow}[\, I\; y\,]
\]

\end_inset

a sequence of row operations 
\begin_inset Formula $\rho_{1}$
\end_inset

, and the second step 
\begin_inset Formula 
\[
[\, U\; y\,]\stackrel{\rho_{2}}{\Longrightarrow}[\, E\; x_{0}\,]
\]

\end_inset

a sequence of row operations 
\begin_inset Formula $\rho_{2}$
\end_inset

, are exactly the same row operations one has to perform to row reduce 
\begin_inset Formula $A$
\end_inset

 directly to reduced echelon form 
\begin_inset Formula $E$
\end_inset

: 
\begin_inset Formula 
\[
[\, A\; b\,]\stackrel{\rho_{1}}{\Longrightarrow}[\, U\; y\,]\stackrel{\rho_{2}}{\Longrightarrow}[\, E\; x_{0}\,].
\]

\end_inset


\end_layout

\begin_layout Note*
\begin_inset Formula $x_{0}$
\end_inset

 is the particular solution of 
\begin_inset Formula $Ax=b$
\end_inset

 that sits in the rightmost colulmn of the augmented matrix at the termination
 of the row-reduction algorithm.
 
\end_layout

\begin_layout Chapter
Cholesky Decomposition
\end_layout

\begin_layout Standard
A symmetric and positive definite matrix can be efficiently decomposed into
 a lower and upper triangular matrix.
 For a matrix of any type, this is achieved by the LU decomposition which
 factorizes 
\begin_inset Formula $A=LU$
\end_inset

.
 If 
\begin_inset Formula $A$
\end_inset

 satisfies the above criteria, one can decompose more efficiently into 
\begin_inset Formula $A=LL^{T}$
\end_inset

 where 
\begin_inset Formula $L$
\end_inset

 is a lower triangular matrix with positive diagonal elements.
 
\begin_inset Formula $L$
\end_inset

 is called the 
\emph on
Cholesky triangle
\emph default
.
\end_layout

\begin_layout Standard
To solve 
\begin_inset Formula $Ax=b$
\end_inset

, one solves first 
\begin_inset Formula $Ly=b$
\end_inset

 for 
\begin_inset Formula $y$
\end_inset

, and then 
\begin_inset Formula $L^{T}x=y$
\end_inset

 for 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard
A variant of the Cholesky decomposition is the form 
\begin_inset Formula $A=R^{T}R$
\end_inset

 , where 
\begin_inset Formula $R$
\end_inset

 is upper triangular.
\end_layout

\begin_layout Standard
Cholesky decomposition is often used to solve the normal equations in linear
 least squares problems; they give 
\begin_inset Formula $A^{T}Ax=A^{T}b$
\end_inset

 , in which 
\begin_inset Formula $A^{T}A$
\end_inset

 is symmetric and positive definite.
\end_layout

\begin_layout Standard
To derive 
\begin_inset Formula $A=LL^{T}$
\end_inset

, we simply equate coefficients on both sides of the equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{bmatrix}a_{11} & a_{12} & \cdots & a_{1n}\\
a_{21} & a_{22} & \cdots & a_{2n}\\
a_{31} & a_{32} & \cdots & a_{3n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{bmatrix}=\begin{bmatrix}l_{11} & 0 & \cdots & 0\\
l_{21} & l_{22} & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
l_{n1} & l_{n2} & \cdots & l_{nn}
\end{bmatrix}\begin{bmatrix}l_{11} & l_{21} & \cdots & l_{n1}\\
0 & l_{22} & \cdots & l_{n2}\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & l_{nn}
\end{bmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
Solving for the unknowns (the nonzero 
\begin_inset Formula $l_{ji}$
\end_inset

s), for 
\begin_inset Formula $i=1,\cdots,n$
\end_inset

 and 
\begin_inset Formula $j=i-1,\ldots,n$
\end_inset

, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
l_{ii} & = & \sqrt{\left(a_{ii}-\sum_{k=1}^{i-1}l_{ik}^{2}\right)}\\
l_{ji} & = & \left(a_{ji}-\sum_{k=1}^{i-1}l_{jk}l_{ik}\right)/l_{ii}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Because 
\begin_inset Formula $A$
\end_inset

 is symmetric and positive definite, the expression under the square root
 is always positive, and all 
\begin_inset Formula $l_{ij}$
\end_inset

 are real.
 
\end_layout

\begin_layout Chapter
Gauss Jordan Method
\end_layout

\begin_layout Chapter
Condition Numers
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\norm}[1]{\lVert#1\rVert}
\end_inset


\end_layout

\begin_layout Definition
The 
\emph on
condition number for matrix inversion
\emph default
 with respect to a matrix norm 
\begin_inset Formula $\norm{\cdot}$
\end_inset

 of a square matrix 
\begin_inset Formula $A$
\end_inset

 is defined by 
\begin_inset Formula 
\[
\kappa(A)=\Vert A\Vert\Vert A^{-1}\Vert\,,
\]

\end_inset

if 
\begin_inset Formula $A$
\end_inset

 is non-singular; and 
\begin_inset Formula $\kappa(A)=+\infty$
\end_inset

 if 
\begin_inset Formula $A$
\end_inset

 is singular.
\end_layout

\begin_layout Standard
The condition number is a measure of stability or sensitivity of a matrix
 (or the linear system it represents) to numerical operations.
 In other words, we may not be able to trust the results of computations
 on an ill-conditioned matrix.
\end_layout

\begin_layout Standard
Matrices with condition numbers near 1 are said to be 
\emph on
well-conditioned
\emph default
.
 Matrices with condition numbers much greater than one (such as around 
\begin_inset Formula $10^{5}$
\end_inset

 for a 
\begin_inset Formula $5\times5$
\end_inset

 Hilbert matrix) are said to be 
\emph on
ill-conditioned
\emph default
.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $\kappa(A)$
\end_inset

 is the condition number of 
\begin_inset Formula $A$
\end_inset

, then 
\begin_inset Formula $\kappa(A)$
\end_inset

 measures a sort of inverse distance from 
\begin_inset Formula $A$
\end_inset

 to the set of singular matrices, normalized by 
\begin_inset Formula $\norm A$
\end_inset

.
 Precisely, if 
\begin_inset Formula $A$
\end_inset

 is invertible, and 
\begin_inset Formula $\norm{B-A}<\norm{A^{-1}}^{-1}$
\end_inset

, then 
\begin_inset Formula $B$
\end_inset

 must also be invertible.
 On the other hand, in the case of the 
\begin_inset Formula $2$
\end_inset

-norm, there always exists a singular matrix 
\begin_inset Formula $B$
\end_inset

 such that 
\begin_inset Formula $\norm{B-A}_{2}=\norm{A^{-1}}_{2}^{-1}$
\end_inset

 (so the distance estimate is sharp).
\end_layout

\begin_layout Chapter
Householder Reflections
\end_layout

\begin_layout Standard
This lecture describes the 
\emph on
Householder transformation
\emph default
 
\begin_inset Formula $u=Hv$
\end_inset

, the most frequently used algorithm for performing QR decomposition.
 The key object here is the 
\emph on
Householder matrix
\emph default
 
\begin_inset Formula $H$
\end_inset

, a symmetric and orthogonal matrix of the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H=I-2xx^{T},
\]

\end_inset

where 
\begin_inset Formula $I$
\end_inset

 is the identity matrix and we have used any normalized vector 
\begin_inset Formula $x$
\end_inset

 with 
\begin_inset Formula $||x||_{2}^{2}=x^{T}x=1$
\end_inset

.
\end_layout

\begin_layout Standard
The Householder transformation zeroes the last 
\begin_inset Formula $m-1$
\end_inset

 elements of a column vector below the first element: 
\begin_inset Formula 
\[
\begin{bmatrix}v_{1}\\
v_{2}\\
\vdots\\
v_{m}
\end{bmatrix}\rightarrow\begin{bmatrix}c\\
0\\
\vdots\\
0
\end{bmatrix}\text{with}\; c=\pm||v||_{2}=\pm\left(\sum_{i=1}^{m}v_{i}^{2}\right)^{1/2}
\]

\end_inset

One can verify that 
\begin_inset Formula 
\[
x=f\begin{bmatrix}v_{1}-c\\
v_{2}\\
\vdots\\
v_{m}
\end{bmatrix}\text{with}\; f=\frac{1}{\sqrt{2c(c-v_{1})}}
\]

\end_inset

fulfils 
\begin_inset Formula $x^{T}x=1$
\end_inset

 and that with 
\begin_inset Formula $H=I-2xx^{T}$
\end_inset

 one obtains the vector 
\begin_inset Formula $\begin{bmatrix}c & 0 & \cdots & 0\end{bmatrix}^{T}$
\end_inset

.
\end_layout

\begin_layout Standard
To perform the decomposition of the 
\begin_inset Formula $m\times n$
\end_inset

 matrix 
\begin_inset Formula $A=QR$
\end_inset

 (with 
\begin_inset Formula $m\ge n$
\end_inset

) we construct an 
\begin_inset Formula $m\times m$
\end_inset

 matrix 
\begin_inset Formula $H^{(1)}$
\end_inset

 to change the 
\begin_inset Formula $m-1$
\end_inset

 elements of the first column to zero.
 Similarly, an 
\begin_inset Formula $m-1\times m-1$
\end_inset

 matrix 
\begin_inset Formula $G^{(2)}$
\end_inset

 will change the 
\begin_inset Formula $m-2$
\end_inset

 elements of the second column to zero.
 With 
\begin_inset Formula $G^{(2)}$
\end_inset

 we produce the 
\begin_inset Formula $m\times m$
\end_inset

 matrix 
\begin_inset Formula 
\[
H^{(2)}=\begin{bmatrix}1 & 0 & \cdots & 0\\
0 & \; & \; & \;\\
\vdots & \; & G^{(2)} & \;\\
0 & \; & \; & \;
\end{bmatrix}.
\]

\end_inset

After 
\begin_inset Formula $n$
\end_inset

 such orthogonal transformations (
\begin_inset Formula $n-1$
\end_inset

 times in the case that 
\begin_inset Formula $m=n$
\end_inset

), we let 
\begin_inset Formula 
\[
R=H^{(n)}\cdots H^{(2)}H^{(1)}A.
\]

\end_inset


\begin_inset Formula $R$
\end_inset

 is upper triangular and the orthogonal matrix 
\begin_inset Formula $Q$
\end_inset

 becomes 
\begin_inset Formula 
\[
Q=H^{(1)}H^{(2)}\cdots H^{(n)}.
\]

\end_inset

In practice the 
\begin_inset Formula $H^{(i)}$
\end_inset

 are never explicitly computed.
\end_layout

\begin_layout Chapter
Givens Rotations
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $m\times n$
\end_inset

 matrix with 
\begin_inset Formula $m\ge n$
\end_inset

 and full rank (viz.
 rank 
\begin_inset Formula $n$
\end_inset

).
 An orthogonal matrix triangularization (QR Decomposition) consists of determini
ng an 
\begin_inset Formula $m\times m$
\end_inset

 orthogonal matrix 
\begin_inset Formula $Q$
\end_inset

 such that 
\begin_inset Formula 
\[
Q^{T}A=\begin{bmatrix}R\\
0
\end{bmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
with the 
\begin_inset Formula $n\times n$
\end_inset

 upper triangular matrix 
\begin_inset Formula $R$
\end_inset

.
 One only has then to solve the triangular system 
\begin_inset Formula $Rx=Py$
\end_inset

, where 
\begin_inset Formula $P$
\end_inset

 consists of the first 
\begin_inset Formula $n$
\end_inset

 rows of 
\begin_inset Formula $Q$
\end_inset

.
\end_layout

\begin_layout Standard
Householder transformations clear whole columns except for the first element
 of a vector.
 If one wants to clear parts of a matrix one element at a time, one can
 use Givens rotation, which is particularly practical for parallel implementatio
n .
\end_layout

\begin_layout Standard
A matrix 
\begin_inset Formula 
\[
G=\begin{bmatrix}1 & \cdots & 0 & \cdots & 0 & \cdots & 0\\
\vdots & \ddots & \vdots & \; & \vdots & \; & \vdots\\
0 & \cdots & c & \cdots & s & \cdots & 0\\
\vdots & \; & \vdots & \ddots & \vdots & \; & \vdots\\
0 & \cdots & -s & \cdots & c & \cdots & 0\\
\vdots & \; & \vdots & \; & \vdots & \ddots & \vdots\\
0 & \cdots & 0 & \cdots & 0 & \cdots & 1
\end{bmatrix}
\]

\end_inset

with properly chosen 
\begin_inset Formula $c=\cos(\varphi)$
\end_inset

 and 
\begin_inset Formula $s=\sin(\varphi)$
\end_inset

 for some rotation angle 
\begin_inset Formula $\varphi$
\end_inset

 can be used to zero the element 
\begin_inset Formula $a_{ki}$
\end_inset

.
 The elements can be zeroed column by column from the bottom up in the following
 order: 
\begin_inset Formula 
\[
(m,1),(m,-1,1),\ldots,(2,1),(m,2),\ldots,(3,2),\ldots,(m,n),\ldots,(n+1,n).
\]

\end_inset


\begin_inset Formula $Q$
\end_inset

 is then the product of 
\begin_inset Formula $g=\frac{\left(2m-n-1\right)n}{2}$
\end_inset

 Givens matrices 
\begin_inset Formula $Q=G_{1}G_{2}\cdots G_{g}$
\end_inset

.
\end_layout

\begin_layout Standard
To annihilate the bottom element of a 
\begin_inset Formula $2\times1$
\end_inset

 vector: 
\begin_inset Formula 
\[
\begin{pmatrix}c & s\\
-s & c
\end{pmatrix}^{T}\begin{pmatrix}a\\
b
\end{pmatrix}=\begin{pmatrix}r\\
0
\end{pmatrix}
\]

\end_inset

the conditions 
\begin_inset Formula $sa+cb=0$
\end_inset

 and 
\begin_inset Formula $c^{2}+s^{2}=1$
\end_inset

 give: 
\begin_inset Formula 
\[
c=\frac{a}{\sqrt{a^{2}+b^{2}}},s=\frac{b}{\sqrt{a^{2}+b^{2}}}
\]

\end_inset


\end_layout

\begin_layout Chapter
Singular Value Decomposition
\end_layout

\begin_layout Theorem
Any real 
\begin_inset Formula $m\times n$
\end_inset

 matrix 
\begin_inset Formula $A$
\end_inset

 can be decomposed into 
\begin_inset Formula 
\[
A=USV^{T}
\]

\end_inset

where 
\begin_inset Formula $U$
\end_inset

 is an 
\begin_inset Formula $m\times m$
\end_inset

 orthogonal matrix, 
\begin_inset Formula $V$
\end_inset

 is an 
\begin_inset Formula $n\times n$
\end_inset

 orthogonal matrix, and 
\begin_inset Formula $S$
\end_inset

 is a unique 
\begin_inset Formula $m\times n$
\end_inset

 diagonal matrix with real, non-negative elements 
\begin_inset Formula $\sigma_{i}$
\end_inset

, 
\begin_inset Formula $i=1,\ldots,\min(m,n)$
\end_inset

 in descending order: 
\begin_inset Formula 
\[
\sigma_{1}\ge\sigma_{2}\ge\dots\ge\sigma_{\min(m,n)}\ge0
\]

\end_inset

The 
\begin_inset Formula $\sigma_{i}$
\end_inset

 are the 
\emph on
singular values
\emph default
 of 
\begin_inset Formula $A$
\end_inset

 and the first 
\begin_inset Formula $\min(m,n)$
\end_inset

 columns of 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 are the left and right (respectively) 
\emph on
singular vectors
\emph default
 of 
\begin_inset Formula $A$
\end_inset

.
 
\begin_inset Formula $S$
\end_inset

 has the form: 
\begin_inset Formula 
\[
\begin{bmatrix}\Sigma\\
0
\end{bmatrix}\operatorname{if}m\ge n\;\operatorname{and}\;\begin{bmatrix}\Sigma & 0\end{bmatrix}\operatorname{if}m<n,
\]

\end_inset

where 
\begin_inset Formula $\Sigma$
\end_inset

 is a diagonal matrix with the diagonal elements 
\begin_inset Formula $\sigma_{1},\sigma_{2},\ldots,\sigma_{\min(m,n)}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We assume now 
\begin_inset Formula $m\ge n$
\end_inset

.
 If 
\begin_inset Formula $r=\operatorname{rank}(A)<n$
\end_inset

 , then 
\begin_inset Formula 
\[
\sigma_{1}\ge\sigma_{2}\ge\cdots\ge\sigma_{r}>\sigma_{r+1}=\cdots=\sigma_{n}=0.
\]

\end_inset

If 
\begin_inset Formula $\sigma_{r}\ne0$
\end_inset

 and 
\begin_inset Formula $\sigma_{r+1}=\cdots=\sigma_{n}=0$
\end_inset

, then 
\begin_inset Formula $r$
\end_inset

 is the rank of 
\begin_inset Formula $A$
\end_inset

.
 In this case, 
\begin_inset Formula $S$
\end_inset

 becomes an 
\begin_inset Formula $r\times r$
\end_inset

 matrix, and 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 shrink accordingly.
 SVD can thus be used for rank determination.
\end_layout

\begin_layout Standard
The SVD provides a numerically robust solution to the least-squares problem.
 The matrix-algebraic phrasing of the least-squares solution 
\begin_inset Formula $x$
\end_inset

 is 
\begin_inset Formula 
\[
x=(A^{T}A)^{-1}A^{T}b
\]

\end_inset

Then utilizing the SVD by making the replacement 
\begin_inset Formula $A=USV^{T}$
\end_inset

 we have 
\begin_inset Formula 
\[
x=V\begin{bmatrix}\Sigma^{-1} & 0\end{bmatrix}U^{T}b.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\norm}[1]{\left\Vert #1\right\Vert }
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\C}{\mathbf{C}}
\end_inset

 
\end_layout

\begin_layout Section*
Proof of SVD
\end_layout

\begin_layout Standard
To prove existence of the SVD, we isolate the direction of the largest action
 of 
\begin_inset Formula $A\in\C^{m\times n}$
\end_inset

, and then proceed by induction on the dimension of 
\begin_inset Formula $A$
\end_inset

.
 We will denote hermitian conjugation by 
\begin_inset Formula $^{T}$
\end_inset

.
 Norms for vectors in 
\begin_inset Formula $\C^{n}$
\end_inset

 will be the usual euclidean 2-norm 
\begin_inset Formula $\norm{\cdot}=\norm{\cdot}_{2}$
\end_inset

 and for matrix the induced by norm of vectors.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\sigma_{1}=\norm A$
\end_inset

.
 By a compactness argument, there must be vectors 
\begin_inset Formula $v_{1}\in\C^{n},u_{1}^{*}\in\C^{m}$
\end_inset

 with 
\begin_inset Formula $\norm{v_{1}}=1,\norm{u_{1}^{*}}=\sigma_{1}$
\end_inset

 and 
\begin_inset Formula $u_{1}^{*}=Av_{1}$
\end_inset

.
 Normalize 
\begin_inset Formula $u_{1}^{*}$
\end_inset

 by setting 
\begin_inset Formula $u_{1}=u_{1}^{*}/\norm{u_{1}^{*}}$
\end_inset

 and consider any extensions of 
\begin_inset Formula $v_{1}$
\end_inset

 to an orthonormal basis 
\begin_inset Formula $\{v_{i}\}$
\end_inset

 of 
\begin_inset Formula $\C^{n}$
\end_inset

 and of 
\begin_inset Formula $u_{1}$
\end_inset

 to an orthonormal basis 
\begin_inset Formula $\{u_{j}\}$
\end_inset

 of 
\begin_inset Formula $\C^{m}$
\end_inset

; let 
\begin_inset Formula $U_{1}$
\end_inset

 and 
\begin_inset Formula $V_{1}$
\end_inset

 denote the unitary matrices with columns 
\begin_inset Formula $\{v_{i}\}$
\end_inset

 and 
\begin_inset Formula $\{u_{j}\}$
\end_inset

 respectively.
 Then we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
U_{1}^{T}AV_{1}=S=\left(\begin{array}{cc}
\sigma_{1} & w^{T}\\
0 & B
\end{array}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
where 
\begin_inset Formula $0$
\end_inset

 is a column vector of dimension 
\begin_inset Formula $m-1$
\end_inset

, 
\begin_inset Formula $w^{T}$
\end_inset

 is a row vector of dimension 
\begin_inset Formula $n-1$
\end_inset

, and 
\begin_inset Formula $B$
\end_inset

 is a matrix of dimension 
\begin_inset Formula $(m-1)\times(n-1)$
\end_inset

.
 Now,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\norm{\left(\begin{array}{cc}
\sigma_{1} & w^{T}\\
0 & B
\end{array}\right)\left(\begin{array}{c}
\sigma_{1}\\
w
\end{array}\right)}\geq\sigma_{1}^{2}+w^{2}=(\sigma_{1}^{2}+w^{2})^{1/2}\norm{\left(\begin{array}{c}
\sigma_{1}\\
w
\end{array}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
so that 
\begin_inset Formula $\norm S\geq(\sigma_{1}^{2}+w^{2})^{1/2}$
\end_inset

.
 But 
\begin_inset Formula $U_{1}$
\end_inset

 and 
\begin_inset Formula $V_{1}$
\end_inset

 are unitary matrix, hence 
\begin_inset Formula $\norm S=\sigma_{1}$
\end_inset

; it therefore implies 
\begin_inset Formula $w=0$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
If 
\begin_inset Formula $n=1$
\end_inset

 or 
\begin_inset Formula $m=1$
\end_inset

 we are done.
 Otherwise the submatrix 
\begin_inset Formula $B$
\end_inset

 describes the action of 
\begin_inset Formula $A$
\end_inset

 on the subspace orthogonal to 
\begin_inset Formula $v_{1}$
\end_inset

.
 By the induction hypothesis 
\begin_inset Formula $B$
\end_inset

 has an SVD 
\begin_inset Formula $B=U_{2}\Sigma_{2}V_{2}^{T}$
\end_inset

.
 Now it is easily verified that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A=U_{1}\left(\begin{array}{cc}
1 & 0\\
0 & U_{2}
\end{array}\right)\left(\begin{array}{cc}
\sigma_{1} & 0\\
0 & \Sigma_{2}
\end{array}\right)\left(\begin{array}{cc}
1 & 0\\
0 & V_{2}
\end{array}\right)^{T}V_{1}^{T}
\]

\end_inset


\end_layout

\begin_layout Standard
\noindent
is an SVD of 
\begin_inset Formula $A$
\end_inset

.
 completing the proof of existence.
\end_layout

\begin_layout Standard
For the uniqueness let 
\begin_inset Formula $A=U\Sigma V^{T}$
\end_inset

 a SVD for 
\begin_inset Formula $A$
\end_inset

 and let 
\begin_inset Formula $e_{i}$
\end_inset

 denote the i-th, 
\begin_inset Formula $i=1\cdots min(m,n)$
\end_inset

 vector of the canonical base of 
\begin_inset Formula $\C^{n}$
\end_inset

.
 As 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $V$
\end_inset

 are unitary, 
\begin_inset Formula $\norm{Ae_{i}}=\sigma_{i}^{2}$
\end_inset

, so each 
\begin_inset Formula $\sigma_{i}$
\end_inset

 is uniquely determined.
\end_layout

\begin_layout Chapter
Advanced Matrix Operations in 
\emph on
Mathematica
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Box Shadowbox
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset listings
lstparams "basicstyle={\ttfamily}"
inline false
status open

\begin_layout Plain Layout

SingularValueList[m]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

SingularValueList[m,k]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

SingularValueList[{m,a}]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\noindent

Norm[m,p]
\end_layout

\begin_layout Plain Layout
\noindent

				   
\end_layout

\begin_layout Plain Layout

Norm[m,"Frobenius"]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

LUDecomposition[m] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

CholeskyDecomposition[m]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

PseudoInverse[m] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

QRDecomposition[m]	
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

JordanDecomposition[m] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

SchurDecomposition[m] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

SchurDecomposition[{m,a}]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

HessenbergDecomposition[m]	 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Section
Examples of Jordan Decomposition
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily}"
inline false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

JordanDecomposition[A] 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
yields the Jordan decomposition of a square matrix 
\begin_inset Formula $A$
\end_inset

.
 The result is a list 
\begin_inset Formula $\left\{ S,J\right\} $
\end_inset

where 
\begin_inset Formula $S$
\end_inset

 is a similarity matrix and 
\begin_inset Formula $J$
\end_inset

 is the Jordan canonical form of 
\begin_inset Formula $A$
\end_inset

 so that
\begin_inset Formula 
\[
A=SJS^{-1}.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $A$
\end_inset

 is a 
\begin_inset Formula $4\times4$
\end_inset

 matrix
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily}"
inline false
status open

\begin_layout Plain Layout

A = {{2, 0, 0, 0}, {0, 1, 0, 0}, {1, -1, 1, 0}, {1, -1, 1, 1}};
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Find the Jordan decomposition in exact arithmetic:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily}"
inline false
status open

\begin_layout Plain Layout

{S, J} = JordanDecomposition[A]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

{{{0, 0, 0, 1}, {0, 0, -1, 0}, {0, 1, -1, 1}, {1, 0, 0, 2}},
\end_layout

\begin_layout Plain Layout

{{1, 1,  0, 0}, {0, 1, 1, 0}, {0, 0, 1, 0}, {0, 0, 0, 2}}}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily}"
inline false
status open

\begin_layout Plain Layout

Map[MatrixForm, %]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\left\{ \left(\begin{array}{cccc}
0 & 0 & 0 & 1\\
0 & 0 & -1 & 0\\
0 & 1 & -1 & 1\\
1 & 0 & 0 & 2
\end{array}\right),\left(\begin{array}{cccc}
1 & 1 & 0 & 0\\
0 & 1 & 1 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 2
\end{array}\right)\right\} $
\end_inset


\end_layout

\begin_layout Standard
Check that 
\begin_inset Formula $A=SJS^{-1}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\ttfamily}"
inline false
status collapsed

\begin_layout Plain Layout

A == S.J.Inverse[S]
\end_layout

\begin_layout Plain Layout

True
\end_layout

\end_inset


\end_layout

\begin_layout Part
Spectral Theory
\end_layout

\begin_layout Chapter
Invariant Subspaces
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $T\,\colon\, V\longrightarrow V$
\end_inset

 be a linear transformation of a vector space 
\begin_inset Formula $V$
\end_inset

.
 A subspace 
\begin_inset Formula $U\subset V$
\end_inset

 is called a 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
em
\end_layout

\end_inset

 
\begin_inset Formula $T$
\end_inset

-invariant subspace
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 if 
\begin_inset Formula $T(u)\in U$
\end_inset

 for all 
\begin_inset Formula $u\in U$
\end_inset

.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $U$
\end_inset

 is an invariant subspace, then the restriction of 
\begin_inset Formula $T$
\end_inset

 to 
\begin_inset Formula $U$
\end_inset

 gives a well defined linear transformation of 
\begin_inset Formula $U$
\end_inset

.
 Furthermore, suppose that 
\begin_inset Formula $V$
\end_inset

 is 
\begin_inset Formula $n$
\end_inset

-dimensional and that 
\begin_inset Formula $v_{1},\ldots,v_{n}$
\end_inset

 is a basis of 
\begin_inset Formula $V$
\end_inset

 with the first 
\begin_inset Formula $m$
\end_inset

 vectors giving a basis of 
\begin_inset Formula $U$
\end_inset

.
 Then, the representing matrix of the transformation 
\begin_inset Formula $T$
\end_inset

 relative to this basis takes the form 
\begin_inset Formula 
\[
\begin{pmatrix}A & B\\
0 & C
\end{pmatrix}
\]

\end_inset

where 
\begin_inset Formula $A$
\end_inset

 is an 
\begin_inset Formula $m\times m$
\end_inset

 matrix representing the restriction transformation 
\begin_inset Formula 
\[
T\big|_{U}\,\colon\, U\longrightarrow U
\]

\end_inset

 relative to the basis 
\begin_inset Formula $v_{1},\ldots,v_{m}$
\end_inset

.
\end_layout

\begin_layout Chapter
Spectral Theorem
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $T$
\end_inset

 is a self-adjoint operator in a finite-dimensional Hilbert space 
\begin_inset Formula $H$
\end_inset

.
 An important fact about self-adjoint operators (not just in finite-dimensional
 spaces) is the following:
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\series bold
F
\series default
act 1.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\emph on
If 
\begin_inset Formula $V\subseteq H$
\end_inset

 is an invariant subspace by 
\begin_inset Formula $T$
\end_inset

, then so it is 
\begin_inset Formula $V^{\perp}$
\end_inset

, the orthogonal complement of 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $x\in V$
\end_inset

 and 
\begin_inset Formula $y\in V^{\perp}$
\end_inset

.
 Then 
\begin_inset Formula $\langle x,Ty\rangle=\langle Tx,y\rangle=0$
\end_inset

, where the last term is zero because 
\begin_inset Formula $V$
\end_inset

 is invariant by 
\begin_inset Formula $T$
\end_inset

, i.e.
 
\begin_inset Formula $Tx\in V$
\end_inset

.
 But this proves that 
\begin_inset Formula $Ty\in V^{\perp}$
\end_inset

.
 
\begin_inset Formula $\square$
\end_inset

 
\end_layout

\begin_layout Standard
In finite dimensions it is known that every linear transformation has, at
 least, one eigenvector.
 Of course, the subspace generated by an eigenvector is always invariant.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $v_{1}$
\end_inset

 be an eigenvector of 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $V_{1}$
\end_inset

 the subspace generated by it.
 For self-adjoint transformations, Fact 1 above says that 
\begin_inset Formula $V_{1}^{\perp}$
\end_inset

 is also invariant by 
\begin_inset Formula $T$
\end_inset

.
 Thus, by restriction, we have a self-adjoint operator 
\begin_inset Formula $T:V_{1}^{\perp}\longrightarrow V_{1}^{\perp}$
\end_inset

 and we could again find an eigenvector and repeat the same argument.
 Thus, we are decomposing 
\begin_inset Formula $H$
\end_inset

 as a direct sum of orthogonal one-dimensional subspaces 
\begin_inset Formula $H=V_{1}\oplus\dots\oplus V_{n}$
\end_inset

, and the operator 
\begin_inset Formula $T$
\end_inset

 can be expressed as a sum
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T=\sum_{i=1}^{n}\lambda_{i}P_{i}
\]

\end_inset

where each 
\begin_inset Formula $\lambda_{i}$
\end_inset

 is the eigenvalue associated with the eigenvector 
\begin_inset Formula $v_{i}$
\end_inset

 and each 
\begin_inset Formula $P_{i}$
\end_inset

 is the orthogonal projection onto the subspace 
\begin_inset Formula $V_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
This is exactly the process of diagonalization of a self-adjoint matrix.
 
\end_layout

\end_body
\end_document
